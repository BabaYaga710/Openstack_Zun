+ dirname /local/repository/setup-controller.sh
+ DIRNAME=/local/repository
+ [ -ne 0 ]
/local/repository/setup-controller.sh: 12: [: -ne: unexpected operator
+ . /local/repository/setup-lib.sh
+ dirname /local/repository/setup-controller.sh
+ DIRNAME=/local/repository
+ OURDIR=/root/setup
+ SETTINGS=/root/setup/settings
+ LOCALSETTINGS=/root/setup/settings.local
+ TOPOMAP=/root/setup/topomap
+ BOOTDIR=/var/emulab/boot
+ TMCC=/usr/local/etc/emulab/tmcc
+ TIMELOGFILE=/root/setup/setup-time.log
+ FIRSTTIME=0
+ [ ! -f /root/setup/setup-lib-first ]
+ [ 0 -ne 0 ]
+ mkdir -p /root/setup
+ touch /root/setup/settings
+ touch /root/setup/settings.local
+ cd /root/setup
+ LOCKFILE=lockfile-create --retry 65535 
+ RMLOCKFILE=lockfile-remove 
+ PSWDGEN=openssl rand -hex 10
+ SSH=ssh -o StrictHostKeyChecking=no
+ SCP=scp -p -o StrictHostKeyChecking=no
+ CONTROLLER=ctl
+ NETWORKMANAGER=nm
+ STORAGEHOST=ctl
+ SHAREHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=
+ BAREMETALNODES=
+ BLOCKNODES=
+ OBJECTNODES=
+ DATALAN=lan-1
+ MGMTLAN=lan-2
+ BLOCKLAN=
+ OBJECTLAN=
+ DATATUNNELS=1
+ DATAFLATLANS=lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATAOTHERLANS=
+ USE_EXISTING_IPS=1
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=0
+ DO_APT_UPDATE=1
+ UBUNTUMIRRORHOST=
+ UBUNTUMIRRORPATH=
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DO_UBUNTU_CLOUDARCHIVE=0
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ BUILD_AARCH64_FROM_CORE=0
+ DISABLE_SECURITY_GROUPS=0
+ ENABLE_HOST_PASSTHROUGH=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ SUPPORT_DYNAMIC_NODES=0
+ KEYSTONEAPIVERSION=
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ GLANCE_LV_SIZE=32
+ SWIFT_LV_SIZE=4
+ CEILOMETER_USE_WSGI=0
+ QUOTASOFF=1
+ KEYSTONEUSEMEMCACHE=0
+ KEYSTONEUSEWSGI=
+ COMPUTE_EXTRA_NOVA_DISK_SPACE=1
+ ML2PLUGIN=openvswitch
+ MANILADRIVER=generic
+ EXTRAIMAGEURLS=
+ LINUXBRIDGE_STATIC=0
+ USE_DESIGNATE_AS_RESOLVER=1
+ USE_NEUTRON_LBAAS=1
+ ENABLE_OPENSTACK_SLOTHD=0
+ OSRELEASE=
+ ADMIN_API=adminapi
+ openssl rand -hex 10
+ ADMIN_API_PASS=92748256c1e798f84f04
+ ADMIN=admin
+ ADMIN_PASS=
+ ADMIN_PASS_HASH=
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ [ x = x ]
+ UPDATING=0
+ NEWNODELIST=
+ OLDNODELIST=
+ [ ! -e /root/setup/apt-configured ]
+ export DEBIAN_FRONTEND=noninteractive
+ DPKGOPTS=
+ APTGETINSTALLOPTS=-y
+ APTGETINSTALL=apt-get  install -y
+ [ 1 -eq 0 ]
+ grep GENIUSER /root/setup/settings
GENIUSER=1
+ [ ! 0 -eq 0 ]
+ grep GENIUSER=1 /root/setup/settings
GENIUSER=1
+ [ 0 -eq 0 ]
+ GENIUSER=1
+ [ 1 -eq 1 ]
+ dpkg -s python-m2crypto
+ [ ! 0 -eq 0 ]
+ [ ! -e /root/setup/geni.key ]
+ HAS_GENI_KEY=1
+ [ ! -e /root/setup/geni.certificate ]
+ HAS_GENI_CERT=1
+ [ ! -e /root/.ssl/encrypted.pem ]
+ [ ! -e /root/setup/manifests.xml -o 0 -ne 0 ]
+ [ ! -e /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/decrypted_admin_pass -a -s /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/parameters ]
+ . /root/setup/parameters
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ COMPUTENODES=compute-1 
+ DATALANS=flat-lan-1
+ DATAFLATLANS=flat-lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATATUNNELS=1
+ MGMTLAN=
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=1
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ DO_APT_UPDATE=1
+ ADMIN_PASS_HASH=
+ ENABLE_HOST_PASSTHROUGH=1
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DISABLE_SECURITY_GROUPS=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ USE_NEUTRON_LBAAS=1
+ CEILOMETER_USE_MONGODB=0
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ KEYSTONEUSEMEMCACHE=0
+ QUOTASOFF=1
+ ML2PLUGIN=openvswitch
+ USE_DESIGNATE_AS_RESOLVER=1
+ EXTRAIMAGEURLS=
+ OSRELEASE=rocky
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ ADMIN_PASS=9da6fece4881
+ ADMIN_PASS_HASH=$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA.
+ [ x$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA. = x ]
+ cat /var/emulab/boot/creator
+ CREATOR=tboudw0
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ cat /var/emulab/boot/nickname
+ cut -d . -f 1
+ NODEID=controller
+ cat /var/emulab/boot/nodeid
+ PNODEID=clnode234
+ cat /var/emulab/boot/nickname
+ cut -d . -f 2
+ EEID=tboudwin-QV52139
+ cat /var/emulab/boot/nickname+ 
cut -d . -f 3
+ EPID=pdc-edu-lab-PG0
+ cat /var/emulab/boot/mydomain
+ OURDOMAIN=clemson.cloudlab.us
+ cat /var/emulab/boot/nickname
+ NFQDN=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ cat /var/emulab/boot/nodeid
+ PFQDN=clnode234.clemson.cloudlab.us
+ cat /var/emulab/boot/myip
+ MYIP=130.127.133.243
+ cat /var/emulab/boot/controlif
+ EXTERNAL_NETWORK_INTERFACE=br-ex
+ cat /var/emulab/boot/nickname
+ cut -f1 -d.
+ HOSTNAME=controller
+ uname -m
+ ARCH=x86_64
+ dpkg-query -S /sbin/init
+ grep -q systemd
+ expr 0 = 0
+ HAVE_SYSTEMD=1
+ OSJUNO=10
+ OSKILO=11
+ OSLIBERTY=12
+ OSMITAKA=13
+ OSNEWTON=14
+ OSOCATA=15
+ OSPIKE=16
+ OSQUEENS=17
+ OSROCKY=18
+ . /etc/lsb-release
+ DISTRIB_ID=Ubuntu
+ DISTRIB_RELEASE=18.04
+ DISTRIB_CODENAME=bionic
+ DISTRIB_DESCRIPTION=Ubuntu 18.04.2 LTS
+ [ ! xrocky = x ]
+ OSCODENAME=rocky
+ [ rocky = juno ]
+ [ rocky = kilo ]
+ [ rocky = liberty ]
+ [ rocky = mitaka ]
+ [ rocky = newton ]
+ [ rocky = ocata ]
+ [ rocky = pike ]
+ [ rocky = queens ]
+ [ rocky = rocky ]
+ OSVERSION=18
+ echo Ubuntu 18.04.2 LTS
+ grep -qi LTS
+ [ 0 -eq 0 ]
+ DO_UBUNTU_CLOUDARCHIVE=1
+ echo 18.04
+ cut -d. -f1
+ DISTRIB_MAJOR=18
+ [ 18 -ge 13 ]
+ KEYSTONEUSEMEMCACHE=1
+ [ 18 -eq 10 ]
+ REGION=RegionOne
+ [ 18 -ge 17 ]
+ KADMINPORT=5000
+ [ x = x3 ]
+ [  != 2 -a 18 -ge 12 ]
+ KAPISTR=v3
+ KEYSTONEAPIVERSION=3
+ NAPISTR=v2
+ [ 18 -ge 13 ]
+ NAPISTR=v2.1
+ [ x = x -a 18 -ge 11 ]
+ KEYSTONEUSEWSGI=1
+ [ 18 -ge 13 ]
+ PROJECT_DOMAIN_PARAM=project_domain_name
+ USER_DOMAIN_PARAM=user_domain_name
+ AUTH_TYPE_PARAM=auth_type
+ [ 18 -ge 14 ]
+ DBDPACKAGE=python-pymysql
+ DBDSTRING=mysql+pymysql
+ [ 1 -eq 1 ]
+ geni-get slice_email
+ SWAPPER_EMAIL=tboudwin@wcupa.edu
+ [ 1 -eq 1 ]
+ + perl -e $found = 0; while (<STDIN>) { if ($_ =~ /\<[\d\w:]*routable_pool [^\>\<]*\/>/) { print STDERR "DEBUG: found empty pool: $_\n"; next; } if ($_ =~ /\<[\d\w:]*routable_pool [^\>]*client_id=['"]controller['"]/) { $found = 1; print STDERR "DEBUG: found: $_\n" } if ($found) { while ($_ =~ m/\<emulab:ipv4 address="([\d.]+)\" netmask=\"([\d\.]+)\"/g) { print "$1\n"; } } if ($found && $_ =~ /routable_pool\>/) { print STDERR "DEBUG: end found: $_\n"; $found = 0; } }
cat /root/setup/manifests.0.xml
+ xargs
DEBUG: found:   <emulab:routable_pool client_id="controller" count="4" type="any" component_manager_id="urn:publicid:IDN+clemson.cloudlab.us+authority+cm">

DEBUG: end found:   <emulab:ipv4 address="130.127.132.210" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.226" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.238" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.239" netmask="255.255.252.0"/></emulab:routable_pool>

+ PUBLICADDRS=130.127.132.210 130.127.132.226 130.127.132.238 130.127.132.239
+ PUBLICCOUNT=0
+ expr 0 + 1
+ PUBLICCOUNT=1
+ expr 1 + 1
+ PUBLICCOUNT=2
+ expr 2 + 1
+ PUBLICCOUNT=3
+ expr 3 + 1
+ PUBLICCOUNT=4
+ [ ! -f /root/setup/topomap -o 0 -ne 0 ]
+ [ ! -z  ]
+ [ ( -s /root/setup/manifests.xml ) -a ( ! ( -s /root/setup/fqdn.map ) ) ]
+ [ ! -s /root/setup/fqdn.map ]
+ cat /root/setup/fqdn.map
+ cut -f1
+ xargs
+ NODES=controller compute-1
+ cat /root/setup/fqdn.map
+ cut -f2
+ xargs
+ FQDNS=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ [ -z compute-1  ]
+ OTHERNODES=
+ [ controller = controller ]
+ continue
+ [ compute-1 = controller ]
+ OTHERNODES= compute-1
+ grep CONTROLLER /root/setup/settings
CONTROLLER="controller"
+ [ ! 0 = 0 ]
+ [ 0 -ne 0 ]
+ grep MIRRORSETUP /root/setup/settings
MIRRORSETUP=1
+ [ ! 0 -eq 0 ]
+ [ ! -f /root/setup/apt-updated -a 1 = 1 ]
+ [ ! -f /root/setup/cloudarchive-added -a 1 = 1 ]
+ [ ! -f /root/setup/apt-dist-upgraded -a 1 = 1 ]
+ maybe_install_packages crudini
+ [ ! 0 -eq 0 ]
+ are_packages_installed crudini
+ retval=1
+ [ ! -z crudini ]
+ dpkg -s crudini
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ ! -f /root/setup/nextsparesubnet ]
+ cat /root/setup/nextsparesubnet
+ NEXTSPARESUBNET=253
+ [ ! -f /root/setup/mgmt-hosts -o 0 -ne 0 ]
+ [ 1 -gt 0 ]
+ i=0
+ [ 0 -lt 1 ]
+ [ -f /root/setup/ipinfo.tun0 ]
+ expr 0 + 1
+ i=1
+ continue
+ [ 1 -lt 1 ]
+ echo 253
+ echo 253
+ [ 0 -gt 0 ]
+ [ ! -e /root/setup/info.mgmt ]
+ . /root/setup/info.mgmt
+ MGMTIP=192.168.0.1
+ MGMTNETMASK=255.255.0.0
+ MGMTPREFIX=16
+ MGMTVLAN=0
+ MGMTMAC=
+ MGMT_NETWORK_INTERFACE=tun0
+ MGMTVLANDEV=
+ MGMTVLANTAG=
+ [ -e /root/setup/info.flat-lan-1 ]
+ continue
+ [ ! -f /root/setup/neutron.vars ]
+ [ ! -f /etc/emulab/bossnode -a 18 -ge 14 -a 1 = 1 ]
+ [ 0 -ne 0 ]
+ which wget
+ GETTER=/usr/bin/wget
+ [ -n /usr/bin/wget ]
+ GETTEROUT=/usr/bin/wget --remote-encoding=unix -c -O
+ GETTER=/usr/bin/wget --remote-encoding=unix -c -N
+ GETTERLOGARG=-o
+ [ 0 -ne 0 ]
+ [ controller != controller ]
+ logtstart controller
+ area=controller
+ echo controller
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=controller
+ date +%s
+ stamp=1557518730
+ date
+ date=Fri May 10 14:05:30 MDT 2019
+ eval LOGTIMESTART_controller=1557518730
+ LOGTIMESTART_controller=1557518730
+ echo START controller 1557518730 Fri May 10 14:05:30 MDT 2019
+ [ -f /root/setup/settings ]
+ . /root/setup/settings
+ GENIUSER=1
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ STORAGEHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=compute-1 
+ MIRRORSETUP=1
+ maybe_install_packages qemu-utils wget lockfile-progs rpm
+ [ ! 0 -eq 0 ]
+ are_packages_installed qemu-utils wget lockfile-progs rpm
+ retval=1
+ [ ! -z qemu-utils ]
+ dpkg -s qemu-utils
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z wget ]
+ dpkg -s wget
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z lockfile-progs ]
+ dpkg -s lockfile-progs
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z rpm ]
+ dpkg -s rpm
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ x86_64 = aarch64 ]
+ maybe_install_packages pssh
+ [ ! 0 -eq 0 ]
+ are_packages_installed pssh
+ retval=1
+ [ ! -z pssh ]
+ dpkg -s pssh
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ PSSH=/usr/bin/parallel-ssh -t 0 -O StrictHostKeyChecking=no 
+ PSCP=/usr/bin/parallel-scp -t 0 -O StrictHostKeyChecking=no 
+ maybe_install_packages dma
+ [ ! 0 -eq 0 ]
+ are_packages_installed dma
+ retval=1
+ [ ! -z dma ]
+ dpkg -s dma
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ maybe_install_packages mailutils
+ [ ! 0 -eq 0 ]
+ are_packages_installed mailutils
+ retval=1
+ [ ! -z mailutils ]
+ dpkg -s mailutils
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ echo clnode234.clemson.cloudlab.us
+ sleep 2
+ hostname
+ echo Your OpenStack instance is setting up on clnode234 .
+ mail -s OpenStack Instance Setting Up tboudwin@wcupa.edu
+ [ 18 -ge 11 ]
+ maybe_install_packages python-openstackclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-openstackclient
+ retval=1
+ [ ! -z python-openstackclient ]
+ dpkg -s python-openstackclient
+ /local/repository/setup-images.sh
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -ge 11 -a 18 -lt 14 ]
+ [ -z  ]
+ logtstart database
+ area=database
+ echo database
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=database
+ date +%s
+ stamp=1557518732
+ date
+ date=Fri May 10 14:05:32 MDT 2019
+ eval LOGTIMESTART_database=1557518732
+ LOGTIMESTART_database=1557518732
+ echo START database 1557518732 Fri May 10 14:05:32 MDT 2019
+ maybe_install_packages mariadb-server python-pymysql
+ [ ! 0 -eq 0 ]
+ are_packages_installed mariadb-server python-pymysql
+ retval=1
+ [ ! -z mariadb-server ]
+ dpkg -s mariadb-server
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-pymysql ]
+ dpkg -s python-pymysql
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ service_stop mysql
+ service=mysql
+ [ 1 -eq 0 ]
+ systemctl stop mysql
+ sleep 8
+ mysqld_safe --skip-grant-tables --skip-networking
190510 14:05:33 mysqld_safe Logging to syslog.
190510 14:05:33 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql
+ openssl rand -hex 10
+ DB_ROOT_PASS=ad12065d4a6fcf049d20
+ echo use mysql; update user set password=PASSWORD("ad12065d4a6fcf049d20") where User='root'; delete from user where User=''; delete from user where User='root' and Host not in ('localhost', '127.0.0.1', '::1'); drop database test; delete from db where Db='test' or Db='test\_%'; flush privileges;
+ mysql -u root
ERROR 1008 (HY000) at line 1: Can't drop database 'test'; database doesn't exist
+ mysqladmin --password=ad12065d4a6fcf049d20 shutdown
+ echo [mysqld]
+ echo bind-address = 192.168.0.1
+ echo default-storage-engine = innodb
+ echo innodb_file_per_table
+ echo collation-server = utf8_general_ci
+ echo init-connect = 'SET NAMES utf8'
+ echo character-set-server = utf8
+ echo max_connections = 4096
+ service_restart mysql
+ service=mysql
+ [ 1 -eq 0 ]
+ systemctl restart mysql
+ service_enable mysql
+ service=mysql
+ [ 1 -eq 0 ]
+ systemctl enable mysql
mysql.service is not a native service, redirecting to systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable mysql
+ echo DB_ROOT_PASS="ad12065d4a6fcf049d20"
+ [ -z  -a 18 -ge 12 ]
+ cat
+ chmod 755 /etc/init.d/legacy-openvpn-net-waiter
+ update-rc.d legacy-openvpn-net-waiter defaults
+ update-rc.d legacy-openvpn-net-waiter enable
+ logtend database
+ area=database
+ echo database
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=database
+ date +%s
+ stamp=1557518744
+ date
+ date=Fri May 10 14:05:44 MDT 2019
+ eval tss=$LOGTIMESTART_database
+ tss=1557518732
+ expr 1557518744 - 1557518732
+ tsres=12
+ perl -e print 12 / 60.0 . "\n"
+ resmin=0.2
+ echo END database 1557518744 Fri May 10 14:05:44 MDT 2019
+ echo TOTAL database 12 0.2
+ [ -z  ]
+ logtstart rabbit
+ area=rabbit
+ echo rabbit
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=rabbit
+ date +%s
+ stamp=1557518744
+ date
+ date=Fri May 10 14:05:44 MDT 2019
+ eval LOGTIMESTART_rabbit=1557518744
+ LOGTIMESTART_rabbit=1557518744
+ echo START rabbit 1557518744 Fri May 10 14:05:44 MDT 2019
+ maybe_install_packages rabbitmq-server
+ [ ! 0 -eq 0 ]
+ are_packages_installed rabbitmq-server
+ retval=1
+ [ ! -z rabbitmq-server ]
+ dpkg -s rabbitmq-server
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ service_restart rabbitmq-server
+ service=rabbitmq-server
+ [ 1 -eq 0 ]
+ systemctl restart rabbitmq-server
+ service_enable rabbitmq-server
+ service=rabbitmq-server
+ [ 1 -eq 0 ]
+ systemctl enable rabbitmq-server
Synchronizing state of rabbitmq-server.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable rabbitmq-server
+ rabbitmqctl start_app
Starting node rabbit@clnode234
+ [ ! 0 -eq 0 ]
+ [ 18 -lt 14 ]
+ [ rocky = juno ]
+ RABBIT_USER=openstack
+ rabbitmqctl add_vhost /
Creating vhost "/"
Error: vhost_already_exists: /
+ openssl rand -hex 10
+ RABBIT_PASS=0375d10f3c80e2774768
+ RABBIT_URL=rabbit://openstack:0375d10f3c80e2774768@controller
+ rabbitmqctl change_password openstack 0375d10f3c80e2774768
Changing password for user "openstack"
Error: no_such_user: openstack
+ [ ! 70 -eq 0 ]
+ rabbitmqctl add_user openstack 0375d10f3c80e2774768
Creating user "openstack"
+ rabbitmqctl set_permissions openstack .* .* .*
Setting permissions for user "openstack" in vhost "/"
+ echo RABBIT_USER="openstack"
+ echo RABBIT_PASS="0375d10f3c80e2774768"
+ echo RABBIT_URL="rabbit://openstack:0375d10f3c80e2774768@controller"
+ rabbitmqctl stop_app
Stopping rabbit application on node rabbit@clnode234
+ service_restart rabbitmq-server
+ service=rabbitmq-server
+ [ 1 -eq 0 ]
+ systemctl restart rabbitmq-server
+ rabbitmqctl start_app
Starting node rabbit@clnode234
+ [ ! 0 -eq 0 ]
+ [ -z  -a 18 -ge 12 ]
+ cat
+ systemctl enable openvpn-net-waiter.service
Created symlink /etc/systemd/system/multi-user.target.wants/openvpn-net-waiter.service â†’ /etc/systemd/system/openvpn-net-waiter.service.
+ logtend rabbit
+ area=rabbit
+ echo rabbit
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=rabbit
+ date +%s
+ stamp=1557518757
+ date
+ date=Fri May 10 14:05:57 MDT 2019
+ eval tss=$LOGTIMESTART_rabbit
+ tss=1557518744
+ expr 1557518757 - 1557518744
+ tsres=13
+ perl -e print 13 / 60.0 . "\n"
+ resmin=0.216666666666667
+ echo END rabbit 1557518757 Fri May 10 14:05:57 MDT 2019
+ echo TOTAL rabbit 13 0.216666666666667
+ DOMARG=
+ [ x3 = x3 ]
+ DOMARG=--domain default
+ [ -z  ]
+ logtstart memcache
+ area=memcache
+ echo memcache
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=memcache
+ date +%s
+ stamp=1557518757
+ date
+ date=Fri May 10 14:05:57 MDT 2019
+ eval LOGTIMESTART_memcache=1557518757
+ LOGTIMESTART_memcache=1557518757
+ echo START memcache 1557518757 Fri May 10 14:05:57 MDT 2019
+ maybe_install_packages memcached python-memcache
+ [ ! 0 -eq 0 ]
+ are_packages_installed memcached python-memcache
+ retval=1
+ [ ! -z memcached ]
+ dpkg -s memcached
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-memcache ]
+ dpkg -s python-memcache
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ cat
+ [ 1 -eq 1 ]
+ mkdir /etc/systemd/system/memcached.service.d
+ systemctl list-units
+ grep -q networking.service
+ [ 1 -eq 0 ]
+ systemctl list-units
+ grep -q network-online.target
+ [ 0 -eq 0 ]
+ cat
+ service_restart memcached
+ service=memcached
+ [ 1 -eq 0 ]
+ systemctl restart memcached
+ service_enable memcached
+ service=memcached
+ [ 1 -eq 0 ]
+ systemctl enable memcached
Synchronizing state of memcached.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable memcached
+ echo MEMCACHE_DONE=1
+ logtend memcache
+ area=memcache
+ echo memcache
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=memcache
+ date +%s
+ stamp=1557518757
+ date
+ date=Fri May 10 14:05:57 MDT 2019
+ eval tss=$LOGTIMESTART_memcache
+ tss=1557518757
+ expr 1557518757 - 1557518757
+ tsres=0
+ perl -e print 0 / 60.0 . "\n"
+ resmin=0
+ echo END memcache 1557518757 Fri May 10 14:05:57 MDT 2019
+ echo TOTAL memcache 0 0
+ [ 18 -ge 18 -a -z  ]
+ logtstart etcd
+ area=etcd
+ echo etcd
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=etcd
+ date +%s
+ stamp=1557518757
+ date
+ date=Fri May 10 14:05:57 MDT 2019
+ eval LOGTIMESTART_etcd=1557518757
+ LOGTIMESTART_etcd=1557518757
+ echo START etcd 1557518757 Fri May 10 14:05:57 MDT 2019
+ [ x86_64 = aarch64 ]
+ maybe_install_packages etcd etcd-server etcd-client
+ [ ! 0 -eq 0 ]
+ are_packages_installed etcd etcd-server etcd-client
+ retval=1
+ [ ! -z etcd ]
+ dpkg -s etcd
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z etcd-server ]
+ dpkg -s etcd-server
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z etcd-client ]
+ dpkg -s etcd-client
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -le 17 ]
+ cat
+ service_enable etcd
+ service=etcd
+ [ 1 -eq 0 ]
+ systemctl enable etcd
Synchronizing state of etcd.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable etcd
Created symlink /etc/systemd/system/etcd2.service â†’ /lib/systemd/system/etcd.service.
+ service_restart etcd
+ service=etcd
+ [ 1 -eq 0 ]
+ systemctl restart etcd
+ echo ETCD_DONE=1
+ logtend etcd
+ area=etcd
+ echo etcd
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=etcd
+ date +%s
+ stamp=1557518758
+ date
+ date=Fri May 10 14:05:58 MDT 2019
+ eval tss=$LOGTIMESTART_etcd
+ tss=1557518757
+ expr 1557518758 - 1557518757
+ tsres=1
+ perl -e print 1 / 60.0 . "\n"
+ resmin=0.0166666666666667
+ echo END etcd 1557518758 Fri May 10 14:05:58 MDT 2019
+ echo TOTAL etcd 1 0.0166666666666667
+ [ -z  ]
+ logtstart keystone
+ area=keystone
+ echo keystone
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=keystone
+ date +%s
+ stamp=1557518758
+ date
+ date=Fri May 10 14:05:58 MDT 2019
+ eval LOGTIMESTART_keystone=1557518758
+ LOGTIMESTART_keystone=1557518758
+ echo START keystone 1557518758 Fri May 10 14:05:58 MDT 2019
+ openssl rand -hex 10
+ KEYSTONE_DBPASS=475bd45587c7b7ebea74
+ echo create database keystone
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on keystone.* to 'keystone'@'localhost' identified by '475bd45587c7b7ebea74'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo+  grant all privileges on keystone.* to 'keystone'@'%' identified by '475bd45587c7b7ebea74'
mysql -u root --password=ad12065d4a6fcf049d20
+ maybe_install_packages keystone python-keystoneclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed keystone python-keystoneclient
+ retval=1
+ [ ! -z keystone ]
+ dpkg -s keystone
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-keystoneclient ]
+ dpkg -s python-keystoneclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -ge 11 ]
+ maybe_install_packages apache2
+ [ ! 0 -eq 0 ]
+ are_packages_installed apache2
+ retval=1
+ [ ! -z apache2 ]
+ dpkg -s apache2
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ maybe_install_packages libapache2-mod-wsgi
+ [ ! 0 -eq 0 ]
+ are_packages_installed libapache2-mod-wsgi
+ retval=1
+ [ ! -z libapache2-mod-wsgi ]
+ dpkg -s libapache2-mod-wsgi
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ openssl rand -hex 10
+ ADMIN_TOKEN=119dff949a74fc99ebad
+ crudini --set /etc/keystone/keystone.conf DEFAULT admin_token 119dff949a74fc99ebad
+ crudini --set /etc/keystone/keystone.conf database connection mysql+pymysql://keystone:475bd45587c7b7ebea74@controller/keystone
+ crudini --set /etc/keystone/keystone.conf token expiration 14400
+ [ 18 -le 10 ]
+ [ 18 -le 11 ]
+ [ 18 -le 13 ]
+ crudini --set /etc/keystone/keystone.conf token provider fernet
+ [ 1 -eq 1 ]
+ [ 18 -lt 17 ]
+ crudini --set /etc/keystone/keystone.conf cache backend dogpile.cache.memcached
+ crudini --set /etc/keystone/keystone.conf cache backend_argument url:127.0.0.1:11211
+ crudini --set /etc/keystone/keystone.conf cache enable true
+ crudini --set /etc/keystone/keystone.conf cache enabled true
+ crudini --set /etc/keystone/keystone.conf cache memcache_servers 127.0.0.1:11211
+ crudini --set /etc/keystone/keystone.conf cache memcached_servers 127.0.0.1:11211
+ crudini --set /etc/keystone/keystone.conf memcache servers 127.0.0.1:11211
+ crudini --set /etc/keystone/keystone.conf DEFAULT verbose False
+ crudini --set /etc/keystone/keystone.conf DEFAULT debug False
+ su -s /bin/sh -c /usr/bin/keystone-manage db_sync keystone
+ [ 18 -ge 14 ]
+ keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
+ keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
+ [ 18 -eq 11 -a 1 -eq 1 ]
+ [ 18 -ge 12 -a 1 -eq 1 -a 18 -lt 14 ]
+ [ 18 -le 10 -o 1 -eq 0 ]
+ service_stop keystone
+ service=keystone
+ [ 1 -eq 0 ]
+ systemctl stop keystone
Failed to stop keystone.service: Unit keystone.service not loaded.
+ service_disable keystone
+ service=keystone
+ [ 1 -eq 0 ]
+ systemctl disable keystone
Failed to disable unit: Unit file keystone.service does not exist.
+ service_restart apache2
+ service=apache2
+ [ 1 -eq 0 ]
+ systemctl restart apache2
+ service_enable apache2
+ service=apache2
+ [ 1 -eq 0 ]
+ systemctl enable apache2
Synchronizing state of apache2.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable apache2
+ rm -f /var/lib/keystone/keystone.db
+ sleep 8
+ crontab -l -u keystone
+ grep -q token_flush
+ echo @hourly /usr/bin/keystone-manage token_flush >/var/log/keystone/keystone-tokenflush.log 2>&1
+ [ 18 -lt 11 ]
+ export OS_TOKEN=119dff949a74fc99ebad
+ export OS_URL=http://controller:5000/v3
+ [ x3 = x3 ]
+ export OS_IDENTITY_API_VERSION=3
+ [ 18 -lt 11 ]
+ __openstack service create --name keystone --description OpenStack Identity identity
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name keystone --description OpenStack Identity identity
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Identity               |
| enabled     | True                             |
| id          | 14a0db27a583421fa97ac886e731793a |
| name        | keystone                         |
| type        | identity                         |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne identity public http://controller:5000/v3
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne identity public http://controller:5000/v3
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 7bacb88316574b8ab05524ae4979a2a7 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 14a0db27a583421fa97ac886e731793a |
| service_name | keystone                         |
| service_type | identity                         |
| url          | http://controller:5000/v3        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne identity internal http://controller:5000/v3
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne identity internal http://controller:5000/v3
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | b9711664afe04868bbc4da169690879e |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 14a0db27a583421fa97ac886e731793a |
| service_name | keystone                         |
| service_type | identity                         |
| url          | http://controller:5000/v3        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne identity admin http://controller:5000/v3
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne identity admin http://controller:5000/v3
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 161ed47f8c8743acbe74f771bc29bd5a |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 14a0db27a583421fa97ac886e731793a |
| service_name | keystone                         |
| service_type | identity                         |
| url          | http://controller:5000/v3        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ x9da6fece4881 = x ]
+ APSWD=9da6fece4881
+ [ 18 -eq 10 ]
+ [ 18 -ge 13 ]
+ openstack domain create --description Default Domain default
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Default Domain                   |
| enabled     | True                             |
| id          | a0bce07342314b118ebf8e33e1eeb2df |
| name        | default                          |
| tags        | []                               |
+-------------+----------------------------------+
+ __openstack project create --domain default --description Admin Project admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack project create --domain default --description Admin Project admin
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Admin Project                    |
| domain_id   | a0bce07342314b118ebf8e33e1eeb2df |
| enabled     | True                             |
| id          | c71f3ce86c4e437abf2407f488c55054 |
| is_domain   | False                            |
| name        | admin                            |
| parent_id   | a0bce07342314b118ebf8e33e1eeb2df |
| tags        | []                               |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack user create --domain default --password 9da6fece4881 --email tboudwin@wcupa.edu admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 9da6fece4881 --email tboudwin@wcupa.edu admin
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| email               | tboudwin@wcupa.edu               |
| enabled             | True                             |
| id                  | 6c368a0d90b64d48aae1ff709f5938d4 |
| name                | admin                            |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role create admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role create admin
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | bffd7d451b304d96aeb56701c919efe5 |
| name      | admin                            |
+-----------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --project admin --user admin admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --project admin --user admin admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role create user
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role create user
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | 88f9f08ae4b144468155f1e669088a48 |
| name      | user                             |
+-----------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --project admin --user admin user
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --project admin --user admin user
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack project create --domain default --description Service Project service
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack project create --domain default --description Service Project service
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Service Project                  |
| domain_id   | a0bce07342314b118ebf8e33e1eeb2df |
| enabled     | True                             |
| id          | eb3d794157014ac6b9c5d7f909d759d6 |
| is_domain   | False                            |
| name        | service                          |
| parent_id   | a0bce07342314b118ebf8e33e1eeb2df |
| tags        | []                               |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack user create --domain default --password 92748256c1e798f84f04 --email tboudwin@wcupa.edu adminapi
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 92748256c1e798f84f04 --email tboudwin@wcupa.edu adminapi
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| email               | tboudwin@wcupa.edu               |
| enabled             | True                             |
| id                  | 26e93374158d4ef5ac8142b240d6590e |
| name                | adminapi                         |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --project admin --user adminapi admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --project admin --user adminapi admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --project admin --user adminapi user
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --project admin --user adminapi user
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ x9da6fece4881 = x ]
+ [ 18 -lt 11 ]
+ unset OS_TOKEN OS_URL
+ unset OS_IDENTITY_API_VERSION
+ crudini --del /etc/keystone/keystone.conf DEFAULT admin_token
+ echo ADMIN_API="adminapi"
+ echo ADMIN_API_PASS="92748256c1e798f84f04"
+ echo KEYSTONE_DBPASS="475bd45587c7b7ebea74"
+ logtend keystone
+ area=keystone
+ echo keystone
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=keystone
+ date +%s
+ stamp=1557518844
+ date
+ date=Fri May 10 14:07:24 MDT 2019
+ eval tss=$LOGTIMESTART_keystone
+ tss=1557518758
+ expr 1557518844 - 1557518758
+ tsres=86
+ perl -e print 86 / 60.0 . "\n"
+ resmin=1.43333333333333
+ echo END keystone 1557518844 Fri May 10 14:07:24 MDT 2019
+ echo TOTAL keystone 86 1.43333333333333
+ echo export OS_TENANT_NAME=admin
+ echo export OS_USERNAME=adminapi
+ echo export OS_PASSWORD=92748256c1e798f84f04
+ echo export OS_AUTH_URL=http://controller:5000/v2.0
+ echo OS_TENANT_NAME="admin"
+ echo OS_USERNAME="adminapi"
+ echo OS_PASSWORD="92748256c1e798f84f04"
+ echo OS_AUTH_URL="http://controller:5000/v2.0"
+ [ x3 = x3 ]
+ echo OS_IDENTITY_API_VERSION=3
+ [ x3 = x3 ]
+ [ 18 -lt 13 ]
+ echo export OS_PROJECT_DOMAIN_NAME=default
+ echo export OS_USER_DOMAIN_NAME=default
+ echo export OS_PROJECT_NAME=admin
+ echo export OS_TENANT_NAME=admin
+ echo export OS_USERNAME=adminapi
+ echo export OS_PASSWORD=92748256c1e798f84f04
+ echo export OS_AUTH_URL=http://controller:5000/v3
+ [ x3 = x3 ]
+ echo export OS_IDENTITY_API_VERSION=3
+ [ 18 -ge 14 ]
+ echo export OS_IMAGE_API_VERSION=2
+ [ 18 -ge 17 ]
+ echo export OS_AUTH_TYPE=password
+ [ x3 = x3 ]
+ [ 18 -lt 13 ]
+ echo OS_PROJECT_DOMAIN_NAME="default"
+ echo OS_USER_DOMAIN_NAME="default"
+ echo OS_PROJECT_NAME="admin"
+ echo OS_TENANT_NAME="admin"
+ echo OS_USERNAME="adminapi"
+ echo OS_PASSWORD="92748256c1e798f84f04"
+ echo OS_AUTH_URL="http://controller:5000/v3"
+ [ x3 = x3 ]
+ echo OS_IDENTITY_API_VERSION=3
+ [ 18 -ge 14 ]
+ echo OS_IMAGE_API_VERSION=2
+ [ 18 -ge 17 ]
+ echo OS_AUTH_TYPE='password'
+ [ 18 -eq 10 ]
+ [ x3 = x3 ]
+ [ 18 -lt 13 ]
+ export OS_PROJECT_DOMAIN_NAME=default
+ export OS_USER_DOMAIN_NAME=default
+ export OS_PROJECT_NAME=admin
+ export OS_TENANT_NAME=admin
+ export OS_USERNAME=adminapi
+ export OS_PASSWORD=92748256c1e798f84f04
+ export OS_AUTH_URL=http://controller:5000/v3
+ [ x3 = x3 ]
+ export OS_IDENTITY_API_VERSION=3
+ ln -sf /root/setup/admin-openrc-newcli.sh /root/setup/admin-openrc.sh
+ ln -sf /root/setup/admin-openrc-newcli.py /root/setup/admin-openrc.py
+ [ -z  ]
+ logtstart glance
+ area=glance
+ echo glance
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=glance
+ date +%s
+ stamp=1557518844
+ date
+ date=Fri May 10 14:07:24 MDT 2019
+ eval LOGTIMESTART_glance=1557518844
+ LOGTIMESTART_glance=1557518844
+ echo START glance 1557518844 Fri May 10 14:07:24 MDT 2019
+ openssl rand -hex 10
+ GLANCE_DBPASS=90422ef6606c271c3df3
+ openssl rand -hex 10
+ GLANCE_PASS=8730282cd9b68ed94645
+ echo create database glance
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on glance.* to 'glance'@'localhost' identified by '90422ef6606c271c3df3'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on glance.* to 'glance'@'%' identified by '90422ef6606c271c3df3'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -lt 11 ]
+ __openstack user create --domain default --password 8730282cd9b68ed94645 glance
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 8730282cd9b68ed94645 glance
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | d595abd364094d01ace4697ceaf28c1c |
| name                | glance                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user glance --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user glance --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name glance --description OpenStack Image Service image
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name glance --description OpenStack Image Service image
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Image Service          |
| enabled     | True                             |
| id          | 94046f68f21d4821b73c4017df93b458 |
| name        | glance                           |
| type        | image                            |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne image public http://controller:9292
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne image public http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | f46a61e2f53a470a8d8d2e85b48eb067 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 94046f68f21d4821b73c4017df93b458 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne image internal http://controller:9292
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne image internal http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 1dc171364b1a4bdda40ced981f11af53 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 94046f68f21d4821b73c4017df93b458 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne image admin http://controller:9292
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne image admin http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | dec0f05209c84b8f878a872efb245f00 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 94046f68f21d4821b73c4017df93b458 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages glance python-glanceclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed glance python-glanceclient
+ retval=1
+ [ ! -z glance ]
+ dpkg -s glance
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-glanceclient ]
+ dpkg -s python-glanceclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ crudini --set /etc/glance/glance-api.conf database connection mysql+pymysql://glance:90422ef6606c271c3df3@controller/glance
+ crudini --set /etc/glance/glance-api.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/glance/glance-api.conf DEFAULT verbose False
+ crudini --set /etc/glance/glance-api.conf DEFAULT debug False
+ crudini --set /etc/glance/glance-api.conf paste_deploy flavor keystone
+ [ 18 -eq 10 ]
+ [ 18 -le 18 ]
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken auth_type password
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken project_name service
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken username glance
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken password 8730282cd9b68ed94645
+ crudini --set /etc/glance/glance-api.conf glance_store default_store file
+ crudini --set /etc/glance/glance-api.conf glance_store filesystem_store_datadir /var/lib/glance/images/
+ [ 18 -ge 14 ]
+ crudini --set /etc/glance/glance-api.conf glance_store stores file,http
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/glance/glance-api.conf keystone_authtoken memcached_servers controller:11211
+ crudini --set /etc/glance/glance-registry.conf database connection mysql+pymysql://glance:90422ef6606c271c3df3@controller/glance
+ crudini --set /etc/glance/glance-registry.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/glance/glance-registry.conf DEFAULT verbose False
+ crudini --set /etc/glance/glance-registry.conf DEFAULT debug False
+ crudini --set /etc/glance/glance-registry.conf paste_deploy flavor keystone
+ [ 18 -eq 10 ]
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken auth_type password
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken project_name service
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken username glance
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken password 8730282cd9b68ed94645
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/glance/glance-registry.conf keystone_authtoken memcached_servers controller:11211
+ su -s /bin/sh -c /usr/bin/glance-manage db_sync glance
/usr/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py:1352: OsloDBDeprecationWarning: EngineFacade is deprecated; please use oslo_db.sqlalchemy.enginefacade
  expire_on_commit=expire_on_commit, _conf=conf)
2019-05-10 14:07:36.227 61466 INFO alembic.runtime.migration [-] Context impl MySQLImpl.[00m
2019-05-10 14:07:36.227 61466 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.[00m
2019-05-10 14:07:36.259 61466 INFO alembic.runtime.migration [-] Context impl MySQLImpl.[00m
2019-05-10 14:07:36.259 61466 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.[00m
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> liberty, liberty initial
INFO  [alembic.runtime.migration] Running upgrade liberty -> mitaka01, add index on created_at and updated_at columns of 'images' table
INFO  [alembic.runtime.migration] Running upgrade mitaka01 -> mitaka02, update metadef os_nova_server
INFO  [alembic.runtime.migration] Running upgrade mitaka02 -> ocata_expand01, add visibility to images
INFO  [alembic.runtime.migration] Running upgrade ocata_expand01 -> pike_expand01, empty expand for symmetry with pike_contract01
INFO  [alembic.runtime.migration] Running upgrade pike_expand01 -> queens_expand01
INFO  [alembic.runtime.migration] Running upgrade queens_expand01 -> rocky_expand01, add os_hidden column to images table
INFO  [alembic.runtime.migration] Running upgrade rocky_expand01 -> rocky_expand02, add os_hash_algo and os_hash_value columns to images table
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade mitaka02 -> ocata_contract01, remove is_public from images
INFO  [alembic.runtime.migration] Running upgrade ocata_contract01 -> pike_contract01, drop glare artifacts tables
INFO  [alembic.runtime.migration] Running upgrade pike_contract01 -> queens_contract01
INFO  [alembic.runtime.migration] Running upgrade queens_contract01 -> rocky_contract01
INFO  [alembic.runtime.migration] Running upgrade rocky_contract01 -> rocky_contract02
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
Upgraded database to: rocky_expand02, current revision(s): rocky_expand02
Database migration is up to date. No migration needed.
Upgraded database to: rocky_contract02, current revision(s): rocky_contract02
Database is synced successfully.
+ [ -n 32 -a ! 32 = 0 ]
+ service_stop glance-registry
+ service=glance-registry
+ [ 1 -eq 0 ]
+ systemctl stop glance-registry
+ service_stop glance-api
+ service=glance-api
+ [ 1 -eq 0 ]
+ systemctl stop glance-api
+ /local/repository/setup-extra-space.sh
+ id -u
+ EUID=0
+ [ 0 -ne 0 ]
+ dirname /local/repository/setup-extra-space.sh
+ . /local/repository/setup-lib.sh
+ dirname /local/repository/setup-extra-space.sh
+ DIRNAME=/local/repository
+ OURDIR=/root/setup
+ SETTINGS=/root/setup/settings
+ LOCALSETTINGS=/root/setup/settings.local
+ TOPOMAP=/root/setup/topomap
+ BOOTDIR=/var/emulab/boot
+ TMCC=/usr/local/etc/emulab/tmcc
+ TIMELOGFILE=/root/setup/setup-time.log
+ FIRSTTIME=0
+ [ ! -f /root/setup/setup-lib-first ]
+ [ 0 -ne 0 ]
+ mkdir -p /root/setup
+ touch /root/setup/settings
+ touch /root/setup/settings.local
+ cd /root/setup
+ LOCKFILE=lockfile-create --retry 65535 
+ RMLOCKFILE=lockfile-remove 
+ PSWDGEN=openssl rand -hex 10
+ SSH=ssh -o StrictHostKeyChecking=no
+ SCP=scp -p -o StrictHostKeyChecking=no
+ CONTROLLER=ctl
+ NETWORKMANAGER=nm
+ STORAGEHOST=ctl
+ SHAREHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=
+ BAREMETALNODES=
+ BLOCKNODES=
+ OBJECTNODES=
+ DATALAN=lan-1
+ MGMTLAN=lan-2
+ BLOCKLAN=
+ OBJECTLAN=
+ DATATUNNELS=1
+ DATAFLATLANS=lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATAOTHERLANS=
+ USE_EXISTING_IPS=1
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=0
+ DO_APT_UPDATE=1
+ UBUNTUMIRRORHOST=
+ UBUNTUMIRRORPATH=
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DO_UBUNTU_CLOUDARCHIVE=0
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ BUILD_AARCH64_FROM_CORE=0
+ DISABLE_SECURITY_GROUPS=0
+ ENABLE_HOST_PASSTHROUGH=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ SUPPORT_DYNAMIC_NODES=0
+ KEYSTONEAPIVERSION=
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ GLANCE_LV_SIZE=32
+ SWIFT_LV_SIZE=4
+ CEILOMETER_USE_WSGI=0
+ QUOTASOFF=1
+ KEYSTONEUSEMEMCACHE=0
+ KEYSTONEUSEWSGI=
+ COMPUTE_EXTRA_NOVA_DISK_SPACE=1
+ ML2PLUGIN=openvswitch
+ MANILADRIVER=generic
+ EXTRAIMAGEURLS=
+ LINUXBRIDGE_STATIC=0
+ USE_DESIGNATE_AS_RESOLVER=1
+ USE_NEUTRON_LBAAS=1
+ ENABLE_OPENSTACK_SLOTHD=0
+ OSRELEASE=
+ ADMIN_API=adminapi
+ openssl rand -hex 10
+ ADMIN_API_PASS=287f3485c837b0bc14de
+ ADMIN=admin
+ ADMIN_PASS=
+ ADMIN_PASS_HASH=
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ [ x = x ]
+ UPDATING=0
+ NEWNODELIST=
+ OLDNODELIST=
+ [ ! -e /root/setup/apt-configured ]
+ export DEBIAN_FRONTEND=noninteractive
+ DPKGOPTS=
+ APTGETINSTALLOPTS=-y
+ APTGETINSTALL=apt-get  install -y
+ [ 1 -eq 0 ]
+ grep GENIUSER /root/setup/settings
GENIUSER=1
+ [ ! 0 -eq 0 ]
+ grep GENIUSER=1 /root/setup/settings
GENIUSER=1
+ [ 0 -eq 0 ]
+ GENIUSER=1
+ [ 1 -eq 1 ]
+ dpkg -s python-m2crypto
+ [ ! 0 -eq 0 ]
+ [ ! -e /root/setup/geni.key ]
+ HAS_GENI_KEY=1
+ [ ! -e /root/setup/geni.certificate ]
+ HAS_GENI_CERT=1
+ [ ! -e /root/.ssl/encrypted.pem ]
+ [ ! -e /root/setup/manifests.xml -o 0 -ne 0 ]
+ [ ! -e /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/decrypted_admin_pass -a -s /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/parameters ]
+ . /root/setup/parameters
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ COMPUTENODES=compute-1 
+ DATALANS=flat-lan-1
+ DATAFLATLANS=flat-lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATATUNNELS=1
+ MGMTLAN=
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=1
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ DO_APT_UPDATE=1
+ ADMIN_PASS_HASH=
+ ENABLE_HOST_PASSTHROUGH=1
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DISABLE_SECURITY_GROUPS=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ USE_NEUTRON_LBAAS=1
+ CEILOMETER_USE_MONGODB=0
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ KEYSTONEUSEMEMCACHE=0
+ QUOTASOFF=1
+ ML2PLUGIN=openvswitch
+ USE_DESIGNATE_AS_RESOLVER=1
+ EXTRAIMAGEURLS=
+ OSRELEASE=rocky
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ ADMIN_PASS=9da6fece4881
+ ADMIN_PASS_HASH=$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA.
+ [ x$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA. = x ]
+ cat /var/emulab/boot/creator
+ CREATOR=tboudw0
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ cat /var/emulab/boot/nickname
+ cut -d . -f 1
+ NODEID=controller
+ cat /var/emulab/boot/nodeid
+ PNODEID=clnode234
+ cat /var/emulab/boot/nickname
+ cut -d . -f 2
+ EEID=tboudwin-QV52139
+ cat /var/emulab/boot/nickname
+ cut -d . -f 3
+ EPID=pdc-edu-lab-PG0
+ cat /var/emulab/boot/mydomain
+ OURDOMAIN=clemson.cloudlab.us
+ cat /var/emulab/boot/nickname
+ NFQDN=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ cat /var/emulab/boot/nodeid
+ PFQDN=clnode234.clemson.cloudlab.us
+ cat /var/emulab/boot/myip
+ MYIP=130.127.133.243
+ cat /var/emulab/boot/controlif
+ EXTERNAL_NETWORK_INTERFACE=br-ex
+ cat /var/emulab/boot/nickname
+ cut -f1 -d.
+ HOSTNAME=controller
+ uname -m
+ ARCH=x86_64
+ dpkg-query -S /sbin/init
+ grep -q systemd
+ expr 0 = 0
+ HAVE_SYSTEMD=1
+ OSJUNO=10
+ OSKILO=11
+ OSLIBERTY=12
+ OSMITAKA=13
+ OSNEWTON=14
+ OSOCATA=15
+ OSPIKE=16
+ OSQUEENS=17
+ OSROCKY=18
+ . /etc/lsb-release
+ DISTRIB_ID=Ubuntu
+ DISTRIB_RELEASE=18.04
+ DISTRIB_CODENAME=bionic
+ DISTRIB_DESCRIPTION=Ubuntu 18.04.2 LTS
+ [ ! xrocky = x ]
+ OSCODENAME=rocky
+ [ rocky = juno ]
+ [ rocky = kilo ]
+ [ rocky = liberty ]
+ [ rocky = mitaka ]
+ [ rocky = newton ]
+ [ rocky = ocata ]
+ [ rocky = pike ]
+ [ rocky = queens ]
+ [ rocky = rocky ]
+ OSVERSION=18
+ echo Ubuntu 18.04.2 LTS
+ grep -qi LTS
+ [ 0 -eq 0 ]
+ DO_UBUNTU_CLOUDARCHIVE=1
+ echo 18.04
+ cut -d. -f1
+ DISTRIB_MAJOR=18
+ [ 18 -ge 13 ]
+ KEYSTONEUSEMEMCACHE=1
+ [ 18 -eq 10 ]
+ REGION=RegionOne
+ [ 18 -ge 17 ]
+ KADMINPORT=5000
+ [ x = x3 ]
+ [  != 2 -a 18 -ge 12 ]
+ KAPISTR=v3
+ KEYSTONEAPIVERSION=3
+ NAPISTR=v2
+ [ 18 -ge 13 ]
+ NAPISTR=v2.1
+ [ x = x -a 18 -ge 11 ]
+ KEYSTONEUSEWSGI=1
+ [ 18 -ge 13 ]
+ PROJECT_DOMAIN_PARAM=project_domain_name
+ USER_DOMAIN_PARAM=user_domain_name
+ AUTH_TYPE_PARAM=auth_type
+ [ 18 -ge 14 ]
+ DBDPACKAGE=python-pymysql
+ DBDSTRING=mysql+pymysql
+ [ 1 -eq 1 ]
+ geni-get slice_email
+ SWAPPER_EMAIL=tboudwin@wcupa.edu
+ [ 1 -eq 1 ]
+ cat /root/setup/manifests.0.xml
+ + perl -e $found = 0; while (<STDIN>) { if ($_ =~ /\<[\d\w:]*routable_pool [^\>\<]*\/>/) { print STDERR "DEBUG: found empty pool: $_\n"; next; } if ($_ =~ /\<[\d\w:]*routable_pool [^\>]*client_id=['"]controller['"]/) { $found = 1; print STDERR "DEBUG: found: $_\n" } if ($found) { while ($_ =~ m/\<emulab:ipv4 address="([\d.]+)\" netmask=\"([\d\.]+)\"/g) { print "$1\n"; } } if ($found && $_ =~ /routable_pool\>/) { print STDERR "DEBUG: end found: $_\n"; $found = 0; } }xargs

DEBUG: found:   <emulab:routable_pool client_id="controller" count="4" type="any" component_manager_id="urn:publicid:IDN+clemson.cloudlab.us+authority+cm">

DEBUG: end found:   <emulab:ipv4 address="130.127.132.210" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.226" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.238" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.239" netmask="255.255.252.0"/></emulab:routable_pool>

+ PUBLICADDRS=130.127.132.210 130.127.132.226 130.127.132.238 130.127.132.239
+ PUBLICCOUNT=0
+ expr 0 + 1
+ PUBLICCOUNT=1
+ expr 1 + 1
+ PUBLICCOUNT=2
+ expr 2 + 1
+ PUBLICCOUNT=3
+ expr 3 + 1
+ PUBLICCOUNT=4
+ [ ! -f /root/setup/topomap -o 0 -ne 0 ]
+ [ ! -z  ]
+ [ ( -s /root/setup/manifests.xml ) -a ( ! ( -s /root/setup/fqdn.map ) ) ]
+ [ ! -s /root/setup/fqdn.map ]
+ cat /root/setup/fqdn.map
+ + cut -f1
xargs
+ NODES=controller compute-1
+ cat /root/setup/fqdn.map
+ cut -f2
+ xargs
+ FQDNS=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ [ -z compute-1  ]
+ OTHERNODES=
+ [ controller = controller ]
+ continue
+ [ compute-1 = controller ]
+ OTHERNODES= compute-1
+ grep CONTROLLER /root/setup/settings
CONTROLLER="controller"
+ [ ! 0 = 0 ]
+ [ 0 -ne 0 ]
+ grep MIRRORSETUP /root/setup/settings
MIRRORSETUP=1
+ [ ! 0 -eq 0 ]
+ [ ! -f /root/setup/apt-updated -a 1 = 1 ]
+ [ ! -f /root/setup/cloudarchive-added -a 1 = 1 ]
+ [ ! -f /root/setup/apt-dist-upgraded -a 1 = 1 ]
+ maybe_install_packages crudini
+ [ ! 0 -eq 0 ]
+ are_packages_installed crudini
+ retval=1
+ [ ! -z crudini ]
+ dpkg -s crudini
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ ! -f /root/setup/nextsparesubnet ]
+ cat /root/setup/nextsparesubnet
+ NEXTSPARESUBNET=253
+ [ ! -f /root/setup/mgmt-hosts -o 0 -ne 0 ]
+ [ 1 -gt 0 ]
+ i=0
+ [ 0 -lt 1 ]
+ [ -f /root/setup/ipinfo.tun0 ]
+ expr 0 + 1
+ i=1
+ continue
+ [ 1 -lt 1 ]
+ echo 253
+ echo 253
+ [ 0 -gt 0 ]
+ [ ! -e /root/setup/info.mgmt ]
+ . /root/setup/info.mgmt
+ MGMTIP=192.168.0.1
+ MGMTNETMASK=255.255.0.0
+ MGMTPREFIX=16
+ MGMTVLAN=0
+ MGMTMAC=
+ MGMT_NETWORK_INTERFACE=tun0
+ MGMTVLANDEV=
+ MGMTVLANTAG=
+ [ -e /root/setup/info.flat-lan-1 ]
+ continue
+ [ ! -f /root/setup/neutron.vars ]
+ [ ! -f /etc/emulab/bossnode -a 18 -ge 14 -a 1 = 1 ]
+ [ 0 -ne 0 ]
+ which wget
+ GETTER=/usr/bin/wget
+ [ -n /usr/bin/wget ]
+ GETTEROUT=/usr/bin/wget --remote-encoding=unix -c -O
+ GETTER=/usr/bin/wget --remote-encoding=unix -c -N
+ GETTERLOGARG=-o
+ [ 0 -ne 0 ]
+ [ -f /root/setup/extra-space-done ]
+ logtstart extra-space
+ area=extra-space
+ echo extra-space
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=extra_space
+ date +%s
+ stamp=1557518873
+ date
+ date=Fri May 10 14:07:53 MDT 2019
+ eval LOGTIMESTART_extra_space=1557518873
+ LOGTIMESTART_extra_space=1557518873
+ echo START extra-space 1557518873 Fri May 10 14:07:53 MDT 2019
+ [ -f /root/setup/settings ]
+ . /root/setup/settings
+ GENIUSER=1
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ STORAGEHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=compute-1 
+ MIRRORSETUP=1
+ DB_ROOT_PASS=ad12065d4a6fcf049d20
+ RABBIT_USER=openstack
+ RABBIT_PASS=0375d10f3c80e2774768
+ RABBIT_URL=rabbit://openstack:0375d10f3c80e2774768@controller
+ MEMCACHE_DONE=1
+ ETCD_DONE=1
+ ADMIN_API=adminapi
+ ADMIN_API_PASS=92748256c1e798f84f04
+ KEYSTONE_DBPASS=475bd45587c7b7ebea74
+ [ -f /root/setup/settings.local ]
+ . /root/setup/settings.local
+ STORAGEDIR=/storage
+ VGNAME=openstack-volumes
+ uname -m
+ ARCH=x86_64
+ maybe_install_packages lvm2
+ [ ! 0 -eq 0 ]
+ are_packages_installed lvm2
+ retval=1
+ [ ! -z lvm2 ]
+ dpkg -s lvm2
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -ge 15 ]
+ maybe_install_packages thin-provisioning-tools
+ [ ! 0 -eq 0 ]
+ are_packages_installed thin-provisioning-tools
+ retval=1
+ [ ! -z thin-provisioning-tools ]
+ dpkg -s thin-provisioning-tools
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ mkdir -p /storage
+ echo STORAGEDIR=/storage
+ vgdisplay emulab
File descriptor 3 (/local/repository/setup-extra-space.sh) leaked on vgdisplay invocation. Parent PID 61485: /bin/sh
  Volume group "emulab" not found
  Cannot process volume group emulab
+ [ 5 -eq 0 ]
+ [ -z  ]
+ LVM=1
+ DONE=0
+ MKEXTRAFS_ARGS=-l -v openstack-volumes -m util -z 1024
+ [ x86_64 = aarch64 -o x86_64 = ppc64le ]
+ lsblk -n -P -b -o NAME,FSTYPE,MOUNTPOINT,PARTTYPE,PARTUUID,TYPE,PKNAME,SIZE
+ perl -e my %devs = (); while (<STDIN>) { $_ =~ s/([A-Z0-9a-z]+=)/;\$$1/g; eval "$_"; if (!($TYPE eq "disk" || $TYPE eq "part")) { next; }; if (exists($devs{$PKNAME})) { delete $devs{$PKNAME}; } if ($FSTYPE eq "" && $MOUNTPOINT eq "" && ($PARTTYPE eq "" || $PARTTYPE eq "0x0") && (int($SIZE) > 3221225472)) { $devs{$NAME} = "/dev/$NAME"; } }; print join(" ",values(%devs))."\n"
+ cat /tmp/devs
+ DEVS=/dev/sda4 /dev/sdb
+ [ -n /dev/sda4 /dev/sdb ]
+ pvcreate /dev/sda4 /dev/sdb
File descriptor 3 (/local/repository/setup-extra-space.sh) leaked on pvcreate invocation. Parent PID 61485: /bin/sh
  Physical volume "/dev/sda4" successfully created.
  Physical volume "/dev/sdb" successfully created.
+ vgcreate openstack-volumes /dev/sda4 /dev/sdb
File descriptor 3 (/local/repository/setup-extra-space.sh) leaked on vgcreate invocation. Parent PID 61485: /bin/sh
  Volume group "openstack-volumes" successfully created
+ [ ! 0 -eq 0 ]
+ DONE=1
+ [ 1 -eq 0 ]
+ vgs -o vg_size --noheadings --units G openstack-volumes
+ sed -ne s/ *\([0-9]*\)[0-9\.]*G/\1/p
File descriptor 3 (/local/repository/setup-extra-space.sh) leaked on vgs invocation. Parent PID 61581: /bin/sh
+ VGTOTAL=1976
+ echo VGNAME=openstack-volumes
+ echo VGTOTAL=1976
+ echo LVM=1
+ [ 1 -eq 1 ]
+ expr 1976 - 1
+ vgt=1975
+ [ controller = ctl ]
+ [ controller = controller ]
+ expr 1975 - 32
+ vgt=1943
+ [ 1943 -lt 20 ]
+ perl -e print 0.75 * 1943;
+ CINDER_LV_SIZE=1457.25
+ echo SWIFT_LV_SIZE=4
+ echo GLANCE_LV_SIZE=32
+ echo CINDER_LV_SIZE=1457.25
+ logtend extra-space
+ area=extra-space
+ echo extra-space
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=extra_space
+ date +%s
+ stamp=1557518874
+ date
+ date=Fri May 10 14:07:54 MDT 2019
+ eval tss=$LOGTIMESTART_extra_space
+ tss=1557518873
+ expr 1557518874 - 1557518873
+ tsres=1
+ perl -e print 1 / 60.0 . "\n"
+ resmin=0.0166666666666667
+ echo END extra-space 1557518874 Fri May 10 14:07:54 MDT 2019
+ echo TOTAL extra-space 1 0.0166666666666667
+ touch /root/setup/extra-space-done
+ . /root/setup/settings.local
+ STORAGEDIR=/storage
+ VGNAME=openstack-volumes
+ VGTOTAL=1976
+ LVM=1
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ CINDER_LV_SIZE=1457.25
+ mkdir -p /storage/glance
+ chown glance:glance /storage/glance
+ chmod 770 /storage/glance
+ [ 1 = 1 ]
+ lvcreate -L 32G -n glance openstack-volumes
  Logical volume "glance" created.
+ [ -f /sbin/mkfs.ext4 ]
+ ftype=ext4
+ mkfs.ext4 /dev/openstack-volumes/glance
mke2fs 1.44.1 (24-Mar-2018)
Creating filesystem with 8388608 4k blocks and 2097152 inodes
Filesystem UUID: 556c210d-f44c-459f-b1ae-ae0e215baaf1
Superblock backups stored on blocks: 
	32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 
	4096000, 7962624

Allocating group tables:   0/256       done                            
Writing inode tables:   0/256       done                            
Creating journal (65536 blocks): done
Writing superblocks and filesystem accounting information:   0/256       done

+ echo /dev/openstack-volumes/glance /storage/glance none defaults 0 0
+ mount /dev/openstack-volumes/glance /storage/glance
+ rsync -avz /var/lib/glance/ /storage/glance/
sending incremental file list
./
.gnupg/
.gnupg/private-keys-v1.d/
image-cache/
image-cache/incomplete/
image-cache/invalid/
image-cache/queue/
images/

sent 276 bytes  received 47 bytes  215.33 bytes/sec
total size is 0  speedup is 0.00
+ rm -rf /var/lib/glance/image-cache /var/lib/glance/images
+ mount -o bind /storage/glance /var/lib/glance
+ echo /storage/glance /var/lib/glance none defaults,bind 0 0
+ service_restart glance-registry
+ service=glance-registry
+ [ 1 -eq 0 ]
+ systemctl restart glance-registry
+ service_enable glance-registry
+ service=glance-registry
+ [ 1 -eq 0 ]
+ systemctl enable glance-registry
Synchronizing state of glance-registry.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable glance-registry
+ service_restart glance-api
+ service=glance-api
+ [ 1 -eq 0 ]
+ systemctl restart glance-api
+ service_enable glance-api
+ service=glance-api
+ [ 1 -eq 0 ]
+ systemctl enable glance-api
Synchronizing state of glance-api.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable glance-api
+ rm -f /var/lib/glance/glance.sqlite
+ echo GLANCE_DBPASS="90422ef6606c271c3df3"
+ echo GLANCE_PASS="8730282cd9b68ed94645"
+ logtend glance
+ area=glance
+ echo glance
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=glance
+ date +%s
+ stamp=1557518878
+ date
+ date=Fri May 10 14:07:58 MDT 2019
+ eval tss=$LOGTIMESTART_glance
+ tss=1557518844
+ expr 1557518878 - 1557518844
+ tsres=34
+ perl -e print 34 / 60.0 . "\n"
+ resmin=0.566666666666667
+ echo END glance 1557518878 Fri May 10 14:07:58 MDT 2019
+ echo TOTAL glance 34 0.566666666666667
+ [ -z  ]
+ logtstart nova
+ area=nova
+ echo nova
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=nova
+ date +%s
+ stamp=1557518878
+ date
+ date=Fri May 10 14:07:58 MDT 2019
+ eval LOGTIMESTART_nova=1557518878
+ LOGTIMESTART_nova=1557518878
+ echo START nova 1557518878 Fri May 10 14:07:58 MDT 2019
+ openssl rand -hex 10
+ NOVA_DBPASS=8f182a0cc87fc8fe28e1
+ openssl rand -hex 10
+ NOVA_PASS=70f8743910a95e3a54fe
+ maybe_install_packages nova-api
+ [ ! 0 -eq 0 ]
+ are_packages_installed nova-api
+ retval=1
+ [ ! -z nova-api ]
+ dpkg -s nova-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ + echo create database nova
mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on nova.* to 'nova'@'localhost' identified by '8f182a0cc87fc8fe28e1'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on nova.* to 'nova'@'%' identified by '8f182a0cc87fc8fe28e1'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -ge 13 ]
+ echo create database nova_api
+ mysql -u root --password=ad12065d4a6fcf049d20
+ + echo grant all privileges on nova_api.* to 'nova'@'localhost' identified by '8f182a0cc87fc8fe28e1'
mysql -u root --password=ad12065d4a6fcf049d20
+ + echo grant all privileges on nova_api.* to 'nova'@'%' identified by '8f182a0cc87fc8fe28e1'
mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -ge 15 ]
+ echo create database nova_cell0
+ mysql -u root --password=ad12065d4a6fcf049d20
+ + echo grant all privileges on nova_cell0.* to 'nova'@'localhost' identified by '8f182a0cc87fc8fe28e1'
mysql -u root --password=ad12065d4a6fcf049d20
+ + echo grant all privileges on nova_cell0.* to 'nova'@'%' identified by '8f182a0cc87fc8fe28e1'
mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -ge 18 ]
+ openssl rand -hex 10
+ PLACEMENT_DBPASS=183a130e6978d3eefbd9
+ echo create database placement
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on placement.* to 'placement'@'localhost' identified by '183a130e6978d3eefbd9'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on placement.* to 'placement'@'%' identified by '183a130e6978d3eefbd9'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -eq 10 ]
+ __openstack user create --domain default --password 70f8743910a95e3a54fe nova
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 70f8743910a95e3a54fe nova
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 0c40a4752cb04157a7b20ea6776558b7 |
| name                | nova                             |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user nova --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user nova --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name nova --description OpenStack Compute Service compute
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name nova --description OpenStack Compute Service compute
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Compute Service        |
| enabled     | True                             |
| id          | cf74815a7e28453fb6ddadcccafb9a46 |
| name        | nova                             |
| type        | compute                          |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ [ 18 -lt 14 ]
+ __openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | eec784e05f074f1092b5e6c1055849a3 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | cf74815a7e28453fb6ddadcccafb9a46 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | a98d3550076c4b59a67512c330395b16 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | cf74815a7e28453fb6ddadcccafb9a46 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | d18e7a31ea6e4eda91f96eb0b42dc919 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | cf74815a7e28453fb6ddadcccafb9a46 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 18 -ge 15 ]
+ openssl rand -hex 10
+ PLACEMENT_PASS=c650059292e41b9adf49
+ __openstack user create --domain default --password c650059292e41b9adf49 placement
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password c650059292e41b9adf49 placement
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 6a2ea4c09c4246aaa7d36201669015cc |
| name                | placement                        |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user placement --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user placement --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name placement --description OpenStack Placement API placement
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name placement --description OpenStack Placement API placement
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Placement API          |
| enabled     | True                             |
| id          | 5d9173edaae54e1d89fbba6437a1fbe5 |
| name        | placement                        |
| type        | placement                        |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ [ 18 -lt 14 ]
+ __openstack endpoint create --region RegionOne placement public http://controller:8778
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne placement public http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 8bed89238ffc4642966bb6da1db0c71b |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 5d9173edaae54e1d89fbba6437a1fbe5 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne placement internal http://controller:8778
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne placement internal http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | d857671ffe834b768f0999ca97e3da80 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 5d9173edaae54e1d89fbba6437a1fbe5 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne placement admin http://controller:8778
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne placement admin http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 1aabc754938b4d29a6655263d7695922 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 5d9173edaae54e1d89fbba6437a1fbe5 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages nova-api nova-conductor nova-consoleauth nova-novncproxy nova-scheduler python-novaclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed nova-api nova-conductor nova-consoleauth nova-novncproxy nova-scheduler python-novaclient
+ retval=1
+ [ ! -z nova-api ]
+ dpkg -s nova-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z nova-conductor ]
+ dpkg -s nova-conductor
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z nova-consoleauth ]
+ dpkg -s nova-consoleauth
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z nova-novncproxy ]
+ dpkg -s nova-novncproxy
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z nova-scheduler ]
+ dpkg -s nova-scheduler
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-novaclient ]
+ dpkg -s python-novaclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -lt 17 ]
+ [ 18 -ge 15 ]
+ maybe_install_packages nova-placement-api
+ [ ! 0 -eq 0 ]
+ are_packages_installed nova-placement-api
+ retval=1
+ [ ! -z nova-placement-api ]
+ dpkg -s nova-placement-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 0 = 1 ]
+ [ 18 -ge 12 ]
+ crudini --set /etc/nova/nova.conf DEFAULT enabled_apis osapi_compute,metadata
+ crudini --set /etc/nova/nova.conf database connection mysql+pymysql://nova:8f182a0cc87fc8fe28e1@controller/nova
+ [ 18 -ge 13 ]
+ crudini --set /etc/nova/nova.conf api_database connection mysql+pymysql://nova:8f182a0cc87fc8fe28e1@controller/nova_api
+ [ 18 -ge 18 ]
+ crudini --set /etc/nova/nova.conf placement_database connection mysql+pymysql://placement:183a130e6978d3eefbd9@controller/placement
+ crudini --set /etc/nova/nova.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/nova/nova.conf DEFAULT my_ip 192.168.0.1
+ [ 18 -lt 13 ]
+ crudini --set /etc/nova/nova.conf glance api_servers http://controller:9292
+ crudini --set /etc/nova/nova.conf DEFAULT verbose False
+ crudini --set /etc/nova/nova.conf DEFAULT debug False
+ [ 18 -lt 11 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/nova/nova.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ [ 18 -lt 11 ]
+ crudini --set /etc/nova/nova.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/nova/nova.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/nova/nova.conf keystone_authtoken auth_type password
+ crudini --set /etc/nova/nova.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/nova/nova.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/nova/nova.conf keystone_authtoken project_name service
+ crudini --set /etc/nova/nova.conf keystone_authtoken username nova
+ crudini --set /etc/nova/nova.conf keystone_authtoken password 70f8743910a95e3a54fe
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/nova/nova.conf keystone_authtoken memcached_servers controller:11211
+ [ 18 -ge 13 ]
+ crudini --set /etc/nova/nova.conf DEFAULT use_neutron True
+ crudini --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver
+ [ 18 -lt 12 ]
+ [ 18 -lt 17 ]
+ crudini --set /etc/nova/nova.conf vnc enabled true
+ crudini --set /etc/nova/nova.conf vnc server_listen 192.168.0.1
+ crudini --set /etc/nova/nova.conf vnc server_proxyclient_address 192.168.0.1
+ [ 18 -eq 11 ]
+ [ 18 -ge 12 -a 18 -lt 15 ]
+ [ 18 -ge 15 ]
+ crudini --set /etc/nova/nova.conf filter_scheduler available_filters nova.scheduler.filters.all_filters
+ crudini --set /etc/nova/nova.conf filter_scheduler enabled_filters RetryFilter, AvailabilityZoneFilter, RamFilter, ComputeFilter, ComputeCapabilitiesFilter, ImagePropertiesFilter, ServerGroupAntiAffinityFilter, ServerGroupAffinityFilter
+ [ 18 -ge 11 ]
+ crudini --set /etc/nova/nova.conf oslo_concurrency lock_path /var/lib/nova/tmp
+ [ 0 = 1 ]
+ [ 18 -ge 12 ]
+ cat /proc/cpuinfo
+ grep -i processor.*:
+ wc -l
+ ncpus=64
+ crudini --set /etc/nova/nova.conf api_database max_overflow 64
+ crudini --set /etc/nova/nova.conf api_database max_pool_size 64
+ [ 18 -ge 15 ]
+ crudini --set /etc/nova/nova.conf placement os_region_name RegionOne
+ crudini --set /etc/nova/nova.conf placement auth_url http://controller:5000/v3
+ crudini --set /etc/nova/nova.conf placement auth_type password
+ crudini --set /etc/nova/nova.conf placement project_domain_name default
+ crudini --set /etc/nova/nova.conf placement user_domain_name default
+ crudini --set /etc/nova/nova.conf placement project_name service
+ crudini --set /etc/nova/nova.conf placement username placement
+ crudini --set /etc/nova/nova.conf placement password c650059292e41b9adf49
+ [ 18 -ge 13 ]
+ su -s /bin/sh -c nova-manage api_db sync nova
+ [ 18 -ge 15 ]
+ su -s /bin/sh -c nova-manage cell_v2 map_cell0 nova
+ su -s /bin/sh -c nova-manage cell_v2 create_cell --name=cell1 --verbose nova
558ff6d4-5722-44f2-9fac-d82ffa452731
+ su -s /bin/sh -c nova-manage db sync nova
/usr/lib/python2.7/dist-packages/pymysql/cursors.py:165: Warning: (1831, u'Duplicate index `block_device_mapping_instance_uuid_virtual_name_device_name_idx`. This is deprecated and will be disallowed in a future release.')
  result = self._query(query)
/usr/lib/python2.7/dist-packages/pymysql/cursors.py:165: Warning: (1831, u'Duplicate index `uniq_instances0uuid`. This is deprecated and will be disallowed in a future release.')
  result = self._query(query)
+ [ 18 -eq 16 ]
+ service_restart memcached
+ service=memcached
+ [ 1 -eq 0 ]
+ systemctl restart memcached
+ service_restart nova-api
+ service=nova-api
+ [ 1 -eq 0 ]
+ systemctl restart nova-api
+ service_enable nova-api
+ service=nova-api
+ [ 1 -eq 0 ]
+ systemctl enable nova-api
Synchronizing state of nova-api.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable nova-api
+ [ 18 -lt 17 ]
+ service_restart nova-consoleauth
+ service=nova-consoleauth
+ [ 1 -eq 0 ]
+ systemctl restart nova-consoleauth
+ service_enable nova-consoleauth
+ service=nova-consoleauth
+ [ 1 -eq 0 ]
+ systemctl enable nova-consoleauth
Synchronizing state of nova-consoleauth.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable nova-consoleauth
+ service_restart nova-scheduler
+ service=nova-scheduler
+ [ 1 -eq 0 ]
+ systemctl restart nova-scheduler
+ service_enable nova-scheduler
+ service=nova-scheduler
+ [ 1 -eq 0 ]
+ systemctl enable nova-scheduler
Synchronizing state of nova-scheduler.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable nova-scheduler
+ service_restart nova-conductor
+ service=nova-conductor
+ [ 1 -eq 0 ]
+ systemctl restart nova-conductor
+ service_enable nova-conductor
+ service=nova-conductor
+ [ 1 -eq 0 ]
+ systemctl enable nova-conductor
Synchronizing state of nova-conductor.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable nova-conductor
+ service_restart nova-novncproxy
+ service=nova-novncproxy
+ [ 1 -eq 0 ]
+ systemctl restart nova-novncproxy
+ service_enable nova-novncproxy
+ service=nova-novncproxy
+ [ 1 -eq 0 ]
+ systemctl enable nova-novncproxy
Synchronizing state of nova-novncproxy.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable nova-novncproxy
+ service_restart nova-serialproxy
+ service=nova-serialproxy
+ [ 1 -eq 0 ]
+ systemctl restart nova-serialproxy
Failed to restart nova-serialproxy.service: Unit nova-serialproxy.service not found.
+ service_enable nova-serialproxy
+ service=nova-serialproxy
+ [ 1 -eq 0 ]
+ systemctl enable nova-serialproxy
Failed to enable unit: Unit file nova-serialproxy.service does not exist.
+ [ 18 -ge 15 ]
+ a2ensite nova-placement-api.conf
Site nova-placement-api already enabled
+ service apache2 reload
+ rm -f /var/lib/nova/nova.sqlite
+ /usr/bin/openstack flavor show m1.tiny
No flavor with a name or ID of 'm1.tiny' exists.
+ [ ! 1 -eq 0 ]
+ __openstack flavor create m1.tiny --id 1 --ram 512 --disk 1 --vcpus 1 --public
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack flavor create m1.tiny --id 1 --ram 512 --disk 1 --vcpus 1 --public
+----------------------------+---------+
| Field                      | Value   |
+----------------------------+---------+
| OS-FLV-DISABLED:disabled   | False   |
| OS-FLV-EXT-DATA:ephemeral  | 0       |
| disk                       | 1       |
| id                         | 1       |
| name                       | m1.tiny |
| os-flavor-access:is_public | True    |
| properties                 |         |
| ram                        | 512     |
| rxtx_factor                | 1.0     |
| swap                       |         |
| vcpus                      | 1       |
+----------------------------+---------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ /usr/bin/openstack flavor show m1.small
No flavor with a name or ID of 'm1.small' exists.
+ [ ! 1 -eq 0 ]
+ __openstack flavor create m1.small --id 2 --ram 2048 --disk 20 --vcpus 1 --public
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack flavor create m1.small --id 2 --ram 2048 --disk 20 --vcpus 1 --public
+----------------------------+----------+
| Field                      | Value    |
+----------------------------+----------+
| OS-FLV-DISABLED:disabled   | False    |
| OS-FLV-EXT-DATA:ephemeral  | 0        |
| disk                       | 20       |
| id                         | 2        |
| name                       | m1.small |
| os-flavor-access:is_public | True     |
| properties                 |          |
| ram                        | 2048     |
| rxtx_factor                | 1.0      |
| swap                       |          |
| vcpus                      | 1        |
+----------------------------+----------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ /usr/bin/openstack flavor show m1.medium
No flavor with a name or ID of 'm1.medium' exists.
+ [ ! 1 -eq 0 ]
+ __openstack flavor create m1.medium --id 3 --ram 4096 --disk 40 --vcpus 2 --public
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack flavor create m1.medium --id 3 --ram 4096 --disk 40 --vcpus 2 --public
+----------------------------+-----------+
| Field                      | Value     |
+----------------------------+-----------+
| OS-FLV-DISABLED:disabled   | False     |
| OS-FLV-EXT-DATA:ephemeral  | 0         |
| disk                       | 40        |
| id                         | 3         |
| name                       | m1.medium |
| os-flavor-access:is_public | True      |
| properties                 |           |
| ram                        | 4096      |
| rxtx_factor                | 1.0       |
| swap                       |           |
| vcpus                      | 2         |
+----------------------------+-----------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ /usr/bin/openstack flavor show m1.large
No flavor with a name or ID of 'm1.large' exists.
+ [ ! 1 -eq 0 ]
+ __openstack flavor create m1.large --id 4 --ram 8192 --disk 80 --vcpus 4 --public
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack flavor create m1.large --id 4 --ram 8192 --disk 80 --vcpus 4 --public
+----------------------------+----------+
| Field                      | Value    |
+----------------------------+----------+
| OS-FLV-DISABLED:disabled   | False    |
| OS-FLV-EXT-DATA:ephemeral  | 0        |
| disk                       | 80       |
| id                         | 4        |
| name                       | m1.large |
| os-flavor-access:is_public | True     |
| properties                 |          |
| ram                        | 8192     |
| rxtx_factor                | 1.0      |
| swap                       |          |
| vcpus                      | 4        |
+----------------------------+----------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ /usr/bin/openstack flavor show m1.xlarge
No flavor with a name or ID of 'm1.xlarge' exists.
+ [ ! 1 -eq 0 ]
+ __openstack flavor create m1.xlarge --id 5 --ram 16384 --disk 160 --vcpus 8 --public
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack flavor create m1.xlarge --id 5 --ram 16384 --disk 160 --vcpus 8 --public
+----------------------------+-----------+
| Field                      | Value     |
+----------------------------+-----------+
| OS-FLV-DISABLED:disabled   | False     |
| OS-FLV-EXT-DATA:ephemeral  | 0         |
| disk                       | 160       |
| id                         | 5         |
| name                       | m1.xlarge |
| os-flavor-access:is_public | True      |
| properties                 |           |
| ram                        | 16384     |
| rxtx_factor                | 1.0       |
| swap                       |           |
| vcpus                      | 8         |
+----------------------------+-----------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ x86_64 = ppc64le ]
+ echo NOVA_DBPASS="8f182a0cc87fc8fe28e1"
+ echo PLACEMENT_DBPASS="183a130e6978d3eefbd9"
+ echo NOVA_PASS="70f8743910a95e3a54fe"
+ echo PLACEMENT_PASS="c650059292e41b9adf49"
+ logtend nova
+ area=nova
+ echo nova
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=nova
+ date +%s
+ stamp=1557519220
+ date
+ date=Fri May 10 14:13:40 MDT 2019
+ eval tss=$LOGTIMESTART_nova
+ tss=1557518878
+ expr 1557519220 - 1557518878
+ tsres=342
+ perl -e print 342 / 60.0 . "\n"
+ resmin=5.7
+ echo END nova 1557519220 Fri May 10 14:13:40 MDT 2019
+ echo TOTAL nova 342 5.7
+ PHOSTS=
+ mkdir -p /root/setup/pssh.setup-compute.stdout /root/setup/pssh.setup-compute.stderr
+ [ -z  ]
+ logtstart nova-computenodes
+ area=nova-computenodes
+ echo nova-computenodes
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=nova_computenodes
+ date +%s
+ stamp=1557519220
+ date
+ date=Fri May 10 14:13:40 MDT 2019
+ eval LOGTIMESTART_nova_computenodes=1557519220
+ LOGTIMESTART_nova_computenodes=1557519220
+ echo START nova-computenodes 1557519220 Fri May 10 14:13:40 MDT 2019
+ NOVA_COMPUTENODES_DONE=1
+ getfqdn compute-1
+ n=compute-1
+ cat /root/setup/fqdn.map
+ grep -E compute-1\s
+ cut -f2
+ fqdn=compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ echo compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ fqdn=compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ scp -o StrictHostKeyChecking=no /root/setup/settings admin-openrc.sh compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us:/root/setup
+ PHOSTS= -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ echo *** Setting up Cmopute service on nodes:  -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
*** Setting up Cmopute service on nodes:  -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ /usr/bin/parallel-ssh -t 0 -O StrictHostKeyChecking=no -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us -o /root/setup/pssh.setup-compute.stdout -e /root/setup/pssh.setup-compute.stderr /local/repository/setup-compute.sh
[1] 14:14:01 [SUCCESS] compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ touch /root/setup/compute-done-compute-1
+ [ 18 -ge 15 ]
+ su -s /bin/sh -c nova-manage cell_v2 discover_hosts --verbose nova
Found 2 cell mappings.
Skipping cell0 since it does not contain hosts.
Getting computes from cell 'cell1': 558ff6d4-5722-44f2-9fac-d82ffa452731
Found 0 unmapped computes in cell: 558ff6d4-5722-44f2-9fac-d82ffa452731
+ crudini --set /etc/nova/nova.conf scheduler discover_hosts_in_cells_interval 300
+ echo NOVA_COMPUTENODES_DONE="1"
+ logtend nova-computenodes
+ area=nova-computenodes
+ echo nova-computenodes
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=nova_computenodes
+ date +%s
+ stamp=1557519244
+ date
+ date=Fri May 10 14:14:04 MDT 2019
+ eval tss=$LOGTIMESTART_nova_computenodes
+ tss=1557519220
+ expr 1557519244 - 1557519220
+ tsres=24
+ perl -e print 24 / 60.0 . "\n"
+ resmin=0.4
+ echo END nova-computenodes 1557519244 Fri May 10 14:14:04 MDT 2019
+ echo TOTAL nova-computenodes 24 0.4
+ [ -z  ]
+ logtstart neutron
+ area=neutron
+ echo neutron
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=neutron
+ date +%s
+ stamp=1557519244
+ date
+ date=Fri May 10 14:14:04 MDT 2019
+ eval LOGTIMESTART_neutron=1557519244
+ LOGTIMESTART_neutron=1557519244
+ echo START neutron 1557519244 Fri May 10 14:14:04 MDT 2019
+ openssl rand -hex 10
+ NEUTRON_DBPASS=afeb2f23fd61fc63b2f7
+ openssl rand -hex 10
+ NEUTRON_PASS=398d7129a22f6c80b3c3
+ openssl rand -hex 10
+ NEUTRON_METADATA_SECRET=e49934e1536e9d8ba189
+ . /root/setup/neutron.vars
+ network_types=flat,gre,vxlan
+ flat_networks=external,flat-lan-1
+ bridge_mappings=bridge_mappings=external:br-ex,flat-lan-1:br-flat-lan-1
+ extra_mappings=
+ network_vlan_ranges=network_vlan_ranges=
+ gre_local_ip=local_ip = 10.11.10.1
+ enable_tunneling=enable_tunneling = True
+ tunnel_types=tunnel_types = gre
+ interface_driver=neutron.agent.linux.interface.OVSInterfaceDriver
+ fwdriver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
+ echo create database neutron
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on neutron.* to 'neutron'@'localhost' identified by 'afeb2f23fd61fc63b2f7'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on neutron.* to 'neutron'@'%' identified by 'afeb2f23fd61fc63b2f7'
+ [ 18 -eq 10 ]
+ __openstack user create --domain default --password 398d7129a22f6c80b3c3 neutron
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 398d7129a22f6c80b3c3 neutron
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 6cb4019637a74c5ab4277c791e272f4e |
| name                | neutron                          |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user neutron --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user neutron --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name neutron --description OpenStack Networking Service network
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name neutron --description OpenStack Networking Service network
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Networking Service     |
| enabled     | True                             |
| id          | a92c9c0799c64d2592d794f94dfcd74c |
| name        | neutron                          |
| type        | network                          |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne network public http://controller:9696
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne network public http://controller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 34e26766eba54380b2abe47bc3dc15a3 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | a92c9c0799c64d2592d794f94dfcd74c |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne network internal http://controller:9696
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne network internal http://controller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | b7436596d98a4008aec7a13f30ab6d2f |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | a92c9c0799c64d2592d794f94dfcd74c |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne network admin http://controller:9696
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne network admin http://controller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 82b6dadb7dc3431590fd8d77f9dc7366 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | a92c9c0799c64d2592d794f94dfcd74c |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages neutron-server neutron-plugin-ml2 python-neutronclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed neutron-server neutron-plugin-ml2 python-neutronclient
+ retval=1
+ [ ! -z neutron-server ]
+ dpkg -s neutron-server
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z neutron-plugin-ml2 ]
+ dpkg -s neutron-plugin-ml2
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-neutronclient ]
+ dpkg -s python-neutronclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 1 -eq 1 -a 18 -ge 14 ]
+ maybe_install_packages python-neutron-lbaas
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-neutron-lbaas
+ retval=1
+ [ ! -z python-neutron-lbaas ]
+ dpkg -s python-neutron-lbaas
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ crudini --set /etc/neutron/neutron.conf database connection mysql+pymysql://neutron:afeb2f23fd61fc63b2f7@controller/neutron
+ crudini --del /etc/neutron/neutron.conf keystone_authtoken auth_host
+ crudini --del /etc/neutron/neutron.conf keystone_authtoken auth_port
+ crudini --del /etc/neutron/neutron.conf keystone_authtoken auth_protocol
+ crudini --set /etc/neutron/neutron.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/neutron/neutron.conf DEFAULT verbose False
+ crudini --set /etc/neutron/neutron.conf DEFAULT debug False
+ crudini --set /etc/neutron/neutron.conf DEFAULT core_plugin ml2
+ [ 18 -lt 14 ]
+ [ 1 -eq 1 -a 18 -ge 14 ]
+ crudini --set /etc/neutron/neutron.conf DEFAULT service_plugins router,metering,neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2
+ crudini --set /etc/neutron/neutron.conf DEFAULT allow_overlapping_ips True
+ [ 18 -le 11 ]
+ [ 18 -lt 11 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/neutron/neutron.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ [ 18 -lt 11 ]
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken auth_type password
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken project_name service
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken username neutron
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken password 398d7129a22f6c80b3c3
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken memcached_servers controller:11211
+ crudini --set /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_status_changes True
+ crudini --set /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_data_changes True
+ crudini --set /etc/neutron/neutron.conf DEFAULT nova_url http://controller:8774/v2.1
+ [ 18 -eq 10 ]
+ crudini --set /etc/neutron/neutron.conf nova auth_url http://controller:5000
+ crudini --set /etc/neutron/neutron.conf nova auth_type password
+ crudini --set /etc/neutron/neutron.conf nova project_domain_name default
+ crudini --set /etc/neutron/neutron.conf nova user_domain_name default
+ crudini --set /etc/neutron/neutron.conf nova region_name RegionOne
+ crudini --set /etc/neutron/neutron.conf nova project_name service
+ crudini --set /etc/neutron/neutron.conf nova username nova
+ crudini --set /etc/neutron/neutron.conf nova password 70f8743910a95e3a54fe
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/neutron/neutron.conf nova memcached_servers controller:11211
+ [ 18 -ge 15 ]
+ crudini --set /etc/neutron/neutron.conf placement os_region_name RegionOne
+ crudini --set /etc/neutron/neutron.conf placement auth_url http://controller:5000/v3
+ crudini --set /etc/neutron/neutron.conf placement auth_type password
+ crudini --set /etc/neutron/neutron.conf placement project_domain_name default
+ crudini --set /etc/neutron/neutron.conf placement user_domain_name default
+ crudini --set /etc/neutron/neutron.conf placement project_name service
+ crudini --set /etc/neutron/neutron.conf placement username placement
+ crudini --set /etc/neutron/neutron.conf placement password c650059292e41b9adf49
+ [ 18 -lt 13 ]
+ crudini --set /etc/neutron/neutron.conf oslo_messaging_notifications driver messagingv2
+ [ 18 -ge 12 ]
+ cat /proc/cpuinfo
+ grep -i processor.*:
+ wc -l
+ ncpus=64
+ crudini --set /etc/neutron/neutron.conf database max_overflow 64
+ crudini --set /etc/neutron/neutron.conf database max_pool_size 64
+ [ 18 -eq 18 ]
+ crudini --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/lock
+ mkdir -p /var/lib/neutron/lock/
+ chown neutron:neutron /var/lib/neutron/lock
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 type_drivers flat,gre,vxlan
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 tenant_network_types flat,gre,vxlan
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 mechanism_drivers openvswitch
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_flat flat_networks external,flat-lan-1
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_gre tunnel_id_ranges 1:1000
+ cat
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_vxlan vni_ranges 3000:4000
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup enable_security_group True
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup enable_ipset True
+ [ -n neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver ]
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
+ [ 1 -eq 1 -a 18 -ge 14 ]
+ crudini --set /etc/neutron/neutron_lbaas.conf service_providers service_provider LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default
+ crudini --set /etc/nova/nova.conf DEFAULT network_api_class nova.network.neutronv2.api.API
+ crudini --set /etc/nova/nova.conf DEFAULT security_group_api neutron
+ [ openvswitch = openvswitch ]
+ crudini --set /etc/nova/nova.conf DEFAULT linuxnet_interface_driver nova.network.linux_net.LinuxOVSInterfaceDriver
+ crudini --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver
+ crudini --set /etc/nova/nova.conf neutron url http://controller:9696
+ crudini --set /etc/nova/nova.conf neutron auth_strategy keystone
+ [ 18 -le 11 ]
+ crudini --set /etc/nova/nova.conf neutron auth_url http://controller:5000
+ [ 18 -lt 13 ]
+ crudini --set /etc/nova/nova.conf neutron project_domain_name default
+ crudini --set /etc/nova/nova.conf neutron user_domain_name default
+ crudini --set /etc/nova/nova.conf neutron auth_type password
+ crudini --set /etc/nova/nova.conf neutron project_name service
+ crudini --set /etc/nova/nova.conf neutron username neutron
+ crudini --set /etc/nova/nova.conf neutron password 398d7129a22f6c80b3c3
+ crudini --set /etc/nova/nova.conf neutron region_name RegionOne
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/nova/nova.conf neutron memcached_servers controller:11211
+ crudini --set /etc/nova/nova.conf neutron service_metadata_proxy True
+ crudini --set /etc/nova/nova.conf neutron metadata_proxy_shared_secret e49934e1536e9d8ba189
+ [ 18 -ge 14 ]
+ su -s /bin/sh -c neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head neutron
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> kilo
INFO  [alembic.runtime.migration] Running upgrade kilo -> 354db87e3225
INFO  [alembic.runtime.migration] Running upgrade 354db87e3225 -> 599c6a226151
INFO  [alembic.runtime.migration] Running upgrade 599c6a226151 -> 52c5312f6baf
INFO  [alembic.runtime.migration] Running upgrade 52c5312f6baf -> 313373c0ffee
INFO  [alembic.runtime.migration] Running upgrade 313373c0ffee -> 8675309a5c4f
INFO  [alembic.runtime.migration] Running upgrade 8675309a5c4f -> 45f955889773
INFO  [alembic.runtime.migration] Running upgrade 45f955889773 -> 26c371498592
INFO  [alembic.runtime.migration] Running upgrade 26c371498592 -> 1c844d1677f7
INFO  [alembic.runtime.migration] Running upgrade 1c844d1677f7 -> 1b4c6e320f79
INFO  [alembic.runtime.migration] Running upgrade 1b4c6e320f79 -> 48153cb5f051
INFO  [alembic.runtime.migration] Running upgrade 48153cb5f051 -> 9859ac9c136
INFO  [alembic.runtime.migration] Running upgrade 9859ac9c136 -> 34af2b5c5a59
INFO  [alembic.runtime.migration] Running upgrade 34af2b5c5a59 -> 59cb5b6cf4d
INFO  [alembic.runtime.migration] Running upgrade 59cb5b6cf4d -> 13cfb89f881a
INFO  [alembic.runtime.migration] Running upgrade 13cfb89f881a -> 32e5974ada25
INFO  [alembic.runtime.migration] Running upgrade 32e5974ada25 -> ec7fcfbf72ee
INFO  [alembic.runtime.migration] Running upgrade ec7fcfbf72ee -> dce3ec7a25c9
INFO  [alembic.runtime.migration] Running upgrade dce3ec7a25c9 -> c3a73f615e4
INFO  [alembic.runtime.migration] Running upgrade c3a73f615e4 -> 659bf3d90664
INFO  [alembic.runtime.migration] Running upgrade 659bf3d90664 -> 1df244e556f5
INFO  [alembic.runtime.migration] Running upgrade 1df244e556f5 -> 19f26505c74f
INFO  [alembic.runtime.migration] Running upgrade 19f26505c74f -> 15be73214821
INFO  [alembic.runtime.migration] Running upgrade 15be73214821 -> b4caf27aae4
INFO  [alembic.runtime.migration] Running upgrade b4caf27aae4 -> 15e43b934f81
INFO  [alembic.runtime.migration] Running upgrade 15e43b934f81 -> 31ed664953e6
INFO  [alembic.runtime.migration] Running upgrade 31ed664953e6 -> 2f9e956e7532
INFO  [alembic.runtime.migration] Running upgrade 2f9e956e7532 -> 3894bccad37f
INFO  [alembic.runtime.migration] Running upgrade 3894bccad37f -> 0e66c5227a8a
INFO  [alembic.runtime.migration] Running upgrade 0e66c5227a8a -> 45f8dd33480b
INFO  [alembic.runtime.migration] Running upgrade 45f8dd33480b -> 5abc0278ca73
INFO  [alembic.runtime.migration] Running upgrade 5abc0278ca73 -> d3435b514502
INFO  [alembic.runtime.migration] Running upgrade d3435b514502 -> 30107ab6a3ee
INFO  [alembic.runtime.migration] Running upgrade 30107ab6a3ee -> c415aab1c048
INFO  [alembic.runtime.migration] Running upgrade c415aab1c048 -> a963b38d82f4
INFO  [alembic.runtime.migration] Running upgrade kilo -> 30018084ec99
INFO  [alembic.runtime.migration] Running upgrade 30018084ec99 -> 4ffceebfada
INFO  [alembic.runtime.migration] Running upgrade 4ffceebfada -> 5498d17be016
INFO  [alembic.runtime.migration] Running upgrade 5498d17be016 -> 2a16083502f3
INFO  [alembic.runtime.migration] Running upgrade 2a16083502f3 -> 2e5352a0ad4d
INFO  [alembic.runtime.migration] Running upgrade 2e5352a0ad4d -> 11926bcfe72d
INFO  [alembic.runtime.migration] Running upgrade 11926bcfe72d -> 4af11ca47297
INFO  [alembic.runtime.migration] Running upgrade 4af11ca47297 -> 1b294093239c
INFO  [alembic.runtime.migration] Running upgrade 1b294093239c -> 8a6d8bdae39
INFO  [alembic.runtime.migration] Running upgrade 8a6d8bdae39 -> 2b4c2465d44b
INFO  [alembic.runtime.migration] Running upgrade 2b4c2465d44b -> e3278ee65050
INFO  [alembic.runtime.migration] Running upgrade e3278ee65050 -> c6c112992c9
INFO  [alembic.runtime.migration] Running upgrade c6c112992c9 -> 5ffceebfada
INFO  [alembic.runtime.migration] Running upgrade 5ffceebfada -> 4ffceebfcdc
INFO  [alembic.runtime.migration] Running upgrade 4ffceebfcdc -> 7bbb25278f53
INFO  [alembic.runtime.migration] Running upgrade 7bbb25278f53 -> 89ab9a816d70
INFO  [alembic.runtime.migration] Running upgrade a963b38d82f4 -> 3d0e74aa7d37
INFO  [alembic.runtime.migration] Running upgrade 3d0e74aa7d37 -> 030a959ceafa
INFO  [alembic.runtime.migration] Running upgrade 030a959ceafa -> a5648cfeeadf
INFO  [alembic.runtime.migration] Running upgrade a5648cfeeadf -> 0f5bef0f87d4
INFO  [alembic.runtime.migration] Running upgrade 0f5bef0f87d4 -> 67daae611b6e
INFO  [alembic.runtime.migration] Running upgrade 89ab9a816d70 -> c879c5e1ee90
INFO  [alembic.runtime.migration] Running upgrade c879c5e1ee90 -> 8fd3918ef6f4
INFO  [alembic.runtime.migration] Running upgrade 8fd3918ef6f4 -> 4bcd4df1f426
INFO  [alembic.runtime.migration] Running upgrade 4bcd4df1f426 -> b67e765a3524
INFO  [alembic.runtime.migration] Running upgrade 67daae611b6e -> 6b461a21bcfc
INFO  [alembic.runtime.migration] Running upgrade 6b461a21bcfc -> 5cd92597d11d
INFO  [alembic.runtime.migration] Running upgrade 5cd92597d11d -> 929c968efe70
INFO  [alembic.runtime.migration] Running upgrade 929c968efe70 -> a9c43481023c
INFO  [alembic.runtime.migration] Running upgrade a9c43481023c -> 804a3c76314c
INFO  [alembic.runtime.migration] Running upgrade 804a3c76314c -> 2b42d90729da
INFO  [alembic.runtime.migration] Running upgrade 2b42d90729da -> 62c781cb6192
INFO  [alembic.runtime.migration] Running upgrade 62c781cb6192 -> c8c222d42aa9
INFO  [alembic.runtime.migration] Running upgrade c8c222d42aa9 -> 349b6fd605a6
INFO  [alembic.runtime.migration] Running upgrade 349b6fd605a6 -> 7d32f979895f
INFO  [alembic.runtime.migration] Running upgrade 7d32f979895f -> 594422d373ee
INFO  [alembic.runtime.migration] Running upgrade 594422d373ee -> 61663558142c
INFO  [alembic.runtime.migration] Running upgrade 61663558142c -> 867d39095bf4, port forwarding
INFO  [alembic.runtime.migration] Running upgrade b67e765a3524 -> a84ccf28f06a
INFO  [alembic.runtime.migration] Running upgrade a84ccf28f06a -> 7d9d8eeec6ad
INFO  [alembic.runtime.migration] Running upgrade 7d9d8eeec6ad -> a8b517cff8ab
INFO  [alembic.runtime.migration] Running upgrade a8b517cff8ab -> 3b935b28e7a0
INFO  [alembic.runtime.migration] Running upgrade 3b935b28e7a0 -> b12a3ef66e62
INFO  [alembic.runtime.migration] Running upgrade b12a3ef66e62 -> 97c25b0d2353
INFO  [alembic.runtime.migration] Running upgrade 97c25b0d2353 -> 2e0d7a8a1586
INFO  [alembic.runtime.migration] Running upgrade 2e0d7a8a1586 -> 5c85685d616d
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> start_neutron_fwaas, start neutron-fwaas chain
INFO  [alembic.runtime.migration] Running upgrade start_neutron_fwaas -> 4202e3047e47, add_index_tenant_id
INFO  [alembic.runtime.migration] Running upgrade 4202e3047e47 -> 540142f314f4, FWaaS router insertion
INFO  [alembic.runtime.migration] Running upgrade 540142f314f4 -> 796c68dffbb, cisco_csr_fwaas
INFO  [alembic.runtime.migration] Running upgrade 796c68dffbb -> kilo, kilo
INFO  [alembic.runtime.migration] Running upgrade kilo -> c40fbb377ad, Initial Liberty no-op script.
INFO  [alembic.runtime.migration] Running upgrade c40fbb377ad -> 4b47ea298795, add reject rule
INFO  [alembic.runtime.migration] Running upgrade 4b47ea298795 -> d6a12e637e28, neutron-fwaas v2.0
INFO  [alembic.runtime.migration] Running upgrade d6a12e637e28 -> 876782258a43, create_default_firewall_groups_table
INFO  [alembic.runtime.migration] Running upgrade 876782258a43 -> f24e0d5e5bff, uniq_firewallgroupportassociation0port
INFO  [alembic.runtime.migration] Running upgrade kilo -> 67c8e8d61d5, Initial Liberty no-op script.
INFO  [alembic.runtime.migration] Running upgrade 67c8e8d61d5 -> 458aa42b14b, fw_table_alter script to make <name> column case sensitive
INFO  [alembic.runtime.migration] Running upgrade 458aa42b14b -> f83a0b2964d0, rename tenant to project
INFO  [alembic.runtime.migration] Running upgrade f83a0b2964d0 -> fd38cd995cc0, change shared attribute for firewall resource
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> start_neutron_lbaas, start neutron-lbaas chain
INFO  [alembic.runtime.migration] Running upgrade start_neutron_lbaas -> lbaasv2, lbaas version 2 api
INFO  [alembic.runtime.migration] Running upgrade lbaasv2 -> 4deef6d81931, add provisioning and operating statuses
INFO  [alembic.runtime.migration] Running upgrade 4deef6d81931 -> 4b6d8d5310b8, add_index_tenant_id
INFO  [alembic.runtime.migration] Running upgrade 4b6d8d5310b8 -> 364f9b6064f0, agentv2
INFO  [alembic.runtime.migration] Running upgrade 364f9b6064f0 -> lbaasv2_tls, lbaasv2 TLS
INFO  [alembic.runtime.migration] Running upgrade lbaasv2_tls -> 4ba00375f715, edge_driver
INFO  [alembic.runtime.migration] Running upgrade 4ba00375f715 -> kilo, kilo
INFO  [alembic.runtime.migration] Running upgrade kilo -> 3345facd0452, Initial Liberty no-op expand script.
INFO  [alembic.runtime.migration] Running upgrade 3345facd0452 -> 4a408dd491c2, Addition of Name column to lbaas_members and lbaas_healthmonitors table
INFO  [alembic.runtime.migration] Running upgrade 4a408dd491c2 -> 3426acbc12de, Add flavor id
INFO  [alembic.runtime.migration] Running upgrade 3426acbc12de -> 6aee0434f911, independent pools
INFO  [alembic.runtime.migration] Running upgrade 6aee0434f911 -> 3543deab1547, add_l7_tables
INFO  [alembic.runtime.migration] Running upgrade 3543deab1547 -> 62deca5010cd, Add tenant-id index for L7 tables
INFO  [alembic.runtime.migration] Running upgrade kilo -> 130ebfdef43, Initial Liberty no-op contract revision.
INFO  [alembic.runtime.migration] Running upgrade 130ebfdef43 -> 4b4dc6d5d843, rename tenant to project
INFO  [alembic.runtime.migration] Running upgrade 4b4dc6d5d843 -> e6417a8b114d, Drop v1 tables
INFO  [alembic.runtime.migration] Running upgrade 62deca5010cd -> 844352f9fe6f, Add healthmonitor max retries down
Running upgrade for neutron ...
OK
Running upgrade for neutron-fwaas ...
OK
Running upgrade for neutron-lbaas ...
OK
+ [ 1 -eq 1 -a 18 -ge 14 ]
+ maybe_install_packages python-neutron-lbaas-dashboard
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-neutron-lbaas-dashboard
+ retval=1
+ [ ! -z python-neutron-lbaas-dashboard ]
+ dpkg -s python-neutron-lbaas-dashboard
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 0 -eq 1 ]
+ echo OPENSTACK_NEUTRON_NETWORK['enable_lb'] = True
+ su -s /bin/sh -c neutron-db-manage --config-file /etc/neutron/neutron.conf --subproject neutron-lbaas upgrade head neutron
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
Running upgrade for neutron-lbaas ...
OK
+ service_restart nova-api
+ service=nova-api
+ [ 1 -eq 0 ]
+ systemctl restart nova-api
+ service_restart nova-scheduler
+ service=nova-scheduler
+ [ 1 -eq 0 ]
+ systemctl restart nova-scheduler
+ service_restart nova-conductor
+ service=nova-conductor
+ [ 1 -eq 0 ]
+ systemctl restart nova-conductor
+ service_restart neutron-server
+ service=neutron-server
+ [ 1 -eq 0 ]
+ systemctl restart neutron-server
+ service_enable neutron-server
+ service=neutron-server
+ [ 1 -eq 0 ]
+ systemctl enable neutron-server
Synchronizing state of neutron-server.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable neutron-server
+ echo NEUTRON_DBPASS="afeb2f23fd61fc63b2f7"
+ echo NEUTRON_PASS="398d7129a22f6c80b3c3"
+ echo NEUTRON_METADATA_SECRET="e49934e1536e9d8ba189"
+ logtend neutron
+ area=neutron
+ echo neutron
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=neutron
+ date +%s
+ stamp=1557519395
+ date
+ date=Fri May 10 14:16:35 MDT 2019
+ eval tss=$LOGTIMESTART_neutron
+ tss=1557519244
+ expr 1557519395 - 1557519244
+ tsres=151
+ perl -e print 151 / 60.0 . "\n"
+ resmin=2.51666666666667
+ echo END neutron 1557519395 Fri May 10 14:16:35 MDT 2019
+ echo TOTAL neutron 151 2.51666666666667
+ [ -z  ]
+ logtstart neutron-networkmanager
+ area=neutron-networkmanager
+ echo neutron-networkmanager
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=neutron_networkmanager
+ date +%s
+ stamp=1557519395
+ date
+ date=Fri May 10 14:16:35 MDT 2019
+ eval LOGTIMESTART_neutron_networkmanager=1557519395
+ LOGTIMESTART_neutron_networkmanager=1557519395
+ echo START neutron-networkmanager 1557519395 Fri May 10 14:16:35 MDT 2019
+ NEUTRON_NETWORKMANAGER_DONE=1
+ unified
+ [ controller = controller ]
+ return 0
+ echo *** Setting up unified networkmanager on controller
*** Setting up unified networkmanager on controller
+ /local/repository/setup-networkmanager.sh
+ [ -ne 0 ]
/local/repository/setup-networkmanager.sh: 10: [: -ne: unexpected operator
+ dirname /local/repository/setup-networkmanager.sh
+ . /local/repository/setup-lib.sh
+ dirname /local/repository/setup-networkmanager.sh
+ DIRNAME=/local/repository
+ OURDIR=/root/setup
+ SETTINGS=/root/setup/settings
+ LOCALSETTINGS=/root/setup/settings.local
+ TOPOMAP=/root/setup/topomap
+ BOOTDIR=/var/emulab/boot
+ TMCC=/usr/local/etc/emulab/tmcc
+ TIMELOGFILE=/root/setup/setup-time.log
+ FIRSTTIME=0
+ [ ! -f /root/setup/setup-lib-first ]
+ [ 0 -ne 0 ]
+ mkdir -p /root/setup
+ touch /root/setup/settings
+ touch /root/setup/settings.local
+ cd /root/setup
+ LOCKFILE=lockfile-create --retry 65535 
+ RMLOCKFILE=lockfile-remove 
+ PSWDGEN=openssl rand -hex 10
+ SSH=ssh -o StrictHostKeyChecking=no
+ SCP=scp -p -o StrictHostKeyChecking=no
+ CONTROLLER=ctl
+ NETWORKMANAGER=nm
+ STORAGEHOST=ctl
+ SHAREHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=
+ BAREMETALNODES=
+ BLOCKNODES=
+ OBJECTNODES=
+ DATALAN=lan-1
+ MGMTLAN=lan-2
+ BLOCKLAN=
+ OBJECTLAN=
+ DATATUNNELS=1
+ DATAFLATLANS=lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATAOTHERLANS=
+ USE_EXISTING_IPS=1
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=0
+ DO_APT_UPDATE=1
+ UBUNTUMIRRORHOST=
+ UBUNTUMIRRORPATH=
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DO_UBUNTU_CLOUDARCHIVE=0
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ BUILD_AARCH64_FROM_CORE=0
+ DISABLE_SECURITY_GROUPS=0
+ ENABLE_HOST_PASSTHROUGH=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ SUPPORT_DYNAMIC_NODES=0
+ KEYSTONEAPIVERSION=
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ GLANCE_LV_SIZE=32
+ SWIFT_LV_SIZE=4
+ CEILOMETER_USE_WSGI=0
+ QUOTASOFF=1
+ KEYSTONEUSEMEMCACHE=0
+ KEYSTONEUSEWSGI=
+ COMPUTE_EXTRA_NOVA_DISK_SPACE=1
+ ML2PLUGIN=openvswitch
+ MANILADRIVER=generic
+ EXTRAIMAGEURLS=
+ LINUXBRIDGE_STATIC=0
+ USE_DESIGNATE_AS_RESOLVER=1
+ USE_NEUTRON_LBAAS=1
+ ENABLE_OPENSTACK_SLOTHD=0
+ OSRELEASE=
+ ADMIN_API=adminapi
+ openssl rand -hex 10
+ ADMIN_API_PASS=1f9c66bc0dbdf53f4f25
+ ADMIN=admin
+ ADMIN_PASS=
+ ADMIN_PASS_HASH=
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ [ x = x ]
+ UPDATING=0
+ NEWNODELIST=
+ OLDNODELIST=
+ [ ! -e /root/setup/apt-configured ]
+ export DEBIAN_FRONTEND=noninteractive
+ DPKGOPTS=
+ APTGETINSTALLOPTS=-y
+ APTGETINSTALL=apt-get  install -y
+ [ 1 -eq 0 ]
+ grep GENIUSER /root/setup/settings
GENIUSER=1
+ [ ! 0 -eq 0 ]
+ grep GENIUSER=1 /root/setup/settings
GENIUSER=1
+ [ 0 -eq 0 ]
+ GENIUSER=1
+ [ 1 -eq 1 ]
+ dpkg -s python-m2crypto
+ [ ! 0 -eq 0 ]
+ [ ! -e /root/setup/geni.key ]
+ HAS_GENI_KEY=1
+ [ ! -e /root/setup/geni.certificate ]
+ HAS_GENI_CERT=1
+ [ ! -e /root/.ssl/encrypted.pem ]
+ [ ! -e /root/setup/manifests.xml -o 0 -ne 0 ]
+ [ ! -e /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/decrypted_admin_pass -a -s /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/parameters ]
+ . /root/setup/parameters
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ COMPUTENODES=compute-1 
+ DATALANS=flat-lan-1
+ DATAFLATLANS=flat-lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATATUNNELS=1
+ MGMTLAN=
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=1
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ DO_APT_UPDATE=1
+ ADMIN_PASS_HASH=
+ ENABLE_HOST_PASSTHROUGH=1
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DISABLE_SECURITY_GROUPS=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ USE_NEUTRON_LBAAS=1
+ CEILOMETER_USE_MONGODB=0
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ KEYSTONEUSEMEMCACHE=0
+ QUOTASOFF=1
+ ML2PLUGIN=openvswitch
+ USE_DESIGNATE_AS_RESOLVER=1
+ EXTRAIMAGEURLS=
+ OSRELEASE=rocky
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ ADMIN_PASS=9da6fece4881
+ ADMIN_PASS_HASH=$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA.
+ [ x$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA. = x ]
+ cat /var/emulab/boot/creator
+ CREATOR=tboudw0
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ cat /var/emulab/boot/nickname
+ cut -d . -f 1
+ NODEID=controller
+ cat /var/emulab/boot/nodeid
+ PNODEID=clnode234
+ cat /var/emulab/boot/nickname
+ cut -d . -f 2
+ EEID=tboudwin-QV52139
+ cat /var/emulab/boot/nickname
+ cut -d . -f 3
+ EPID=pdc-edu-lab-PG0
+ cat /var/emulab/boot/mydomain
+ OURDOMAIN=clemson.cloudlab.us
+ cat /var/emulab/boot/nickname
+ NFQDN=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ cat /var/emulab/boot/nodeid
+ PFQDN=clnode234.clemson.cloudlab.us
+ cat /var/emulab/boot/myip
+ MYIP=130.127.133.243
+ cat /var/emulab/boot/controlif
+ EXTERNAL_NETWORK_INTERFACE=br-ex
+ cat /var/emulab/boot/nickname
+ cut -f1 -d.
+ HOSTNAME=controller
+ uname -m
+ ARCH=x86_64
+ dpkg-query -S /sbin/init
+ grep -q systemd
+ expr 0 = 0
+ HAVE_SYSTEMD=1
+ OSJUNO=10
+ OSKILO=11
+ OSLIBERTY=12
+ OSMITAKA=13
+ OSNEWTON=14
+ OSOCATA=15
+ OSPIKE=16
+ OSQUEENS=17
+ OSROCKY=18
+ . /etc/lsb-release
+ DISTRIB_ID=Ubuntu
+ DISTRIB_RELEASE=18.04
+ DISTRIB_CODENAME=bionic
+ DISTRIB_DESCRIPTION=Ubuntu 18.04.2 LTS
+ [ ! xrocky = x ]
+ OSCODENAME=rocky
+ [ rocky = juno ]
+ [ rocky = kilo ]
+ [ rocky = liberty ]
+ [ rocky = mitaka ]
+ [ rocky = newton ]
+ [ rocky = ocata ]
+ [ rocky = pike ]
+ [ rocky = queens ]
+ [ rocky = rocky ]
+ OSVERSION=18
+ echo Ubuntu 18.04.2 LTS
+ grep -qi LTS
+ [ 0 -eq 0 ]
+ DO_UBUNTU_CLOUDARCHIVE=1
+ echo 18.04
+ cut -d. -f1
+ DISTRIB_MAJOR=18
+ [ 18 -ge 13 ]
+ KEYSTONEUSEMEMCACHE=1
+ [ 18 -eq 10 ]
+ REGION=RegionOne
+ [ 18 -ge 17 ]
+ KADMINPORT=5000
+ [ x = x3 ]
+ [  != 2 -a 18 -ge 12 ]
+ KAPISTR=v3
+ KEYSTONEAPIVERSION=3
+ NAPISTR=v2
+ [ 18 -ge 13 ]
+ NAPISTR=v2.1
+ [ x = x -a 18 -ge 11 ]
+ KEYSTONEUSEWSGI=1
+ [ 18 -ge 13 ]
+ PROJECT_DOMAIN_PARAM=project_domain_name
+ USER_DOMAIN_PARAM=user_domain_name
+ AUTH_TYPE_PARAM=auth_type
+ [ 18 -ge 14 ]
+ DBDPACKAGE=python-pymysql
+ DBDSTRING=mysql+pymysql
+ [ 1 -eq 1 ]
+ geni-get slice_email
+ SWAPPER_EMAIL=tboudwin@wcupa.edu
+ [ 1 -eq 1 ]
+ + cat /root/setup/manifests.0.xml
perl -e $found = 0; while (<STDIN>) { if ($_ =~ /\<[\d\w:]*routable_pool [^\>\<]*\/>/) { print STDERR "DEBUG: found empty pool: $_\n"; next; } if ($_ =~ /\<[\d\w:]*routable_pool [^\>]*client_id=['"]controller['"]/) { $found = 1; print STDERR "DEBUG: found: $_\n" } if ($found) { while ($_ =~ m/\<emulab:ipv4 address="([\d.]+)\" netmask=\"([\d\.]+)\"/g) { print "$1\n"; } } if ($found && $_ =~ /routable_pool\>/) { print STDERR "DEBUG: end found: $_\n"; $found = 0; } }
+ xargs
DEBUG: found:   <emulab:routable_pool client_id="controller" count="4" type="any" component_manager_id="urn:publicid:IDN+clemson.cloudlab.us+authority+cm">

DEBUG: end found:   <emulab:ipv4 address="130.127.132.210" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.226" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.238" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.239" netmask="255.255.252.0"/></emulab:routable_pool>

+ PUBLICADDRS=130.127.132.210 130.127.132.226 130.127.132.238 130.127.132.239
+ PUBLICCOUNT=0
+ expr 0 + 1
+ PUBLICCOUNT=1
+ expr 1 + 1
+ PUBLICCOUNT=2
+ expr 2 + 1
+ PUBLICCOUNT=3
+ expr 3 + 1
+ PUBLICCOUNT=4
+ [ ! -f /root/setup/topomap -o 0 -ne 0 ]
+ [ ! -z  ]
+ [ ( -s /root/setup/manifests.xml ) -a ( ! ( -s /root/setup/fqdn.map ) ) ]
+ [ ! -s /root/setup/fqdn.map ]
+ cat /root/setup/fqdn.map
+ cut -f1
+ xargs
+ NODES=controller compute-1
+ + cat /root/setup/fqdn.map
cut -f2
+ xargs
+ FQDNS=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ [ -z compute-1  ]
+ OTHERNODES=
+ [ controller = controller ]
+ continue
+ [ compute-1 = controller ]
+ OTHERNODES= compute-1
+ grep CONTROLLER /root/setup/settings
CONTROLLER="controller"
+ [ ! 0 = 0 ]
+ [ 0 -ne 0 ]
+ grep MIRRORSETUP /root/setup/settings
MIRRORSETUP=1
+ [ ! 0 -eq 0 ]
+ [ ! -f /root/setup/apt-updated -a 1 = 1 ]
+ [ ! -f /root/setup/cloudarchive-added -a 1 = 1 ]
+ [ ! -f /root/setup/apt-dist-upgraded -a 1 = 1 ]
+ maybe_install_packages crudini
+ [ ! 0 -eq 0 ]
+ are_packages_installed crudini
+ retval=1
+ [ ! -z crudini ]
+ dpkg -s crudini
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ ! -f /root/setup/nextsparesubnet ]
+ cat /root/setup/nextsparesubnet
+ NEXTSPARESUBNET=253
+ [ ! -f /root/setup/mgmt-hosts -o 0 -ne 0 ]
+ [ 1 -gt 0 ]
+ i=0
+ [ 0 -lt 1 ]
+ [ -f /root/setup/ipinfo.tun0 ]
+ expr 0 + 1
+ i=1
+ continue
+ [ 1 -lt 1 ]
+ echo 253
+ echo 253
+ [ 0 -gt 0 ]
+ [ ! -e /root/setup/info.mgmt ]
+ . /root/setup/info.mgmt
+ MGMTIP=192.168.0.1
+ MGMTNETMASK=255.255.0.0
+ MGMTPREFIX=16
+ MGMTVLAN=0
+ MGMTMAC=
+ MGMT_NETWORK_INTERFACE=tun0
+ MGMTVLANDEV=
+ MGMTVLANTAG=
+ [ -e /root/setup/info.flat-lan-1 ]
+ continue
+ [ ! -f /root/setup/neutron.vars ]
+ [ ! -f /etc/emulab/bossnode -a 18 -ge 14 -a 1 = 1 ]
+ [ 0 -ne 0 ]
+ which wget
+ GETTER=/usr/bin/wget
+ [ -n /usr/bin/wget ]
+ GETTEROUT=/usr/bin/wget --remote-encoding=unix -c -O
+ GETTER=/usr/bin/wget --remote-encoding=unix -c -N
+ GETTERLOGARG=-o
+ [ 0 -ne 0 ]
+ [ controller != controller ]
+ [ -f /root/setup/setup-networkmanager-done ]
+ logtstart networkmanager
+ area=networkmanager
+ + echo networkmanager
sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=networkmanager
+ date +%s
+ stamp=1557519395
+ date
+ date=Fri May 10 14:16:35 MDT 2019
+ eval LOGTIMESTART_networkmanager=1557519395
+ LOGTIMESTART_networkmanager=1557519395
+ echo START networkmanager 1557519395 Fri May 10 14:16:35 MDT 2019
+ [ -f /root/setup/settings ]
+ . /root/setup/settings
+ GENIUSER=1
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ STORAGEHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=compute-1 
+ MIRRORSETUP=1
+ DB_ROOT_PASS=ad12065d4a6fcf049d20
+ RABBIT_USER=openstack
+ RABBIT_PASS=0375d10f3c80e2774768
+ RABBIT_URL=rabbit://openstack:0375d10f3c80e2774768@controller
+ MEMCACHE_DONE=1
+ ETCD_DONE=1
+ ADMIN_API=adminapi
+ ADMIN_API_PASS=92748256c1e798f84f04
+ KEYSTONE_DBPASS=475bd45587c7b7ebea74
+ GLANCE_DBPASS=90422ef6606c271c3df3
+ GLANCE_PASS=8730282cd9b68ed94645
+ NOVA_DBPASS=8f182a0cc87fc8fe28e1
+ PLACEMENT_DBPASS=183a130e6978d3eefbd9
+ NOVA_PASS=70f8743910a95e3a54fe
+ PLACEMENT_PASS=c650059292e41b9adf49
+ NOVA_COMPUTENODES_DONE=1
+ NEUTRON_DBPASS=afeb2f23fd61fc63b2f7
+ NEUTRON_PASS=398d7129a22f6c80b3c3
+ NEUTRON_METADATA_SECRET=e49934e1536e9d8ba189
+ /local/repository/setup-network-plugin.sh
+ [ -ne 0 ]
/local/repository/setup-network-plugin.sh: 10: [: -ne: unexpected operator
+ dirname /local/repository/setup-network-plugin.sh
+ . /local/repository/setup-lib.sh
+ dirname /local/repository/setup-network-plugin.sh
+ DIRNAME=/local/repository
+ OURDIR=/root/setup
+ SETTINGS=/root/setup/settings
+ LOCALSETTINGS=/root/setup/settings.local
+ TOPOMAP=/root/setup/topomap
+ BOOTDIR=/var/emulab/boot
+ TMCC=/usr/local/etc/emulab/tmcc
+ TIMELOGFILE=/root/setup/setup-time.log
+ FIRSTTIME=0
+ [ ! -f /root/setup/setup-lib-first ]
+ [ 0 -ne 0 ]
+ mkdir -p /root/setup
+ touch /root/setup/settings
+ touch /root/setup/settings.local
+ cd /root/setup
+ LOCKFILE=lockfile-create --retry 65535 
+ RMLOCKFILE=lockfile-remove 
+ PSWDGEN=openssl rand -hex 10
+ SSH=ssh -o StrictHostKeyChecking=no
+ SCP=scp -p -o StrictHostKeyChecking=no
+ CONTROLLER=ctl
+ NETWORKMANAGER=nm
+ STORAGEHOST=ctl
+ SHAREHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=
+ BAREMETALNODES=
+ BLOCKNODES=
+ OBJECTNODES=
+ DATALAN=lan-1
+ MGMTLAN=lan-2
+ BLOCKLAN=
+ OBJECTLAN=
+ DATATUNNELS=1
+ DATAFLATLANS=lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATAOTHERLANS=
+ USE_EXISTING_IPS=1
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=0
+ DO_APT_UPDATE=1
+ UBUNTUMIRRORHOST=
+ UBUNTUMIRRORPATH=
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DO_UBUNTU_CLOUDARCHIVE=0
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ BUILD_AARCH64_FROM_CORE=0
+ DISABLE_SECURITY_GROUPS=0
+ ENABLE_HOST_PASSTHROUGH=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ SUPPORT_DYNAMIC_NODES=0
+ KEYSTONEAPIVERSION=
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ GLANCE_LV_SIZE=32
+ SWIFT_LV_SIZE=4
+ CEILOMETER_USE_WSGI=0
+ QUOTASOFF=1
+ KEYSTONEUSEMEMCACHE=0
+ KEYSTONEUSEWSGI=
+ COMPUTE_EXTRA_NOVA_DISK_SPACE=1
+ ML2PLUGIN=openvswitch
+ MANILADRIVER=generic
+ EXTRAIMAGEURLS=
+ LINUXBRIDGE_STATIC=0
+ USE_DESIGNATE_AS_RESOLVER=1
+ USE_NEUTRON_LBAAS=1
+ ENABLE_OPENSTACK_SLOTHD=0
+ OSRELEASE=
+ ADMIN_API=adminapi
+ openssl rand -hex 10
+ ADMIN_API_PASS=e8df6c6a3339832c4cb2
+ ADMIN=admin
+ ADMIN_PASS=
+ ADMIN_PASS_HASH=
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ [ x = x ]
+ UPDATING=0
+ NEWNODELIST=
+ OLDNODELIST=
+ [ ! -e /root/setup/apt-configured ]
+ export DEBIAN_FRONTEND=noninteractive
+ DPKGOPTS=
+ APTGETINSTALLOPTS=-y
+ APTGETINSTALL=apt-get  install -y
+ [ 1 -eq 0 ]
+ grep GENIUSER /root/setup/settings
GENIUSER=1
+ [ ! 0 -eq 0 ]
+ grep GENIUSER=1 /root/setup/settings
GENIUSER=1
+ [ 0 -eq 0 ]
+ GENIUSER=1
+ [ 1 -eq 1 ]
+ dpkg -s python-m2crypto
+ [ ! 0 -eq 0 ]
+ [ ! -e /root/setup/geni.key ]
+ HAS_GENI_KEY=1
+ [ ! -e /root/setup/geni.certificate ]
+ HAS_GENI_CERT=1
+ [ ! -e /root/.ssl/encrypted.pem ]
+ [ ! -e /root/setup/manifests.xml -o 0 -ne 0 ]
+ [ ! -e /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/decrypted_admin_pass -a -s /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/parameters ]
+ . /root/setup/parameters
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ COMPUTENODES=compute-1 
+ DATALANS=flat-lan-1
+ DATAFLATLANS=flat-lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATATUNNELS=1
+ MGMTLAN=
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=1
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ DO_APT_UPDATE=1
+ ADMIN_PASS_HASH=
+ ENABLE_HOST_PASSTHROUGH=1
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DISABLE_SECURITY_GROUPS=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ USE_NEUTRON_LBAAS=1
+ CEILOMETER_USE_MONGODB=0
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ KEYSTONEUSEMEMCACHE=0
+ QUOTASOFF=1
+ ML2PLUGIN=openvswitch
+ USE_DESIGNATE_AS_RESOLVER=1
+ EXTRAIMAGEURLS=
+ OSRELEASE=rocky
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ ADMIN_PASS=9da6fece4881
+ ADMIN_PASS_HASH=$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA.
+ [ x$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA. = x ]
+ cat /var/emulab/boot/creator
+ CREATOR=tboudw0
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ cat /var/emulab/boot/nickname
+ cut -d . -f 1
+ NODEID=controller
+ cat /var/emulab/boot/nodeid
+ PNODEID=clnode234
+ cat /var/emulab/boot/nickname
+ cut -d . -f 2
+ EEID=tboudwin-QV52139
+ cat /var/emulab/boot/nickname
+ cut -d . -f 3
+ EPID=pdc-edu-lab-PG0
+ cat /var/emulab/boot/mydomain
+ OURDOMAIN=clemson.cloudlab.us
+ cat /var/emulab/boot/nickname
+ NFQDN=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ cat /var/emulab/boot/nodeid
+ PFQDN=clnode234.clemson.cloudlab.us
+ cat /var/emulab/boot/myip
+ MYIP=130.127.133.243
+ cat /var/emulab/boot/controlif
+ EXTERNAL_NETWORK_INTERFACE=br-ex
+ cat /var/emulab/boot/nickname
+ cut -f1 -d.
+ HOSTNAME=controller
+ uname -m
+ ARCH=x86_64
+ dpkg-query -S /sbin/init
+ grep -q systemd
+ expr 0 = 0
+ HAVE_SYSTEMD=1
+ OSJUNO=10
+ OSKILO=11
+ OSLIBERTY=12
+ OSMITAKA=13
+ OSNEWTON=14
+ OSOCATA=15
+ OSPIKE=16
+ OSQUEENS=17
+ OSROCKY=18
+ . /etc/lsb-release
+ DISTRIB_ID=Ubuntu
+ DISTRIB_RELEASE=18.04
+ DISTRIB_CODENAME=bionic
+ DISTRIB_DESCRIPTION=Ubuntu 18.04.2 LTS
+ [ ! xrocky = x ]
+ OSCODENAME=rocky
+ [ rocky = juno ]
+ [ rocky = kilo ]
+ [ rocky = liberty ]
+ [ rocky = mitaka ]
+ [ rocky = newton ]
+ [ rocky = ocata ]
+ [ rocky = pike ]
+ [ rocky = queens ]
+ [ rocky = rocky ]
+ OSVERSION=18
+ echo Ubuntu 18.04.2 LTS
+ grep -qi LTS
+ [ 0 -eq 0 ]
+ DO_UBUNTU_CLOUDARCHIVE=1
+ echo 18.04
+ cut -d. -f1
+ DISTRIB_MAJOR=18
+ [ 18 -ge 13 ]
+ KEYSTONEUSEMEMCACHE=1
+ [ 18 -eq 10 ]
+ REGION=RegionOne
+ [ 18 -ge 17 ]
+ KADMINPORT=5000
+ [ x = x3 ]
+ [  != 2 -a 18 -ge 12 ]
+ KAPISTR=v3
+ KEYSTONEAPIVERSION=3
+ NAPISTR=v2
+ [ 18 -ge 13 ]
+ NAPISTR=v2.1
+ [ x = x -a 18 -ge 11 ]
+ KEYSTONEUSEWSGI=1
+ [ 18 -ge 13 ]
+ PROJECT_DOMAIN_PARAM=project_domain_name
+ USER_DOMAIN_PARAM=user_domain_name
+ AUTH_TYPE_PARAM=auth_type
+ [ 18 -ge 14 ]
+ DBDPACKAGE=python-pymysql
+ DBDSTRING=mysql+pymysql
+ [ 1 -eq 1 ]
+ geni-get slice_email
+ SWAPPER_EMAIL=tboudwin@wcupa.edu
+ [ 1 -eq 1 ]
+ + perl -e $found = 0; while (<STDIN>) { if ($_ =~ /\<[\d\w:]*routable_pool [^\>\<]*\/>/) { print STDERR "DEBUG: found empty pool: $_\n"; next; } if ($_ =~ /\<[\d\w:]*routable_pool [^\>]*client_id=['"]controller['"]/) { $found = 1; print STDERR "DEBUG: found: $_\n" } if ($found) { while ($_ =~ m/\<emulab:ipv4 address="([\d.]+)\" netmask=\"([\d\.]+)\"/g) { print "$1\n"; } } if ($found && $_ =~ /routable_pool\>/) { print STDERR "DEBUG: end found: $_\n"; $found = 0; } }
cat /root/setup/manifests.0.xml
+ xargs
DEBUG: found:   <emulab:routable_pool client_id="controller" count="4" type="any" component_manager_id="urn:publicid:IDN+clemson.cloudlab.us+authority+cm">

DEBUG: end found:   <emulab:ipv4 address="130.127.132.210" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.226" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.238" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.239" netmask="255.255.252.0"/></emulab:routable_pool>

+ PUBLICADDRS=130.127.132.210 130.127.132.226 130.127.132.238 130.127.132.239
+ PUBLICCOUNT=0
+ expr 0 + 1
+ PUBLICCOUNT=1
+ expr 1 + 1
+ PUBLICCOUNT=2
+ expr 2 + 1
+ PUBLICCOUNT=3
+ expr 3 + 1
+ PUBLICCOUNT=4
+ [ ! -f /root/setup/topomap -o 0 -ne 0 ]
+ [ ! -z  ]
+ [ ( -s /root/setup/manifests.xml ) -a ( ! ( -s /root/setup/fqdn.map ) ) ]
+ [ ! -s /root/setup/fqdn.map ]
+ cat /root/setup/fqdn.map
+ cut -f1
+ xargs
+ NODES=controller compute-1
+ cat /root/setup/fqdn.map
+ cut -f2
+ xargs
+ FQDNS=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ [ -z compute-1  ]
+ OTHERNODES=
+ [ controller = controller ]
+ continue
+ [ compute-1 = controller ]
+ OTHERNODES= compute-1
+ grep CONTROLLER /root/setup/settings
CONTROLLER="controller"
+ [ ! 0 = 0 ]
+ [ 0 -ne 0 ]
+ grep MIRRORSETUP /root/setup/settings
MIRRORSETUP=1
+ [ ! 0 -eq 0 ]
+ [ ! -f /root/setup/apt-updated -a 1 = 1 ]
+ [ ! -f /root/setup/cloudarchive-added -a 1 = 1 ]
+ [ ! -f /root/setup/apt-dist-upgraded -a 1 = 1 ]
+ maybe_install_packages crudini
+ [ ! 0 -eq 0 ]
+ are_packages_installed crudini
+ retval=1
+ [ ! -z crudini ]
+ dpkg -s crudini
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ ! -f /root/setup/nextsparesubnet ]
+ cat /root/setup/nextsparesubnet
+ NEXTSPARESUBNET=253
+ [ ! -f /root/setup/mgmt-hosts -o 0 -ne 0 ]
+ [ 1 -gt 0 ]
+ i=0
+ [ 0 -lt 1 ]
+ [ -f /root/setup/ipinfo.tun0 ]
+ expr 0 + 1
+ i=1
+ continue
+ [ 1 -lt 1 ]
+ echo 253
+ echo 253
+ [ 0 -gt 0 ]
+ [ ! -e /root/setup/info.mgmt ]
+ . /root/setup/info.mgmt
+ MGMTIP=192.168.0.1
+ MGMTNETMASK=255.255.0.0
+ MGMTPREFIX=16
+ MGMTVLAN=0
+ MGMTMAC=
+ MGMT_NETWORK_INTERFACE=tun0
+ MGMTVLANDEV=
+ MGMTVLANTAG=
+ [ -e /root/setup/info.flat-lan-1 ]
+ continue
+ [ ! -f /root/setup/neutron.vars ]
+ [ ! -f /etc/emulab/bossnode -a 18 -ge 14 -a 1 = 1 ]
+ [ 0 -ne 0 ]
+ which wget
+ GETTER=/usr/bin/wget
+ [ -n /usr/bin/wget ]
+ GETTEROUT=/usr/bin/wget --remote-encoding=unix -c -O
+ GETTER=/usr/bin/wget --remote-encoding=unix -c -N
+ GETTERLOGARG=-o
+ [ 0 -ne 0 ]
+ [ -f /root/setup/setup-network-plugin-done ]
+ logtstart network-plugin
+ area=network-plugin
+ echo network-plugin
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=network_plugin
+ date +%s
+ stamp=1557519396
+ date
+ date=Fri May 10 14:16:36 MDT 2019
+ eval LOGTIMESTART_network_plugin=1557519396
+ LOGTIMESTART_network_plugin=1557519396
+ echo START network-plugin 1557519396 Fri May 10 14:16:36 MDT 2019
+ [ -f /root/setup/settings ]
+ . /root/setup/settings
+ GENIUSER=1
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ STORAGEHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=compute-1 
+ MIRRORSETUP=1
+ DB_ROOT_PASS=ad12065d4a6fcf049d20
+ RABBIT_USER=openstack
+ RABBIT_PASS=0375d10f3c80e2774768
+ RABBIT_URL=rabbit://openstack:0375d10f3c80e2774768@controller
+ MEMCACHE_DONE=1
+ ETCD_DONE=1
+ ADMIN_API=adminapi
+ ADMIN_API_PASS=92748256c1e798f84f04
+ KEYSTONE_DBPASS=475bd45587c7b7ebea74
+ GLANCE_DBPASS=90422ef6606c271c3df3
+ GLANCE_PASS=8730282cd9b68ed94645
+ NOVA_DBPASS=8f182a0cc87fc8fe28e1
+ PLACEMENT_DBPASS=183a130e6978d3eefbd9
+ NOVA_PASS=70f8743910a95e3a54fe
+ PLACEMENT_PASS=c650059292e41b9adf49
+ NOVA_COMPUTENODES_DONE=1
+ NEUTRON_DBPASS=afeb2f23fd61fc63b2f7
+ NEUTRON_PASS=398d7129a22f6c80b3c3
+ NEUTRON_METADATA_SECRET=e49934e1536e9d8ba189
+ [ -f /root/setup/settings.local ]
+ . /root/setup/settings.local
+ STORAGEDIR=/storage
+ VGNAME=openstack-volumes
+ VGTOTAL=1976
+ LVM=1
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ CINDER_LV_SIZE=1457.25
+ [ openvswitch = linuxbridge ]
+ /local/repository/setup-network-plugin-openvswitch.sh
+ [ -ne 0 ]
/local/repository/setup-network-plugin-openvswitch.sh: 10: [: -ne: unexpected operator
+ dirname /local/repository/setup-network-plugin-openvswitch.sh
+ . /local/repository/setup-lib.sh
+ dirname /local/repository/setup-network-plugin-openvswitch.sh
+ DIRNAME=/local/repository
+ OURDIR=/root/setup
+ SETTINGS=/root/setup/settings
+ LOCALSETTINGS=/root/setup/settings.local
+ TOPOMAP=/root/setup/topomap
+ BOOTDIR=/var/emulab/boot
+ TMCC=/usr/local/etc/emulab/tmcc
+ TIMELOGFILE=/root/setup/setup-time.log
+ FIRSTTIME=0
+ [ ! -f /root/setup/setup-lib-first ]
+ [ 0 -ne 0 ]
+ mkdir -p /root/setup
+ touch /root/setup/settings
+ touch /root/setup/settings.local
+ cd /root/setup
+ LOCKFILE=lockfile-create --retry 65535 
+ RMLOCKFILE=lockfile-remove 
+ PSWDGEN=openssl rand -hex 10
+ SSH=ssh -o StrictHostKeyChecking=no
+ SCP=scp -p -o StrictHostKeyChecking=no
+ CONTROLLER=ctl
+ NETWORKMANAGER=nm
+ STORAGEHOST=ctl
+ SHAREHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=
+ BAREMETALNODES=
+ BLOCKNODES=
+ OBJECTNODES=
+ DATALAN=lan-1
+ MGMTLAN=lan-2
+ BLOCKLAN=
+ OBJECTLAN=
+ DATATUNNELS=1
+ DATAFLATLANS=lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATAOTHERLANS=
+ USE_EXISTING_IPS=1
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=0
+ DO_APT_UPDATE=1
+ UBUNTUMIRRORHOST=
+ UBUNTUMIRRORPATH=
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DO_UBUNTU_CLOUDARCHIVE=0
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ BUILD_AARCH64_FROM_CORE=0
+ DISABLE_SECURITY_GROUPS=0
+ ENABLE_HOST_PASSTHROUGH=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ SUPPORT_DYNAMIC_NODES=0
+ KEYSTONEAPIVERSION=
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ GLANCE_LV_SIZE=32
+ SWIFT_LV_SIZE=4
+ CEILOMETER_USE_WSGI=0
+ QUOTASOFF=1
+ KEYSTONEUSEMEMCACHE=0
+ KEYSTONEUSEWSGI=
+ COMPUTE_EXTRA_NOVA_DISK_SPACE=1
+ ML2PLUGIN=openvswitch
+ MANILADRIVER=generic
+ EXTRAIMAGEURLS=
+ LINUXBRIDGE_STATIC=0
+ USE_DESIGNATE_AS_RESOLVER=1
+ USE_NEUTRON_LBAAS=1
+ ENABLE_OPENSTACK_SLOTHD=0
+ OSRELEASE=
+ ADMIN_API=adminapi
+ openssl rand -hex 10
+ ADMIN_API_PASS=48f05b7134f0a196ea76
+ ADMIN=admin
+ ADMIN_PASS=
+ ADMIN_PASS_HASH=
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ [ x = x ]
+ UPDATING=0
+ NEWNODELIST=
+ OLDNODELIST=
+ [ ! -e /root/setup/apt-configured ]
+ export DEBIAN_FRONTEND=noninteractive
+ DPKGOPTS=
+ APTGETINSTALLOPTS=-y
+ APTGETINSTALL=apt-get  install -y
+ [ 1 -eq 0 ]
+ grep GENIUSER /root/setup/settings
GENIUSER=1
+ [ ! 0 -eq 0 ]
+ grep GENIUSER=1 /root/setup/settings
GENIUSER=1
+ [ 0 -eq 0 ]
+ GENIUSER=1
+ [ 1 -eq 1 ]
+ dpkg -s python-m2crypto
+ [ ! 0 -eq 0 ]
+ [ ! -e /root/setup/geni.key ]
+ HAS_GENI_KEY=1
+ [ ! -e /root/setup/geni.certificate ]
+ HAS_GENI_CERT=1
+ [ ! -e /root/.ssl/encrypted.pem ]
+ [ ! -e /root/setup/manifests.xml -o 0 -ne 0 ]
+ [ ! -e /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/decrypted_admin_pass -a -s /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/parameters ]
+ . /root/setup/parameters
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ COMPUTENODES=compute-1 
+ DATALANS=flat-lan-1
+ DATAFLATLANS=flat-lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATATUNNELS=1
+ MGMTLAN=
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=1
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ DO_APT_UPDATE=1
+ ADMIN_PASS_HASH=
+ ENABLE_HOST_PASSTHROUGH=1
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DISABLE_SECURITY_GROUPS=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ USE_NEUTRON_LBAAS=1
+ CEILOMETER_USE_MONGODB=0
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ KEYSTONEUSEMEMCACHE=0
+ QUOTASOFF=1
+ ML2PLUGIN=openvswitch
+ USE_DESIGNATE_AS_RESOLVER=1
+ EXTRAIMAGEURLS=
+ OSRELEASE=rocky
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ ADMIN_PASS=9da6fece4881
+ ADMIN_PASS_HASH=$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA.
+ [ x$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA. = x ]
+ cat /var/emulab/boot/creator
+ CREATOR=tboudw0
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ cat /var/emulab/boot/nickname
+ cut -d . -f 1
+ NODEID=controller
+ cat /var/emulab/boot/nodeid
+ PNODEID=clnode234
+ cat /var/emulab/boot/nickname
+ cut -d . -f 2
+ EEID=tboudwin-QV52139
+ cat /var/emulab/boot/nickname
+ cut -d . -f 3
+ EPID=pdc-edu-lab-PG0
+ cat /var/emulab/boot/mydomain
+ OURDOMAIN=clemson.cloudlab.us
+ cat /var/emulab/boot/nickname
+ NFQDN=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ cat /var/emulab/boot/nodeid
+ PFQDN=clnode234.clemson.cloudlab.us
+ cat /var/emulab/boot/myip
+ MYIP=130.127.133.243
+ cat /var/emulab/boot/controlif
+ EXTERNAL_NETWORK_INTERFACE=br-ex
+ cat /var/emulab/boot/nickname
+ cut -f1 -d.
+ HOSTNAME=controller
+ uname -m
+ ARCH=x86_64
+ + dpkg-query -S /sbin/init
grep -q systemd
+ expr 0 = 0
+ HAVE_SYSTEMD=1
+ OSJUNO=10
+ OSKILO=11
+ OSLIBERTY=12
+ OSMITAKA=13
+ OSNEWTON=14
+ OSOCATA=15
+ OSPIKE=16
+ OSQUEENS=17
+ OSROCKY=18
+ . /etc/lsb-release
+ DISTRIB_ID=Ubuntu
+ DISTRIB_RELEASE=18.04
+ DISTRIB_CODENAME=bionic
+ DISTRIB_DESCRIPTION=Ubuntu 18.04.2 LTS
+ [ ! xrocky = x ]
+ OSCODENAME=rocky
+ [ rocky = juno ]
+ [ rocky = kilo ]
+ [ rocky = liberty ]
+ [ rocky = mitaka ]
+ [ rocky = newton ]
+ [ rocky = ocata ]
+ [ rocky = pike ]
+ [ rocky = queens ]
+ [ rocky = rocky ]
+ OSVERSION=18
+ echo Ubuntu 18.04.2 LTS
+ grep -qi LTS
+ [ 0 -eq 0 ]
+ DO_UBUNTU_CLOUDARCHIVE=1
+ echo 18.04
+ cut -d. -f1
+ DISTRIB_MAJOR=18
+ [ 18 -ge 13 ]
+ KEYSTONEUSEMEMCACHE=1
+ [ 18 -eq 10 ]
+ REGION=RegionOne
+ [ 18 -ge 17 ]
+ KADMINPORT=5000
+ [ x = x3 ]
+ [  != 2 -a 18 -ge 12 ]
+ KAPISTR=v3
+ KEYSTONEAPIVERSION=3
+ NAPISTR=v2
+ [ 18 -ge 13 ]
+ NAPISTR=v2.1
+ [ x = x -a 18 -ge 11 ]
+ KEYSTONEUSEWSGI=1
+ [ 18 -ge 13 ]
+ PROJECT_DOMAIN_PARAM=project_domain_name
+ USER_DOMAIN_PARAM=user_domain_name
+ AUTH_TYPE_PARAM=auth_type
+ [ 18 -ge 14 ]
+ DBDPACKAGE=python-pymysql
+ DBDSTRING=mysql+pymysql
+ [ 1 -eq 1 ]
+ geni-get slice_email
+ SWAPPER_EMAIL=tboudwin@wcupa.edu
+ [ 1 -eq 1 ]
+ cat /root/setup/manifests.0.xml
+ perl -e $found = 0; while (<STDIN>) { if ($_ =~ /\<[\d\w:]*routable_pool [^\>\<]*\/>/) { print STDERR "DEBUG: found empty pool: $_\n"; next; } if ($_ =~ /\<[\d\w:]*routable_pool [^\>]*client_id=['"]controller['"]/) { $found = 1; print STDERR "DEBUG: found: $_\n" } if ($found) { while ($_ =~ m/\<emulab:ipv4 address="([\d.]+)\" netmask=\"([\d\.]+)\"/g) { print "$1\n"; } } if ($found && $_ =~ /routable_pool\>/) { print STDERR "DEBUG: end found: $_\n"; $found = 0; } }
+ xargs
DEBUG: found:   <emulab:routable_pool client_id="controller" count="4" type="any" component_manager_id="urn:publicid:IDN+clemson.cloudlab.us+authority+cm">

DEBUG: end found:   <emulab:ipv4 address="130.127.132.210" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.226" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.238" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.239" netmask="255.255.252.0"/></emulab:routable_pool>

+ PUBLICADDRS=130.127.132.210 130.127.132.226 130.127.132.238 130.127.132.239
+ PUBLICCOUNT=0
+ expr 0 + 1
+ PUBLICCOUNT=1
+ expr 1 + 1
+ PUBLICCOUNT=2
+ expr 2 + 1
+ PUBLICCOUNT=3
+ expr 3 + 1
+ PUBLICCOUNT=4
+ [ ! -f /root/setup/topomap -o 0 -ne 0 ]
+ [ ! -z  ]
+ [ ( -s /root/setup/manifests.xml ) -a ( ! ( -s /root/setup/fqdn.map ) ) ]
+ [ ! -s /root/setup/fqdn.map ]
+ cat /root/setup/fqdn.map
+ + cut -f1
xargs
+ NODES=controller compute-1
+ cat /root/setup/fqdn.map
+ cut -f2
+ xargs
+ FQDNS=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ [ -z compute-1  ]
+ OTHERNODES=
+ [ controller = controller ]
+ continue
+ [ compute-1 = controller ]
+ OTHERNODES= compute-1
+ grep CONTROLLER /root/setup/settings
CONTROLLER="controller"
+ [ ! 0 = 0 ]
+ [ 0 -ne 0 ]
+ grep MIRRORSETUP /root/setup/settings
MIRRORSETUP=1
+ [ ! 0 -eq 0 ]
+ [ ! -f /root/setup/apt-updated -a 1 = 1 ]
+ [ ! -f /root/setup/cloudarchive-added -a 1 = 1 ]
+ [ ! -f /root/setup/apt-dist-upgraded -a 1 = 1 ]
+ maybe_install_packages crudini
+ [ ! 0 -eq 0 ]
+ are_packages_installed crudini
+ retval=1
+ [ ! -z crudini ]
+ dpkg -s crudini
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ ! -f /root/setup/nextsparesubnet ]
+ cat /root/setup/nextsparesubnet
+ NEXTSPARESUBNET=253
+ [ ! -f /root/setup/mgmt-hosts -o 0 -ne 0 ]
+ [ 1 -gt 0 ]
+ i=0
+ [ 0 -lt 1 ]
+ [ -f /root/setup/ipinfo.tun0 ]
+ expr 0 + 1
+ i=1
+ continue
+ [ 1 -lt 1 ]
+ echo 253
+ echo 253
+ [ 0 -gt 0 ]
+ [ ! -e /root/setup/info.mgmt ]
+ . /root/setup/info.mgmt
+ MGMTIP=192.168.0.1
+ MGMTNETMASK=255.255.0.0
+ MGMTPREFIX=16
+ MGMTVLAN=0
+ MGMTMAC=
+ MGMT_NETWORK_INTERFACE=tun0
+ MGMTVLANDEV=
+ MGMTVLANTAG=
+ [ -e /root/setup/info.flat-lan-1 ]
+ continue
+ [ ! -f /root/setup/neutron.vars ]
+ [ ! -f /etc/emulab/bossnode -a 18 -ge 14 -a 1 = 1 ]
+ [ 0 -ne 0 ]
+ which wget
+ GETTER=/usr/bin/wget
+ [ -n /usr/bin/wget ]
+ GETTEROUT=/usr/bin/wget --remote-encoding=unix -c -O
+ GETTER=/usr/bin/wget --remote-encoding=unix -c -N
+ GETTERLOGARG=-o
+ [ 0 -ne 0 ]
+ [ -f /root/setup/setup-network-plugin-openvswitch-done ]
+ logtstart network-plugin-openvswitch
+ area=network-plugin-openvswitch
+ echo network-plugin-openvswitch
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=network_plugin_openvswitch
+ date +%s
+ stamp=1557519396
+ date
+ date=Fri May 10 14:16:36 MDT 2019
+ eval LOGTIMESTART_network_plugin_openvswitch=1557519396
+ LOGTIMESTART_network_plugin_openvswitch=1557519396
+ echo START network-plugin-openvswitch 1557519396 Fri May 10 14:16:36 MDT 2019
+ [ -f /root/setup/settings ]
+ . /root/setup/settings
+ GENIUSER=1
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ STORAGEHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=compute-1 
+ MIRRORSETUP=1
+ DB_ROOT_PASS=ad12065d4a6fcf049d20
+ RABBIT_USER=openstack
+ RABBIT_PASS=0375d10f3c80e2774768
+ RABBIT_URL=rabbit://openstack:0375d10f3c80e2774768@controller
+ MEMCACHE_DONE=1
+ ETCD_DONE=1
+ ADMIN_API=adminapi
+ ADMIN_API_PASS=92748256c1e798f84f04
+ KEYSTONE_DBPASS=475bd45587c7b7ebea74
+ GLANCE_DBPASS=90422ef6606c271c3df3
+ GLANCE_PASS=8730282cd9b68ed94645
+ NOVA_DBPASS=8f182a0cc87fc8fe28e1
+ PLACEMENT_DBPASS=183a130e6978d3eefbd9
+ NOVA_PASS=70f8743910a95e3a54fe
+ PLACEMENT_PASS=c650059292e41b9adf49
+ NOVA_COMPUTENODES_DONE=1
+ NEUTRON_DBPASS=afeb2f23fd61fc63b2f7
+ NEUTRON_PASS=398d7129a22f6c80b3c3
+ NEUTRON_METADATA_SECRET=e49934e1536e9d8ba189
+ [ -f /root/setup/settings.local ]
+ . /root/setup/settings.local
+ STORAGEDIR=/storage
+ VGNAME=openstack-volumes
+ VGTOTAL=1976
+ LVM=1
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ CINDER_LV_SIZE=1457.25
+ . /root/setup/neutron.vars
+ network_types=flat,gre,vxlan
+ flat_networks=external,flat-lan-1
+ bridge_mappings=bridge_mappings=external:br-ex,flat-lan-1:br-flat-lan-1
+ extra_mappings=
+ network_vlan_ranges=network_vlan_ranges=
+ gre_local_ip=local_ip = 10.11.10.1
+ enable_tunneling=enable_tunneling = True
+ tunnel_types=tunnel_types = gre
+ interface_driver=neutron.agent.linux.interface.OVSInterfaceDriver
+ fwdriver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
+ cat
+ sysctl -p
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directory
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-ip6tables: No such file or directory
+ maybe_install_packages neutron-plugin-ml2 conntrack
+ [ ! 0 -eq 0 ]
+ are_packages_installed neutron-plugin-ml2 conntrack
+ retval=1
+ [ ! -z neutron-plugin-ml2 ]
+ dpkg -s neutron-plugin-ml2
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z conntrack ]
+ dpkg -s conntrack
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -ge 18 ]
+ maybe_install_packages neutron-openvswitch-agent
+ [ ! 0 -eq 0 ]
+ are_packages_installed neutron-openvswitch-agent
+ retval=1
+ [ ! -z neutron-openvswitch-agent ]
+ dpkg -s neutron-openvswitch-agent
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ controller != controller ]
+ crudini --del /etc/neutron/neutron.conf keystone_authtoken auth_host
+ crudini --del /etc/neutron/neutron.conf keystone_authtoken auth_port
+ crudini --del /etc/neutron/neutron.conf keystone_authtoken auth_protocol
+ crudini --set /etc/neutron/neutron.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/neutron/neutron.conf DEFAULT verbose False
+ crudini --set /etc/neutron/neutron.conf DEFAULT debug False
+ crudini --set /etc/neutron/neutron.conf DEFAULT core_plugin ml2
+ [ 1 -eq 1 -a 18 -ge 14 ]
+ crudini --set /etc/neutron/neutron.conf DEFAULT service_plugins router,metering,neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2
+ crudini --set /etc/neutron/neutron.conf DEFAULT allow_overlapping_ips True
+ crudini --set /etc/neutron/neutron.conf DEFAULT notification_driver messagingv2
+ [ 18 -lt 11 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/neutron/neutron.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ [ 18 -lt 11 ]
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken auth_type password
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken project_name service
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken username neutron
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken password 398d7129a22f6c80b3c3
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/neutron/neutron.conf keystone_authtoken memcached_servers controller:11211
+ [ 18 -ge 15 ]
+ crudini --set /etc/neutron/neutron.conf placement os_region_name RegionOne
+ crudini --set /etc/neutron/neutron.conf placement auth_url http://controller:5000/v3
+ crudini --set /etc/neutron/neutron.conf placement auth_type password
+ crudini --set /etc/neutron/neutron.conf placement project_domain_name default
+ crudini --set /etc/neutron/neutron.conf placement user_domain_name default
+ crudini --set /etc/neutron/neutron.conf placement project_name service
+ crudini --set /etc/neutron/neutron.conf placement username placement
+ crudini --set /etc/neutron/neutron.conf placement password c650059292e41b9adf49
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 type_drivers flat,gre,vxlan
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 tenant_network_types flat,gre,vxlan
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 mechanism_drivers openvswitch
+ extdrivers=
+ [ 18 -ge 14 ]
+ extdrivers=dns
+ [ -n dns ]
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 extension_drivers dns
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_flat flat_networks external,flat-lan-1
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_gre tunnel_id_ranges 1:1000
+ cat
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_vxlan vni_ranges 3000:4000
+ crudini --set /etc/neutron/plugins/ml2/openvswitch_agent.ini securitygroup enable_security_group True
+ crudini --set /etc/neutron/plugins/ml2/openvswitch_agent.ini securitygroup enable_ipset True
+ [ -n neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver ]
+ crudini --set /etc/neutron/plugins/ml2/openvswitch_agent.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup enable_security_group True
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup enable_ipset True
+ [ -n neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver ]
+ crudini --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
+ cat
+ [ 18 -ge 13 ]
+ cat
+ echo 130.127.133.243    controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us clnode234.clemson.cloudlab.us
+ [ 18 -le 12 ]
+ patch -d / -p0
patching file /usr/lib/python2.7/dist-packages/neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ofswitch.py
patching file /usr/lib/python2.7/dist-packages/neutron/plugins/ml2/drivers/openvswitch/agent/openflow/br_cookie.py
+ [ 18 -ge 12 -a 18 -lt 14 ]
+ modprobe bridge
+ echo bridge
+ service_restart openvswitch-switch
+ service=openvswitch-switch
+ [ 1 -eq 0 ]
+ systemctl restart openvswitch-switch
+ service_enable openvswitch-switch
+ service=openvswitch-switch
+ [ 1 -eq 0 ]
+ systemctl enable openvswitch-switch
Synchronizing state of openvswitch-switch.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable openvswitch-switch
+ service_restart nova-compute
+ service=nova-compute
+ [ 1 -eq 0 ]
+ systemctl restart nova-compute
Failed to restart nova-compute.service: Unit nova-compute.service not found.
+ service_restart neutron-ovs-cleanup
+ service=neutron-ovs-cleanup
+ [ 1 -eq 0 ]
+ systemctl restart neutron-ovs-cleanup
+ service_enable neutron-ovs-cleanup
+ service=neutron-ovs-cleanup
+ [ 1 -eq 0 ]
+ systemctl enable neutron-ovs-cleanup
Synchronizing state of neutron-ovs-cleanup.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable neutron-ovs-cleanup
+ [ 18 -lt 13 ]
+ service_restart neutron-openvswitch-agent
+ service=neutron-openvswitch-agent
+ [ 1 -eq 0 ]
+ systemctl restart neutron-openvswitch-agent
+ service_enable neutron-openvswitch-agent
+ service=neutron-openvswitch-agent
+ [ 1 -eq 0 ]
+ systemctl enable neutron-openvswitch-agent
Synchronizing state of neutron-openvswitch-agent.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable neutron-openvswitch-agent
+ [ 18 -gt 12 ]
+ echo *** Re-adding OVS anti-spoofing flows with reserved cookie...
*** Re-adding OVS anti-spoofing flows with reserved cookie...
+ i=30
+ [ ! -f /var/lib/neutron/ovs-default-flows.reserved_cookie -a 30 -gt 0 ]
+ sleep 1
+ expr 30 - 1
+ i=29
+ [ ! -f /var/lib/neutron/ovs-default-flows.reserved_cookie -a 29 -gt 0 ]
+ sleep 1
+ expr 29 - 1
+ i=28
+ [ ! -f /var/lib/neutron/ovs-default-flows.reserved_cookie -a 28 -gt 0 ]
+ sleep 5
+ service_restart neutron-openvswitch-agent
+ service=neutron-openvswitch-agent
+ [ 1 -eq 0 ]
+ systemctl restart neutron-openvswitch-agent
+ sleep 5
+ [ -f /var/lib/neutron/ovs-default-flows.reserved_cookie -a -f /etc/neutron/ovs-default-flows/br-ex ]
+ cat /var/lib/neutron/ovs-default-flows.reserved_cookie
+ cookie=5989062200986886586
+ cat /etc/neutron/ovs-default-flows/br-ex
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.1,in_port=1,actions=NORMAL
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.1,in_port=1,actions=NORMAL
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.133.243,actions=NORMAL
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.133.243,actions=NORMAL
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.210,actions=NORMAL
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.210,actions=NORMAL
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.226,actions=NORMAL
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.226,actions=NORMAL
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.238,actions=NORMAL
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.238,actions=NORMAL
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.239,actions=NORMAL
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.132.239,actions=NORMAL
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.133.243/22,in_port=1,actions=NORMAL
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.133.243/22,in_port=1,actions=NORMAL
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.133.243/22,actions=drop
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=130.127.133.243/22,actions=drop
+ echo cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=172.16.0.0/12,actions=drop
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,dl_type=0x0806,nw_proto=0x2,arp_spa=172.16.0.0/12,actions=drop
+ echo cookie=5989062200986886586,priority=0,actions=NORMAL
+ ovs-ofctl add-flow br-ex cookie=5989062200986886586,priority=0,actions=NORMAL
+ mv /etc/neutron/ovs-default-flows/br-ex.tmp /etc/neutron/ovs-default-flows/br-ex
+ touch /root/setup/setup-network-plugin-openvswitch-done
+ logtend network-plugin-openvswitch
+ area=network-plugin-openvswitch
+ echo network-plugin-openvswitch
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=network_plugin_openvswitch
+ date +%s
+ stamp=1557519416
+ date
+ date=Fri May 10 14:16:56 MDT 2019
+ eval tss=$LOGTIMESTART_network_plugin_openvswitch
+ tss=1557519396
+ expr 1557519416 - 1557519396
+ tsres=20
+ perl -e print 20 / 60.0 . "\n"
+ resmin=0.333333333333333
+ echo END network-plugin-openvswitch 1557519416 Fri May 10 14:16:56 MDT 2019
+ echo TOTAL network-plugin-openvswitch 20 0.333333333333333
+ exit 0
+ [ 0 -eq 0 ]
+ touch /root/setup/setup-network-plugin-done
+ logtend network-plugin
+ area=network-plugin
+ echo network-plugin
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=network_plugin
+ date +%s
+ stamp=1557519416
+ date
+ date=Fri May 10 14:16:56 MDT 2019
+ eval tss=$LOGTIMESTART_network_plugin
+ tss=1557519396
+ expr 1557519416 - 1557519396
+ tsres=20
+ perl -e print 20 / 60.0 . "\n"
+ resmin=0.333333333333333
+ echo END network-plugin 1557519416 Fri May 10 14:16:56 MDT 2019
+ echo TOTAL network-plugin 20 0.333333333333333
+ exit 0
+ . /root/setup/neutron.vars
+ network_types=flat,gre,vxlan
+ flat_networks=external,flat-lan-1
+ bridge_mappings=bridge_mappings=external:br-ex,flat-lan-1:br-flat-lan-1
+ extra_mappings=
+ network_vlan_ranges=network_vlan_ranges=
+ gre_local_ip=local_ip = 10.11.10.1
+ enable_tunneling=enable_tunneling = True
+ tunnel_types=tunnel_types = gre
+ interface_driver=neutron.agent.linux.interface.OVSInterfaceDriver
+ fwdriver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
+ [ 18 -ge 11 ]
+ maybe_install_packages python-oslo.service
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-oslo.service
+ retval=1
+ [ ! -z python-oslo.service ]
+ dpkg -s python-oslo.service
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ patch -d / -p0
patching file /usr/lib/python2.7/dist-packages/oslo_service/service.py
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
1 out of 1 hunk ignored -- saving rejects to file /usr/lib/python2.7/dist-packages/oslo_service/service.py.rej
+ cat
+ sysctl -p
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
+ maybe_install_packages neutron-l3-agent neutron-dhcp-agent neutron-metering-agent
+ [ ! 0 -eq 0 ]
+ are_packages_installed neutron-l3-agent neutron-dhcp-agent neutron-metering-agent
+ retval=1
+ [ ! -z neutron-l3-agent ]
+ dpkg -s neutron-l3-agent
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z neutron-dhcp-agent ]
+ dpkg -s neutron-dhcp-agent
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z neutron-metering-agent ]
+ dpkg -s neutron-metering-agent
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 1 -eq 1 -a 18 -ge 14 ]
+ maybe_install_packages neutron-lbaasv2-agent
+ [ ! 0 -eq 0 ]
+ are_packages_installed neutron-lbaasv2-agent
+ retval=1
+ [ ! -z neutron-lbaasv2-agent ]
+ dpkg -s neutron-lbaasv2-agent
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -eq 18 ]
+ crudini --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/lock
+ mkdir -p /var/lib/neutron/lock/
+ chown neutron:neutron /var/lib/neutron/lock
+ crudini --set /etc/neutron/l3_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.OVSInterfaceDriver
+ crudini --set /etc/neutron/l3_agent.ini DEFAULT use_namespaces True
+ [ openvswitch = openvswitch ]
+ crudini --set /etc/neutron/l3_agent.ini DEFAULT external_network_bridge br-ex
+ crudini --set /etc/neutron/l3_agent.ini DEFAULT verbose False
+ crudini --set /etc/neutron/l3_agent.ini DEFAULT debug False
+ crudini --set /etc/neutron/dhcp_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.OVSInterfaceDriver
+ crudini --set /etc/neutron/dhcp_agent.ini DEFAULT dhcp_driver neutron.agent.linux.dhcp.Dnsmasq
+ [ openvswitch = openvswitch ]
+ crudini --set /etc/neutron/dhcp_agent.ini DEFAULT use_namespaces True
+ [ 18 -ge ]
/local/repository/setup-networkmanager.sh: 90: [: -ge: argument expected
+ crudini --set /etc/neutron/dhcp_agent.ini DEFAULT verbose False
+ crudini --set /etc/neutron/dhcp_agent.ini DEFAULT debug False
+ crudini --set /etc/neutron/dhcp_agent.ini DEFAULT dnsmasq_config_file /etc/neutron/dnsmasq-neutron.conf
+ cat
+ pkill dnsmasq
+ [ 18 -lt 11 ]
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT auth_uri http://controller:5000
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT auth_url http://controller:5000/v2.0
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT auth_region RegionOne
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT auth_type password
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT project_domain_name default
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT user_domain_name default
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT project_name service
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT username neutron
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT password 398d7129a22f6c80b3c3
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT admin_tenant_name service
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT admin_user neutron
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT admin_password 398d7129a22f6c80b3c3
+ [ 18 -lt 16 ]
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT nova_metadata_host controller
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT metadata_proxy_shared_secret e49934e1536e9d8ba189
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT verbose False
+ crudini --set /etc/neutron/metadata_agent.ini DEFAULT debug False
+ crudini --set /etc/neutron/metering_agent.ini DEFAULT debug True
+ crudini --set /etc/neutron/metering_agent.ini DEFAULT driver neutron.services.metering.drivers.iptables.iptables_driver.IptablesMeteringDriver
+ crudini --set /etc/neutron/metering_agent.ini DEFAULT measure_interval 30
+ crudini --set /etc/neutron/metering_agent.ini DEFAULT report_interval 300
+ crudini --set /etc/neutron/metering_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.OVSInterfaceDriver
+ crudini --set /etc/neutron/metering_agent.ini DEFAULT use_namespaces True
+ [ 1 -eq 1 -a 18 -ge 14 ]
+ crudini --set /etc/neutron/lbaas_agent.ini DEFAULT device_driver neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver
+ [ openvswitch = linuxbridge ]
+ crudini --set /etc/neutron/lbaas_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.OVSInterfaceDriver
+ crudini --set /etc/neutron/lbaas_agent.ini haproxy user_group haproxy
+ crudini --set /etc/neutron/neutron_lbaas.conf service_providers service_provider LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default
+ service_restart neutron-l3-agent
+ service=neutron-l3-agent
+ [ 1 -eq 0 ]
+ systemctl restart neutron-l3-agent
+ service_enable neutron-l3-agent
+ service=neutron-l3-agent
+ [ 1 -eq 0 ]
+ systemctl enable neutron-l3-agent
Synchronizing state of neutron-l3-agent.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable neutron-l3-agent
+ service_restart neutron-dhcp-agent
+ service=neutron-dhcp-agent
+ [ 1 -eq 0 ]
+ systemctl restart neutron-dhcp-agent
+ service_enable neutron-dhcp-agent
+ service=neutron-dhcp-agent
+ [ 1 -eq 0 ]
+ systemctl enable neutron-dhcp-agent
Synchronizing state of neutron-dhcp-agent.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable neutron-dhcp-agent
+ service_restart neutron-metadata-agent
+ service=neutron-metadata-agent
+ [ 1 -eq 0 ]
+ systemctl restart neutron-metadata-agent
+ service_enable neutron-metadata-agent
+ service=neutron-metadata-agent
+ [ 1 -eq 0 ]
+ systemctl enable neutron-metadata-agent
Synchronizing state of neutron-metadata-agent.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable neutron-metadata-agent
+ service_restart neutron-metering-agent
+ service=neutron-metering-agent
+ [ 1 -eq 0 ]
+ systemctl restart neutron-metering-agent
+ service_enable neutron-metering-agent
+ service=neutron-metering-agent
+ [ 1 -eq 0 ]
+ systemctl enable neutron-metering-agent
Synchronizing state of neutron-metering-agent.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable neutron-metering-agent
+ [ 1 -eq 1 -a 18 -ge 14 ]
+ service_restart neutron-lbaasv2-agent
+ service=neutron-lbaasv2-agent
+ [ 1 -eq 0 ]
+ systemctl restart neutron-lbaasv2-agent
+ service_enable neutron-lbaasv2-agent
+ service=neutron-lbaasv2-agent
+ [ 1 -eq 0 ]
+ systemctl enable neutron-lbaasv2-agent
Synchronizing state of neutron-lbaasv2-agent.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable neutron-lbaasv2-agent
+ touch /root/setup/setup-networkmanager-done
+ logtend networkmanager
+ area=networkmanager
+ echo networkmanager
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=networkmanager
+ date +%s
+ stamp=1557519421
+ date
+ date=Fri May 10 14:17:01 MDT 2019
+ eval tss=$LOGTIMESTART_networkmanager
+ tss=1557519395
+ expr 1557519421 - 1557519395
+ tsres=26
+ perl -e print 26 / 60.0 . "\n"
+ resmin=0.433333333333333
+ echo END networkmanager 1557519421 Fri May 10 14:17:01 MDT 2019
+ echo TOTAL networkmanager 26 0.433333333333333
+ exit 0
+ echo NEUTRON_NETWORKMANAGER_DONE="1"
+ logtend neutron-networkmanager
+ area=neutron-networkmanager
+ echo neutron-networkmanager
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=neutron_networkmanager
+ date +%s
+ stamp=1557519421
+ date
+ date=Fri May 10 14:17:01 MDT 2019
+ eval tss=$LOGTIMESTART_neutron_networkmanager
+ tss=1557519395
+ expr 1557519421 - 1557519395
+ tsres=26
+ perl -e print 26 / 60.0 . "\n"
+ resmin=0.433333333333333
+ echo END neutron-networkmanager 1557519421 Fri May 10 14:17:01 MDT 2019
+ echo TOTAL neutron-networkmanager 26 0.433333333333333
+ [ -z  ]
+ logtstart neutron-computenodes
+ area=neutron-computenodes
+ echo neutron-computenodes
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=neutron_computenodes
+ date +%s
+ stamp=1557519421
+ date
+ date=Fri May 10 14:17:01 MDT 2019
+ eval LOGTIMESTART_neutron_computenodes=1557519421
+ LOGTIMESTART_neutron_computenodes=1557519421
+ echo START neutron-computenodes 1557519421 Fri May 10 14:17:01 MDT 2019
+ NEUTRON_COMPUTENODES_DONE=1
+ PHOSTS=
+ mkdir -p /root/setup/pssh.setup-compute-network.stdout /root/setup/pssh.setup-compute-network.stderr
+ getfqdn compute-1
+ n=compute-1
+ cat /root/setup/fqdn.map
+ grep -E compute-1\s
+ cut -f2
+ fqdn=compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ echo compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ fqdn=compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ scp -o StrictHostKeyChecking=no /root/setup/settings compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us:/root/setup/settings
+ PHOSTS= -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ echo *** Setting up Compute network on nodes:  -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
*** Setting up Compute network on nodes:  -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ /usr/bin/parallel-ssh -t 0 -O StrictHostKeyChecking=no -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us -o /root/setup/pssh.setup-compute-network.stdout -e /root/setup/pssh.setup-compute-network.stderr /local/repository/setup-compute-network.sh
[1] 14:17:28 [SUCCESS] compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ touch /root/setup/compute-network-done-compute-1
+ service_restart neutron-server
+ service=neutron-server
+ [ 1 -eq 0 ]
+ systemctl restart neutron-server
+ retries=30
+ [ 30 -gt 0 ]
+ neutron net-list
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.

+ [ 0 -eq 0 ]
+ break
+ echo NEUTRON_COMPUTENODES_DONE="1"
+ logtend neutron-computenodes
+ area=neutron-computenodes
+ + echo neutron-computenodes
sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=neutron_computenodes
+ date +%s
+ stamp=1557519451
+ date
+ date=Fri May 10 14:17:31 MDT 2019
+ eval tss=$LOGTIMESTART_neutron_computenodes
+ tss=1557519421
+ expr 1557519451 - 1557519421
+ tsres=30
+ perl -e print 30 / 60.0 . "\n"
+ resmin=0.5
+ echo END neutron-computenodes 1557519451 Fri May 10 14:17:31 MDT 2019
+ echo TOTAL neutron-computenodes 30 0.5
+ [ -z  ]
+ logtstart neutron-network-ext-float
+ area=neutron-network-ext-float
+ echo neutron-network-ext-float
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=neutron_network_ext_float
+ date +%s
+ stamp=1557519451
+ date
+ date=Fri May 10 14:17:31 MDT 2019
+ eval LOGTIMESTART_neutron_network_ext_float=1557519451
+ LOGTIMESTART_neutron_network_ext_float=1557519451
+ echo START neutron-network-ext-float 1557519451 Fri May 10 14:17:31 MDT 2019
+ NEUTRON_NETWORKS_DONE=1
+ [ rocky = kilo -o rocky = liberty ]
+ neutron net-create ext-net --shared --router:external True --provider:physical_network external --provider:network_type flat
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
Created a new network:
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | True                                 |
| availability_zone_hints   |                                      |
| availability_zones        |                                      |
| created_at                | 2019-05-10T20:17:33Z                 |
| description               |                                      |
| dns_domain                |                                      |
| id                        | a018224c-7606-441a-99c8-c9f4129be687 |
| ipv4_address_scope        |                                      |
| ipv6_address_scope        |                                      |
| is_default                | False                                |
| mtu                       | 1500                                 |
| name                      | ext-net                              |
| project_id                | c71f3ce86c4e437abf2407f488c55054     |
| provider:network_type     | flat                                 |
| provider:physical_network | external                             |
| provider:segmentation_id  |                                      |
| revision_number           | 0                                    |
| router:external           | True                                 |
| shared                    | True                                 |
| status                    | ACTIVE                               |
| subnets                   |                                      |
| tags                      |                                      |
| tenant_id                 | c71f3ce86c4e437abf2407f488c55054     |
| updated_at                | 2019-05-10T20:17:33Z                 |
+---------------------------+--------------------------------------+
+ . /root/setup/ctlnet.vars
+ ctlip=130.127.133.243
+ ctlmac=3c:fd:fe:55:45:78
+ ctlstrippedmac=3cfdfe554578
+ ctlnetmask=255.255.252.0
+ ctlgw=130.127.132.1
+ ctlnet=130.127.132.0/22
+ ctlprefix=22
+ neutron subnet-create ext-net --name ext-subnet --disable-dhcp --gateway 130.127.132.1 130.127.132.0/22
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
Created a new subnet:
+-------------------+------------------------------------------------------+
| Field             | Value                                                |
+-------------------+------------------------------------------------------+
| allocation_pools  | {"start": "130.127.132.2", "end": "130.127.135.254"} |
| cidr              | 130.127.132.0/22                                     |
| created_at        | 2019-05-10T20:17:35Z                                 |
| description       |                                                      |
| dns_nameservers   |                                                      |
| enable_dhcp       | False                                                |
| gateway_ip        | 130.127.132.1                                        |
| host_routes       |                                                      |
| id                | 7d7e574b-7932-46b8-b2ba-d6e3be0e4182                 |
| ip_version        | 4                                                    |
| ipv6_address_mode |                                                      |
| ipv6_ra_mode      |                                                      |
| name              | ext-subnet                                           |
| network_id        | a018224c-7606-441a-99c8-c9f4129be687                 |
| project_id        | c71f3ce86c4e437abf2407f488c55054                     |
| revision_number   | 0                                                    |
| service_types     |                                                      |
| subnetpool_id     |                                                      |
| tags              |                                                      |
| tenant_id         | c71f3ce86c4e437abf2407f488c55054                     |
| updated_at        | 2019-05-10T20:17:35Z                                 |
+-------------------+------------------------------------------------------+
+ neutron subnet-show ext-subnet
+ awk / id / {print $4}
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
+ SID=7d7e574b-7932-46b8-b2ba-d6e3be0e4182
+ [ ! -z 7d7e574b-7932-46b8-b2ba-d6e3be0e4182 ]
+ echo delete from ipallocationpools where subnet_id='7d7e574b-7932-46b8-b2ba-d6e3be0e4182'
+ mysql --password=ad12065d4a6fcf049d20 neutron
+ + echo insert into ipallocationpools values (UUID(),'7d7e574b-7932-46b8-b2ba-d6e3be0e4182','130.127.132.210','130.127.132.210')mysql
 --password=ad12065d4a6fcf049d20 neutron
+ + echo insert into ipallocationpools values (UUID(),'7d7e574b-7932-46b8-b2ba-d6e3be0e4182','130.127.132.226','130.127.132.226')
mysql --password=ad12065d4a6fcf049d20 neutron
+ + echo insert into ipallocationpools values (UUID(),'7d7e574b-7932-46b8-b2ba-d6e3be0e4182','130.127.132.238','130.127.132.238')
mysql --password=ad12065d4a6fcf049d20 neutron
+ mysql --password=ad12065d4a6fcf049d20 neutron
+ echo insert into ipallocationpools values (UUID(),'7d7e574b-7932-46b8-b2ba-d6e3be0e4182','130.127.132.239','130.127.132.239')
+ [ 18 -ge 14 ]
+ echo select id from ipamsubnets where neutron_subnet_id='7d7e574b-7932-46b8-b2ba-d6e3be0e4182'
+ mysql -N --password=afeb2f23fd61fc63b2f7 neutron
+ IPAMSID=95318a12-bced-48b6-a341-18453474cf1c
+ [ -z 95318a12-bced-48b6-a341-18453474cf1c ]
+ echo delete from ipamallocationpools where ipam_subnet_id='95318a12-bced-48b6-a341-18453474cf1c'
+ mysql --password=ad12065d4a6fcf049d20 neutron
+ echo insert into ipamallocationpools values (UUID(),'95318a12-bced-48b6-a341-18453474cf1c','130.127.132.210','130.127.132.210')
+ mysql --password=ad12065d4a6fcf049d20 neutron
+ echo insert into ipamallocationpools values (UUID(),'95318a12-bced-48b6-a341-18453474cf1c','130.127.132.226','130.127.132.226')
+ mysql --password=ad12065d4a6fcf049d20 neutron
+ echo insert into ipamallocationpools values (UUID(),'95318a12-bced-48b6-a341-18453474cf1c','130.127.132.238','130.127.132.238')
+ mysql --password=ad12065d4a6fcf049d20 neutron
+ echo insert into ipamallocationpools values (UUID(),'95318a12-bced-48b6-a341-18453474cf1c','130.127.132.239','130.127.132.239')
+ mysql --password=ad12065d4a6fcf049d20 neutron
+ echo NEUTRON_NETWORKS_DONE="1"
+ logtend neutron-network-ext-float
+ area=neutron-network-ext-float
+ echo neutron-network-ext-float
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=neutron_network_ext_float
+ date +%s
+ stamp=1557519457
+ date
+ date=Fri May 10 14:17:37 MDT 2019
+ eval tss=$LOGTIMESTART_neutron_network_ext_float
+ tss=1557519451
+ expr 1557519457 - 1557519451
+ tsres=6
+ perl -e print 6 / 60.0 . "\n"
+ resmin=0.1
+ echo END neutron-network-ext-float 1557519457 Fri May 10 14:17:37 MDT 2019
+ echo TOTAL neutron-network-ext-float 6 0.1
+ [ -z  ]
+ logtstart horizon
+ area=horizon
+ echo horizon
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=horizon
+ date +%s
+ stamp=1557519457
+ date
+ date=Fri May 10 14:17:37 MDT 2019
+ eval LOGTIMESTART_horizon=1557519457
+ LOGTIMESTART_horizon=1557519457
+ echo START horizon 1557519457 Fri May 10 14:17:37 MDT 2019
+ DASHBOARD_DONE=1
+ maybe_install_packages openstack-dashboard apache2 libapache2-mod-wsgi
+ [ ! 0 -eq 0 ]
+ are_packages_installed openstack-dashboard apache2 libapache2-mod-wsgi
+ retval=1
+ [ ! -z openstack-dashboard ]
+ dpkg -s openstack-dashboard
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z apache2 ]
+ dpkg -s apache2
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z libapache2-mod-wsgi ]
+ dpkg -s libapache2-mod-wsgi
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ echo 
+ sed -i -e s/OPENSTACK_HOST.*=.*$/OPENSTACK_HOST = "controller"/ /etc/openstack-dashboard/local_settings.py
+ sed -i -e s/^.*ALLOWED_HOSTS = \[.*$/ALLOWED_HOSTS = \["*"\]/ /etc/openstack-dashboard/local_settings.py
+ grep -q ^#[ \t]*SESSION_TIMEOUT /etc/openstack-dashboard/local_settings.py
+ [ 1 -eq 0 ]
+ echo SESSION_TIMEOUT = 14400
+ grep -q ^#[ \t]*OPENSTACK_KEYSTONE_DEFAULT_ROLE /etc/openstack-dashboard/local_settings.py
+ [ 1 -eq 0 ]
+ echo OPENSTACK_KEYSTONE_DEFAULT_ROLE = "user"
+ [ 18 -ge 11 ]
+ cat
+ [ 18 -ge 13 ]
+ cat
+ [ x3 = x3 ]
+ IDVERS=3
+ grep ^#[ \t]*OPENSTACK_KEYSTONE_URL /etc/openstack-dashboard/local_settings.py
#    OPENSTACK_KEYSTONE_URL: 'RegionTwo'
+ [ 0 -eq 0 ]
+ sed -i -e s|^#.*OPENSTACK_KEYSTONE_URL.*=.*$|OPENSTACK_KEYSTONE_URL = "http://%s:5000/v3" % OPENSTACK_HOST| /etc/openstack-dashboard/local_settings.py
+ grep ^#[ \t]*OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT /etc/openstack-dashboard/local_settings.py
#OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = False
+ [ 0 -eq 0 ]
+ sed -i -e s|^#.*OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT.*=.*$|OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True| /etc/openstack-dashboard/local_settings.py
+ grep ^#[ \t]*OPENSTACK_KEYSTONE_DEFAULT_DOMAIN /etc/openstack-dashboard/local_settings.py
#OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = 'Default'
+ [ 0 -eq 0 ]
+ sed -i -e s|^#.*OPENSTACK_KEYSTONE_DEFAULT_DOMAIN.*=.*$|OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = 'default'| /etc/openstack-dashboard/local_settings.py
+ [ 18 -ge 13 ]
+ IMAGEVERS="image": 2,
+ cat
+ [ 18 -eq 15 ]
+ [ 18 -ge 16 ]
+ chown horizon.www-data /var/lib/openstack-dashboard/secret_key
+ [ 18 -ge 14 ]
+ patch -p0 -d /
patching file /usr/share/openstack-dashboard/openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.js
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
1 out of 1 hunk ignored -- saving rejects to file /usr/share/openstack-dashboard/openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.js.rej
+ service_restart apache2
+ service=apache2
+ [ 1 -eq 0 ]
+ systemctl restart apache2
+ service_enable apache2
+ service=apache2
+ [ 1 -eq 0 ]
+ systemctl enable apache2
Synchronizing state of apache2.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable apache2
+ service_restart memcached
+ service=memcached
+ [ 1 -eq 0 ]
+ systemctl restart memcached
+ echo DASHBOARD_DONE="1"
+ logtend horizon
+ area=horizon
+ echo horizon
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=horizon
+ date +%s
+ stamp=1557519458
+ date
+ date=Fri May 10 14:17:38 MDT 2019
+ eval tss=$LOGTIMESTART_horizon
+ tss=1557519457
+ expr 1557519458 - 1557519457
+ tsres=1
+ perl -e print 1 / 60.0 . "\n"
+ resmin=0.0166666666666667
+ echo END horizon 1557519458 Fri May 10 14:17:38 MDT 2019
+ echo TOTAL horizon 1 0.0166666666666667
+ [ -z  ]
+ logtstart cinder
+ area=cinder
+ echo cinder
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=cinder
+ date +%s
+ stamp=1557519458
+ date
+ date=Fri May 10 14:17:38 MDT 2019
+ eval LOGTIMESTART_cinder=1557519458
+ LOGTIMESTART_cinder=1557519458
+ echo START cinder 1557519458 Fri May 10 14:17:38 MDT 2019
+ openssl rand -hex 10
+ CINDER_DBPASS=5a3b8b798010f2d95066
+ openssl rand -hex 10
+ CINDER_PASS=f61e53efc351839e2af6
+ echo create database cinder
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on cinder.* to 'cinder'@'localhost' identified by '5a3b8b798010f2d95066'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on cinder.* to 'cinder'@'%' identified by '5a3b8b798010f2d95066'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -eq 10 ]
+ __openstack user create --domain default --password f61e53efc351839e2af6 cinder
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password f61e53efc351839e2af6 cinder
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 5b56cba5f3fe4548be5df43255622729 |
| name                | cinder                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user cinder --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user cinder --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name cinder --description OpenStack Block Storage Service volume
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name cinder --description OpenStack Block Storage Service volume
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Block Storage Service  |
| enabled     | True                             |
| id          | 7d0c73fce212485ca27b2d2025c6ea10 |
| name        | cinder                           |
| type        | volume                           |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name cinderv2 --description OpenStack Block Storage Service volumev2
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name cinderv2 --description OpenStack Block Storage Service volumev2
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Block Storage Service  |
| enabled     | True                             |
| id          | 459cb34fcfcd434da4e62ff80b5af1d8 |
| name        | cinderv2                         |
| type        | volumev2                         |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ [ 18 -lt 15 ]
+ __openstack endpoint create --region RegionOne volumev2 public http://controller:8776/v2/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne volumev2 public http://controller:8776/v2/%(project_id)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | 3b95a9951fa34e28b945c2d0c761005e         |
| interface    | public                                   |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | 459cb34fcfcd434da4e62ff80b5af1d8         |
| service_name | cinderv2                                 |
| service_type | volumev2                                 |
| url          | http://controller:8776/v2/%(project_id)s |
+--------------+------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne volumev2 internal http://controller:8776/v2/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne volumev2 internal http://controller:8776/v2/%(project_id)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | 83760482e4af4d7898a3838a5e732070         |
| interface    | internal                                 |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | 459cb34fcfcd434da4e62ff80b5af1d8         |
| service_name | cinderv2                                 |
| service_type | volumev2                                 |
| url          | http://controller:8776/v2/%(project_id)s |
+--------------+------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne volumev2 admin http://controller:8776/v2/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne volumev2 admin http://controller:8776/v2/%(project_id)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | af5925dab31242aea6011586dce938ed         |
| interface    | admin                                    |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | 459cb34fcfcd434da4e62ff80b5af1d8         |
| service_name | cinderv2                                 |
| service_type | volumev2                                 |
| url          | http://controller:8776/v2/%(project_id)s |
+--------------+------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name cinderv3 --description OpenStack Block Storage Service volumev3
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name cinderv3 --description OpenStack Block Storage Service volumev3
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Block Storage Service  |
| enabled     | True                             |
| id          | cbadc9c6f4a84882a99b357c8ff21c0f |
| name        | cinderv3                         |
| type        | volumev3                         |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne volumev3 public http://controller:8776/v3/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne volumev3 public http://controller:8776/v3/%(project_id)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | fc476cf4444a4df9a68691bfd448999b         |
| interface    | public                                   |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | cbadc9c6f4a84882a99b357c8ff21c0f         |
| service_name | cinderv3                                 |
| service_type | volumev3                                 |
| url          | http://controller:8776/v3/%(project_id)s |
+--------------+------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne volumev3 internal http://controller:8776/v3/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne volumev3 internal http://controller:8776/v3/%(project_id)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | f0f307b9bf734b0b89927af14cbce313         |
| interface    | internal                                 |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | cbadc9c6f4a84882a99b357c8ff21c0f         |
| service_name | cinderv3                                 |
| service_type | volumev3                                 |
| url          | http://controller:8776/v3/%(project_id)s |
+--------------+------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne volumev3 admin http://controller:8776/v3/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne volumev3 admin http://controller:8776/v3/%(project_id)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | 573ed5b14f2b4098b4e8dcb451b326ce         |
| interface    | admin                                    |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | cbadc9c6f4a84882a99b357c8ff21c0f         |
| service_name | cinderv3                                 |
| service_type | volumev3                                 |
| url          | http://controller:8776/v3/%(project_id)s |
+--------------+------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages cinder-api cinder-scheduler python-cinderclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed cinder-api cinder-scheduler python-cinderclient
+ retval=1
+ [ ! -z cinder-api ]
+ dpkg -s cinder-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z cinder-scheduler ]
+ dpkg -s cinder-scheduler
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-cinderclient ]
+ dpkg -s python-cinderclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ crudini --set /etc/cinder/cinder.conf database connection mysql+pymysql://cinder:5a3b8b798010f2d95066@controller/cinder
+ crudini --del /etc/cinder/cinder.conf keystone_authtoken auth_host
+ crudini --del /etc/cinder/cinder.conf keystone_authtoken auth_port
+ crudini --del /etc/cinder/cinder.conf keystone_authtoken auth_protocol
+ crudini --set /etc/cinder/cinder.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/cinder/cinder.conf DEFAULT verbose False
+ crudini --set /etc/cinder/cinder.conf DEFAULT debug False
+ crudini --set /etc/cinder/cinder.conf DEFAULT my_ip 192.168.0.1
+ [ 18 -lt 11 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/cinder/cinder.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ [ 18 -lt 11 ]
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken auth_type password
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken project_name service
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken username cinder
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken password f61e53efc351839e2af6
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/cinder/cinder.conf keystone_authtoken memcached_servers controller:11211
+ crudini --set /etc/cinder/cinder.conf DEFAULT glance_host controller
+ [ 18 -eq 11 ]
+ [ 18 -ge 12 ]
+ crudini --set /etc/cinder/cinder.conf oslo_concurrency lock_path /var/lib/cinder/tmp
+ [ 18 -ge 12 ]
+ crudini --set /etc/nova/nova.conf cinder os_region_name RegionOne
+ sed -i -e s/^\(.*volume_group.*=.*\)$/#\1/ /etc/cinder/cinder.conf
+ [ 18 -eq 16 ]
+ su -s /bin/sh -c /usr/bin/cinder-manage db sync cinder
2019-05-10 14:18:01.008 2905 INFO migrate.versioning.api [-] 84 -> 85... [00m
2019-05-10 14:18:11.441 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:11.441 2905 INFO migrate.versioning.api [-] 85 -> 86... [00m
2019-05-10 14:18:11.541 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:11.541 2905 INFO migrate.versioning.api [-] 86 -> 87... [00m
2019-05-10 14:18:11.935 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:11.936 2905 INFO migrate.versioning.api [-] 87 -> 88... [00m
2019-05-10 14:18:13.102 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:13.102 2905 INFO migrate.versioning.api [-] 88 -> 89... [00m
2019-05-10 14:18:13.515 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:13.515 2905 INFO migrate.versioning.api [-] 89 -> 90... [00m
2019-05-10 14:18:14.093 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.093 2905 INFO migrate.versioning.api [-] 90 -> 91... [00m
2019-05-10 14:18:14.430 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.430 2905 INFO migrate.versioning.api [-] 91 -> 92... [00m
2019-05-10 14:18:14.464 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.464 2905 INFO migrate.versioning.api [-] 92 -> 93... [00m
2019-05-10 14:18:14.497 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.497 2905 INFO migrate.versioning.api [-] 93 -> 94... [00m
2019-05-10 14:18:14.539 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.539 2905 INFO migrate.versioning.api [-] 94 -> 95... [00m
2019-05-10 14:18:14.576 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.577 2905 INFO migrate.versioning.api [-] 95 -> 96... [00m
2019-05-10 14:18:14.648 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.648 2905 INFO migrate.versioning.api [-] 96 -> 97... [00m
2019-05-10 14:18:14.706 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.706 2905 INFO migrate.versioning.api [-] 97 -> 98... [00m
2019-05-10 14:18:14.933 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:14.933 2905 INFO migrate.versioning.api [-] 98 -> 99... [00m
2019-05-10 14:18:15.285 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:15.286 2905 INFO migrate.versioning.api [-] 99 -> 100... [00m
2019-05-10 14:18:15.288 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding attachment_specs_attachment_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.290 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding cgsnapshots_consistencygroup_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.291 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding group_snapshots_group_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.292 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding group_type_specs_group_type_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.294 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding group_volume_type_mapping_group_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.295 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding group_volume_type_mapping_volume_type_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.297 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding quality_of_service_specs_specs_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.298 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding reservations_allocated_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.299 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding reservations_usage_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.301 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding snapshot_metadata_snapshot_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.302 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding snapshots_cgsnapshot_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.304 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding snapshots_group_snapshot_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.305 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding snapshots_volume_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.307 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding transfers_volume_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.308 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volume_admin_metadata_volume_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.310 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volume_attachment_volume_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.311 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volume_glance_metadata_snapshot_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.313 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volume_glance_metadata_volume_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.314 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volume_metadata_volume_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.315 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volume_type_extra_specs_volume_type_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.317 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volume_types_qos_specs_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.318 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volumes_consistencygroup_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.320 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding volumes_group_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.322 2905 INFO 100_add_foreign_key_indexes [-] Skipped adding workers_service_id_idx because an equivalent index already exists.[00m
2019-05-10 14:18:15.344 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:15.344 2905 INFO migrate.versioning.api [-] 100 -> 101... [00m
2019-05-10 14:18:15.377 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:15.378 2905 INFO migrate.versioning.api [-] 101 -> 102... [00m
2019-05-10 14:18:15.731 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:15.731 2905 INFO migrate.versioning.api [-] 102 -> 103... [00m
2019-05-10 14:18:16.386 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:16.386 2905 INFO migrate.versioning.api [-] 103 -> 104... [00m
2019-05-10 14:18:16.940 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:16.940 2905 INFO migrate.versioning.api [-] 104 -> 105... [00m
2019-05-10 14:18:17.209 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:17.209 2905 INFO migrate.versioning.api [-] 105 -> 106... [00m
2019-05-10 14:18:17.242 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:17.243 2905 INFO migrate.versioning.api [-] 106 -> 107... [00m
2019-05-10 14:18:17.267 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:17.267 2905 INFO migrate.versioning.api [-] 107 -> 108... [00m
2019-05-10 14:18:17.301 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:17.301 2905 INFO migrate.versioning.api [-] 108 -> 109... [00m
2019-05-10 14:18:17.334 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:17.334 2905 INFO migrate.versioning.api [-] 109 -> 110... [00m
2019-05-10 14:18:17.376 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:17.377 2905 INFO migrate.versioning.api [-] 110 -> 111... [00m
2019-05-10 14:18:17.561 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:17.561 2905 INFO migrate.versioning.api [-] 111 -> 112... [00m
2019-05-10 14:18:18.074 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:18.074 2905 INFO migrate.versioning.api [-] 112 -> 113... [00m
2019-05-10 14:18:18.275 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:18.275 2905 INFO migrate.versioning.api [-] 113 -> 114... [00m
2019-05-10 14:18:19.417 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:19.417 2905 INFO migrate.versioning.api [-] 114 -> 115... [00m
2019-05-10 14:18:19.905 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:19.906 2905 INFO migrate.versioning.api [-] 115 -> 116... [00m
2019-05-10 14:18:20.199 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:20.199 2905 INFO migrate.versioning.api [-] 116 -> 117... [00m
2019-05-10 14:18:20.534 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:20.534 2905 INFO migrate.versioning.api [-] 117 -> 118... [00m
2019-05-10 14:18:20.573 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:20.573 2905 INFO migrate.versioning.api [-] 118 -> 119... [00m
2019-05-10 14:18:20.635 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:20.635 2905 INFO migrate.versioning.api [-] 119 -> 120... [00m
2019-05-10 14:18:20.659 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:20.660 2905 INFO migrate.versioning.api [-] 120 -> 121... [00m
2019-05-10 14:18:20.693 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:20.693 2905 INFO migrate.versioning.api [-] 121 -> 122... [00m
2019-05-10 14:18:20.735 2905 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:18:20.736 2905 INFO migrate.versioning.api [-] 122 -> 123... [00m
2019-05-10 14:18:21.235 2905 INFO migrate.versioning.api [-] done[00m
+ service_restart cinder-scheduler
+ service=cinder-scheduler
+ [ 1 -eq 0 ]
+ systemctl restart cinder-scheduler
+ service_enable cinder-scheduler
+ service=cinder-scheduler
+ [ 1 -eq 0 ]
+ systemctl enable cinder-scheduler
Synchronizing state of cinder-scheduler.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable cinder-scheduler
+ [ 18 -ge 15 ]
+ a2enconf cinder-wsgi.conf
Conf cinder-wsgi already enabled
+ service_restart apache2
+ service=apache2
+ [ 1 -eq 0 ]
+ systemctl restart apache2
+ rm -f /var/lib/cinder/cinder.sqlite
+ echo CINDER_DBPASS="5a3b8b798010f2d95066"
+ echo CINDER_PASS="f61e53efc351839e2af6"
+ logtend cinder
+ area=cinder
+ echo cinder
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=cinder
+ date +%s
+ stamp=1557519502
+ date
+ date=Fri May 10 14:18:22 MDT 2019
+ eval tss=$LOGTIMESTART_cinder
+ tss=1557519458
+ expr 1557519502 - 1557519458
+ tsres=44
+ perl -e print 44 / 60.0 . "\n"
+ resmin=0.733333333333333
+ echo END cinder 1557519502 Fri May 10 14:18:22 MDT 2019
+ echo TOTAL cinder 44 0.733333333333333
+ [ -z  ]
+ logtstart cinder-host
+ area=cinder-host
+ echo cinder-host
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=cinder_host
+ date +%s
+ stamp=1557519502
+ date
+ date=Fri May 10 14:18:22 MDT 2019
+ eval LOGTIMESTART_cinder_host=1557519502
+ LOGTIMESTART_cinder_host=1557519502
+ echo START cinder-host 1557519502 Fri May 10 14:18:22 MDT 2019
+ getfqdn ctl
+ n=ctl
+ cat /root/setup/fqdn.map
+ grep -E ctl\s
+ cut -f2
+ fqdn=
+ echo
+ fqdn=
+ [ ctl = controller ]
+ scp -o StrictHostKeyChecking=no /root/setup/settings :/root/setup/settings
cp: cannot create regular file ':/root/setup/settings': No such file or directory
+ ssh -o StrictHostKeyChecking=no /local/repository/setup-storage.sh
Pseudo-terminal will not be allocated because stdin is not a terminal.
ssh: Could not resolve hostname /local/repository/setup-storage.sh: Name or service not known
+ echo STORAGE_HOST_DONE="1"
+ logtend cinder-host
+ area=cinder-host
+ echo cinder-host
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=cinder_host
+ date +%s
+ stamp=1557519502
+ date
+ date=Fri May 10 14:18:22 MDT 2019
+ eval tss=$LOGTIMESTART_cinder_host
+ tss=1557519502
+ expr 1557519502 - 1557519502
+ tsres=0
+ perl -e print 0 / 60.0 . "\n"
+ resmin=0
+ echo END cinder-host 1557519502 Fri May 10 14:18:22 MDT 2019
+ echo TOTAL cinder-host 0 0
+ [ 18 -ge 13 -a -z  ]
+ logtstart manila
+ area=manila
+ echo manila
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=manila
+ date +%s
+ stamp=1557519502
+ date
+ date=Fri May 10 14:18:22 MDT 2019
+ eval LOGTIMESTART_manila=1557519502
+ LOGTIMESTART_manila=1557519502
+ echo START manila 1557519502 Fri May 10 14:18:22 MDT 2019
+ openssl rand -hex 10
+ MANILA_DBPASS=b2bd23d86e44b7407596
+ openssl rand -hex 10
+ MANILA_PASS=2eade20daad922a8057c
+ echo create database manila
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on manila.* to 'manila'@'localhost' identified by 'b2bd23d86e44b7407596'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on manila.* to 'manila'@'%' identified by 'b2bd23d86e44b7407596'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ __openstack user create --domain default --password 2eade20daad922a8057c manila
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 2eade20daad922a8057c manila
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 08dbbb09b1844de0930597669bd408fe |
| name                | manila                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user manila --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user manila --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name manila --description OpenStack Shared File Systems share
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name manila --description OpenStack Shared File Systems share
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Shared File Systems    |
| enabled     | True                             |
| id          | 307da50f171e43f2bfbb38e9526aa1b9 |
| name        | manila                           |
| type        | share                            |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name manilav2 --description OpenStack Shared File Systems sharev2
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name manilav2 --description OpenStack Shared File Systems sharev2
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Shared File Systems    |
| enabled     | True                             |
| id          | c66e6d16e2bf40eeaaa8713e81ee38b7 |
| name        | manilav2                         |
| type        | sharev2                          |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne share public http://controller:8786/v1/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne share public http://controller:8786/v1/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 0860d3521ffc475495055c776c753224        |
| interface    | public                                  |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 307da50f171e43f2bfbb38e9526aa1b9        |
| service_name | manila                                  |
| service_type | share                                   |
| url          | http://controller:8786/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne share internal http://controller:8786/v1/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne share internal http://controller:8786/v1/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 0b8524306ffc4d5ebf50454767b4a65f        |
| interface    | internal                                |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 307da50f171e43f2bfbb38e9526aa1b9        |
| service_name | manila                                  |
| service_type | share                                   |
| url          | http://controller:8786/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne share admin http://controller:8786/v1/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne share admin http://controller:8786/v1/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 65e17be979414849aec559c2b782fe7a        |
| interface    | admin                                   |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 307da50f171e43f2bfbb38e9526aa1b9        |
| service_name | manila                                  |
| service_type | share                                   |
| url          | http://controller:8786/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne sharev2 public http://controller:8786/v2/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne sharev2 public http://controller:8786/v2/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | aff073960a874c698d4eb2a5f52b8a63        |
| interface    | public                                  |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | c66e6d16e2bf40eeaaa8713e81ee38b7        |
| service_name | manilav2                                |
| service_type | sharev2                                 |
| url          | http://controller:8786/v2/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne sharev2 internal http://controller:8786/v2/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne sharev2 internal http://controller:8786/v2/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 19974a56548444099cde3a9ba360cd7c        |
| interface    | internal                                |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | c66e6d16e2bf40eeaaa8713e81ee38b7        |
| service_name | manilav2                                |
| service_type | sharev2                                 |
| url          | http://controller:8786/v2/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne sharev2 admin http://controller:8786/v2/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne sharev2 admin http://controller:8786/v2/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 49106497159f421c890f48dbdc6df43c        |
| interface    | admin                                   |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | c66e6d16e2bf40eeaaa8713e81ee38b7        |
| service_name | manilav2                                |
| service_type | sharev2                                 |
| url          | http://controller:8786/v2/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages manila-api manila-scheduler python-manilaclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed manila-api manila-scheduler python-manilaclient
+ retval=1
+ [ ! -z manila-api ]
+ dpkg -s manila-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z manila-scheduler ]
+ dpkg -s manila-scheduler
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-manilaclient ]
+ dpkg -s python-manilaclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ crudini --set /etc/manila/manila.conf database connection mysql+pymysql://manila:b2bd23d86e44b7407596@controller/manila
+ crudini --del /etc/manila/manila.conf keystone_authtoken auth_host
+ crudini --del /etc/manila/manila.conf keystone_authtoken auth_port
+ crudini --del /etc/manila/manila.conf keystone_authtoken auth_protocol
+ crudini --set /etc/manila/manila.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/manila/manila.conf DEFAULT verbose False
+ crudini --set /etc/manila/manila.conf DEFAULT debug False
+ crudini --set /etc/manila/manila.conf DEFAULT my_ip 192.168.0.1
+ crudini --set /etc/manila/manila.conf DEFAULT default_share_type default_share_type
+ crudini --set /etc/manila/manila.conf DEFAULT rootwrap_config /etc/manila/rootwrap.conf
+ [ 18 -lt 14 ]
+ crudini --set /etc/manila/manila.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ crudini --set /etc/manila/manila.conf keystone_authtoken memcached_servers controller:11211
+ crudini --set /etc/manila/manila.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/manila/manila.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/manila/manila.conf keystone_authtoken auth_type password
+ crudini --set /etc/manila/manila.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/manila/manila.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/manila/manila.conf keystone_authtoken project_name service
+ crudini --set /etc/manila/manila.conf keystone_authtoken username manila
+ crudini --set /etc/manila/manila.conf keystone_authtoken password 2eade20daad922a8057c
+ crudini --set /etc/manila/manila.conf oslo_concurrency lock_path /var/lib/manila/tmp
+ su -s /bin/sh -c manila-manage db sync manila
2019-05-10 14:18:43.706 3444 INFO alembic.runtime.migration [-] Context impl MySQLImpl.[00m
2019-05-10 14:18:43.706 3444 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.[00m
2019-05-10 14:18:44.341 3444 INFO alembic.runtime.migration [-] Running upgrade  -> 162a3e673105, manila_init[00m
2019-05-10 14:18:50.023 3444 INFO alembic.runtime.migration [-] Running upgrade 162a3e673105 -> 211836bf835c, add access level[00m
2019-05-10 14:18:50.324 3444 INFO alembic.runtime.migration [-] Running upgrade 211836bf835c -> 38e632621e5a, change volume_type to share_type[00m
2019-05-10 14:18:50.325 3444 INFO 38e632621e5a_change_volume_type_to_share_type_py [-] Renaming column name shares.volume_type_id to shares.share_type.id[00m
2019-05-10 14:18:50.384 3444 INFO 38e632621e5a_change_volume_type_to_share_type_py [-] Renaming volume_types table to share_types[00m
2019-05-10 14:18:50.710 3444 INFO 38e632621e5a_change_volume_type_to_share_type_py [-] Creating share_type_extra_specs table[00m
2019-05-10 14:18:50.919 3444 INFO 38e632621e5a_change_volume_type_to_share_type_py [-] Migrating volume_type_extra_specs to share_type_extra_specs[00m
2019-05-10 14:18:50.920 3444 INFO 38e632621e5a_change_volume_type_to_share_type_py [-] Dropping volume_type_extra_specs table[00m
2019-05-10 14:18:51.019 3444 INFO alembic.runtime.migration [-] Running upgrade 38e632621e5a -> 17115072e1c3, add_nova_net_id_column_to_share_networks[00m
2019-05-10 14:18:51.330 3444 INFO alembic.runtime.migration [-] Running upgrade 17115072e1c3 -> 4ee2cf4be19a, Remove share_snapshots.export_location[00m
2019-05-10 14:18:51.807 3444 INFO alembic.runtime.migration [-] Running upgrade 4ee2cf4be19a -> 59eb64046740, Add required extra spec[00m
2019-05-10 14:18:51.832 3444 INFO alembic.runtime.migration [-] Running upgrade 59eb64046740 -> ef0c02b4366, Add_share_type_projects[00m
2019-05-10 14:18:52.393 3444 INFO alembic.runtime.migration [-] Running upgrade ef0c02b4366 -> 30cb96d995fa, add public column for share[00m
2019-05-10 14:18:52.721 3444 INFO alembic.runtime.migration [-] Running upgrade 30cb96d995fa -> 56cdbe267881, Add share_export_locations table[00m
2019-05-10 14:18:53.265 3444 INFO alembic.runtime.migration [-] Running upgrade 56cdbe267881 -> 3a482171410f, add_driver_private_data_table[00m
2019-05-10 14:18:53.475 3444 INFO alembic.runtime.migration [-] Running upgrade 3a482171410f -> 533646c7af38, Remove unused attr status[00m
2019-05-10 14:18:54.053 3444 INFO alembic.runtime.migration [-] Running upgrade 533646c7af38 -> 3db9992c30f3, Transform statuses to lowercase[00m
2019-05-10 14:18:54.094 3444 INFO alembic.runtime.migration [-] Running upgrade 3db9992c30f3 -> 5077ffcc5f1c, add_share_instances[00m
2019-05-10 14:18:59.013 3444 INFO alembic.runtime.migration [-] Running upgrade 5077ffcc5f1c -> 579c267fbb4d, add_share_instances_access_map[00m
2019-05-10 14:18:59.566 3444 INFO alembic.runtime.migration [-] Running upgrade 579c267fbb4d -> 1f0bd302c1a6, add_availability_zones_table[00m
2019-05-10 14:19:02.348 3444 INFO alembic.runtime.migration [-] Running upgrade 1f0bd302c1a6 -> 55761e5f59c5, Add 'snapshot_support' extra spec to share types[00m
2019-05-10 14:19:02.724 3444 INFO alembic.runtime.migration [-] Running upgrade 55761e5f59c5 -> 3651e16d7c43, Create Consistency Groups Tables and Columns[00m
2019-05-10 14:19:04.543 3444 INFO alembic.runtime.migration [-] Running upgrade 3651e16d7c43 -> 323840a08dc4, Add shares.task_state[00m
2019-05-10 14:19:04.903 3444 INFO alembic.runtime.migration [-] Running upgrade 323840a08dc4 -> dda6de06349, Add DB support for share instance export locations metadata.[00m
2019-05-10 14:19:06.202 3444 INFO alembic.runtime.migration [-] Running upgrade dda6de06349 -> 344c1ac4747f, Remove access rules status and add access_rule_status to share_instance
model[00m
2019-05-10 14:19:07.099 3444 INFO alembic.runtime.migration [-] Running upgrade 344c1ac4747f -> 293fac1130ca, Add replication attributes to Share and ShareInstance models.[00m
2019-05-10 14:19:07.752 3444 INFO alembic.runtime.migration [-] Running upgrade 293fac1130ca -> 5155c7077f99, Add more network info attributes to 'network_allocations' table.[00m
2019-05-10 14:19:09.261 3444 INFO alembic.runtime.migration [-] Running upgrade 5155c7077f99 -> eb6d5544cbbd, add provider_location to share_snapshot_instances[00m
2019-05-10 14:19:09.696 3444 INFO alembic.runtime.migration [-] Running upgrade eb6d5544cbbd -> 221a83cfd85b, change_user_id_length[00m
2019-05-10 14:19:09.696 3444 INFO 221a83cfd85b_change_user_project_id_length_py [-] Changing user_id length for share_networks[00m
2019-05-10 14:19:10.075 3444 INFO 221a83cfd85b_change_user_project_id_length_py [-] Changing project_id length for share_networks[00m
2019-05-10 14:19:10.443 3444 INFO 221a83cfd85b_change_user_project_id_length_py [-] Changing project_id length for security_services[00m
2019-05-10 14:19:10.979 3444 INFO alembic.runtime.migration [-] Running upgrade 221a83cfd85b -> fdfb668d19e1, add_gateway_to_network_allocations_table[00m
2019-05-10 14:19:11.574 3444 INFO alembic.runtime.migration [-] Running upgrade fdfb668d19e1 -> e8ea58723178, Remove host from driver private data[00m
2019-05-10 14:19:12.696 3444 INFO alembic.runtime.migration [-] Running upgrade e8ea58723178 -> 493eaffd79e1, add_mtu_network_allocations[00m
2019-05-10 14:19:13.250 3444 INFO alembic.runtime.migration [-] Running upgrade 493eaffd79e1 -> 63809d875e32, add_access_key[00m
2019-05-10 14:19:13.577 3444 INFO alembic.runtime.migration [-] Running upgrade 63809d875e32 -> 48a7beae3117, move_share_type_id_to_instances[00m
2019-05-10 14:19:14.892 3444 INFO alembic.runtime.migration [-] Running upgrade 48a7beae3117 -> 3e7d62517afa, Add 'create_share_from_snapshot_support' extra spec to share types[00m
2019-05-10 14:19:15.219 3444 INFO alembic.runtime.migration [-] Running upgrade 3e7d62517afa -> 95e3cf760840, remove_nova_net_id_column_from_share_networks[00m
2019-05-10 14:19:15.529 3444 INFO alembic.runtime.migration [-] Running upgrade 95e3cf760840 -> 87ce15c59bbe, add_revert_to_snapshot_support[00m
2019-05-10 14:19:15.931 3444 INFO alembic.runtime.migration [-] Running upgrade 87ce15c59bbe -> 54667b9cade7, add_share_instance_access_map_state[00m
2019-05-10 14:19:16.300 3444 INFO alembic.runtime.migration [-] Running upgrade 54667b9cade7 -> e9f79621d83f, add_cast_rules_to_readonly_to_share_instances[00m
2019-05-10 14:19:16.301 3444 INFO e9f79621d83f_add_cast_rules_to_readonly_to_share_instances_py [-] Adding cast_rules_to_readonly column to share instances.[00m
2019-05-10 14:19:17.171 3444 INFO alembic.runtime.migration [-] Running upgrade e9f79621d83f -> 03da71c0e321, Convert consistency groups to share groups[00m
2019-05-10 14:19:17.172 3444 INFO 03da71c0e321_convert_cgs_to_share_groups_py [-] Renaming consistency group tables[00m
2019-05-10 14:19:23.828 3444 INFO alembic.runtime.migration [-] Running upgrade 03da71c0e321 -> e1949a93157a, Add share group types table[00m
2019-05-10 14:19:25.562 3444 INFO alembic.runtime.migration [-] Running upgrade e1949a93157a -> a77e2ad5012d, add_share_snapshot_access[00m
2019-05-10 14:19:26.601 3444 INFO alembic.runtime.migration [-] Running upgrade a77e2ad5012d -> 927920b37453, Add 'provider_location' attr to 'share_group_snapshot_members' model.[00m
2019-05-10 14:19:27.045 3444 INFO alembic.runtime.migration [-] Running upgrade 927920b37453 -> d5db24264f5c, Add enum 'consistent_snapshot_support' attr to 'share_groups' model.[00m
2019-05-10 14:19:27.347 3444 INFO alembic.runtime.migration [-] Running upgrade d5db24264f5c -> 7d142971c4ef, add_reservation_expire_index[00m
2019-05-10 14:19:27.464 3444 INFO alembic.runtime.migration [-] Running upgrade 7d142971c4ef -> 5237b6625330, Add 'availability_zone_id' field to 'share_groups' table.[00m
2019-05-10 14:19:27.893 3444 INFO alembic.runtime.migration [-] Running upgrade 5237b6625330 -> 31252d671ae5, Squash 'share_group_snapshot_members' and 'share_snapshot_instances' models.[00m
2019-05-10 14:19:29.611 3444 INFO alembic.runtime.migration [-] Running upgrade 31252d671ae5 -> 238720805ce1, Add messages table[00m
2019-05-10 14:19:29.854 3444 INFO alembic.runtime.migration [-] Running upgrade 238720805ce1 -> b516de97bfee, Add ProjectShareTypeQuota model[00m
2019-05-10 14:19:30.722 3444 INFO alembic.runtime.migration [-] Running upgrade b516de97bfee -> 829a09b0ddd4, Fix 'project_share_type_quotas' unique constraint[00m
2019-05-10 14:19:31.497 3444 INFO alembic.runtime.migration [-] Running upgrade 829a09b0ddd4 -> 27cb96d991fa, add description for share type[00m
2019-05-10 14:19:31.891 3444 INFO alembic.runtime.migration [-] Running upgrade 27cb96d991fa -> 4a482571410f, add_backend_info_table[00m
2019-05-10 14:19:32.117 3444 INFO alembic.runtime.migration [-] Running upgrade 4a482571410f -> 0274d20c560f, Add ou to security service[00m
2019-05-10 14:19:32.628 3444 INFO alembic.runtime.migration [-] Running upgrade 0274d20c560f -> 097fad24d2fc, add_share_instances_share_id_index[00m
2019-05-10 14:19:32.829 3444 INFO alembic.runtime.migration [-] Running upgrade 097fad24d2fc -> 11ee96se625f3, add metadata for access rule[00m
+ __openstack flavor create manila-service-flavor --id 100 --ram 256 --disk 0 --vcpus 1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack flavor create manila-service-flavor --id 100 --ram 256 --disk 0 --vcpus 1
+----------------------------+-----------------------+
| Field                      | Value                 |
+----------------------------+-----------------------+
| OS-FLV-DISABLED:disabled   | False                 |
| OS-FLV-EXT-DATA:ephemeral  | 0                     |
| disk                       | 0                     |
| id                         | 100                   |
| name                       | manila-service-flavor |
| os-flavor-access:is_public | True                  |
| properties                 |                       |
| ram                        | 256                   |
| rxtx_factor                | 1.0                   |
| swap                       |                       |
| vcpus                      | 1                     |
+----------------------------+-----------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 18 -eq 17 ]
+ service_restart manila-scheduler
+ service=manila-scheduler
+ [ 1 -eq 0 ]
+ systemctl restart manila-scheduler
+ service_enable manila-scheduler
+ service=manila-scheduler
+ [ 1 -eq 0 ]
+ systemctl enable manila-scheduler
Synchronizing state of manila-scheduler.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable manila-scheduler
+ service_restart manila-api
+ service=manila-api
+ [ 1 -eq 0 ]
+ systemctl restart manila-api
+ service_enable manila-api
+ service=manila-api
+ [ 1 -eq 0 ]
+ systemctl enable manila-api
Synchronizing state of manila-api.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable manila-api
+ rm -f /var/lib/manila/manila.sqlite
+ manila type-create default_share_type True
ERROR: The server has either erred or is incapable of performing the requested operation.
+ maybe_install_packages python-manila-ui
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-manila-ui
+ retval=1
+ [ ! -z python-manila-ui ]
+ dpkg -s python-manila-ui
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ dpkg-query -L python-manila-ui
+ grep -q templates
+ [ ! 0 -eq 0 ]
+ [ 18 -eq 14 -a -f /local/repository/etc/manila-rocky-noset.patch ]
+ [ 18 -eq 16 ]
+ service_restart apache2
+ service=apache2
+ [ 1 -eq 0 ]
+ systemctl restart apache2
+ service_restart memcached
+ service=memcached
+ [ 1 -eq 0 ]
+ systemctl restart memcached
+ echo MANILA_DBPASS="b2bd23d86e44b7407596"
+ echo MANILA_PASS="2eade20daad922a8057c"
+ logtend manila
+ area=manila
+ echo manila
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=manila
+ date +%s
+ stamp=1557519578
+ date
+ date=Fri May 10 14:19:38 MDT 2019
+ eval tss=$LOGTIMESTART_manila
+ tss=1557519502
+ expr 1557519578 - 1557519502
+ tsres=76
+ perl -e print 76 / 60.0 . "\n"
+ resmin=1.26666666666667
+ echo END manila 1557519578 Fri May 10 14:19:38 MDT 2019
+ echo TOTAL manila 76 1.26666666666667
+ [ -z  ]
+ logtstart manila-host
+ area=manila-host
+ echo manila-host
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=manila_host
+ date +%s
+ stamp=1557519578
+ date
+ date=Fri May 10 14:19:38 MDT 2019
+ eval LOGTIMESTART_manila_host=1557519578
+ LOGTIMESTART_manila_host=1557519578
+ echo START manila-host 1557519578 Fri May 10 14:19:38 MDT 2019
+ getfqdn ctl
+ n=ctl
+ cat /root/setup/fqdn.map
+ grep -E ctl\s
+ cut -f2
+ fqdn=
+ echo
+ fqdn=
+ [ ctl = controller ]
+ scp -o StrictHostKeyChecking=no /root/setup/settings :/root/setup/settings
cp: cannot create regular file ':/root/setup/settings': No such file or directory
+ ssh -o StrictHostKeyChecking=no /local/repository/setup-share-node.sh
Pseudo-terminal will not be allocated because stdin is not a terminal.
ssh: Could not resolve hostname /local/repository/setup-share-node.sh: Name or service not known
+ echo SHARE_HOST_DONE="1"
+ logtend manila-host
+ area=manila-host
+ echo manila-host
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=manila_host
+ date +%s
+ stamp=1557519578
+ date
+ date=Fri May 10 14:19:38 MDT 2019
+ eval tss=$LOGTIMESTART_manila_host
+ tss=1557519578
+ expr 1557519578 - 1557519578
+ tsres=0
+ perl -e print 0 / 60.0 . "\n"
+ resmin=0
+ echo END manila-host 1557519578 Fri May 10 14:19:38 MDT 2019
+ echo TOTAL manila-host 0 0
+ [ -z  ]
+ logtstart swift
+ area=swift
+ echo swift
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=swift
+ date +%s
+ stamp=1557519578
+ date
+ date=Fri May 10 14:19:38 MDT 2019
+ eval LOGTIMESTART_swift=1557519578
+ LOGTIMESTART_swift=1557519578
+ echo START swift 1557519578 Fri May 10 14:19:38 MDT 2019
+ openssl rand -hex 10
+ SWIFT_PASS=c3a4899e89192a1e7eb8
+ openssl rand -hex 10
+ SWIFT_HASH_PATH_PREFIX=d51684ed7c48c231579a
+ openssl rand -hex 10
+ SWIFT_HASH_PATH_SUFFIX=86bb0f47011f3b72117b
+ [ 18 -eq 10 ]
+ __openstack user create --domain default --password c3a4899e89192a1e7eb8 swift
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password c3a4899e89192a1e7eb8 swift
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 83328b3e75e8479c9a9c0a2d48cf8441 |
| name                | swift                            |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user swift --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user swift --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name swift --description OpenStack Object Storage Service object-store
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name swift --description OpenStack Object Storage Service object-store
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Object Storage Service |
| enabled     | True                             |
| id          | 7e10280ee3e64c8490a0c8452a3951c6 |
| name        | swift                            |
| type        | object-store                     |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne object-store public http://controller:8080/v1/AUTH_%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne object-store public http://controller:8080/v1/AUTH_%(tenant_id)s
+--------------+----------------------------------------------+
| Field        | Value                                        |
+--------------+----------------------------------------------+
| enabled      | True                                         |
| id           | d4b6db70b88a471991ca015a3e0b8e1d             |
| interface    | public                                       |
| region       | RegionOne                                    |
| region_id    | RegionOne                                    |
| service_id   | 7e10280ee3e64c8490a0c8452a3951c6             |
| service_name | swift                                        |
| service_type | object-store                                 |
| url          | http://controller:8080/v1/AUTH_%(tenant_id)s |
+--------------+----------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne object-store internal http://controller:8080/v1/AUTH_%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne object-store internal http://controller:8080/v1/AUTH_%(tenant_id)s
+--------------+----------------------------------------------+
| Field        | Value                                        |
+--------------+----------------------------------------------+
| enabled      | True                                         |
| id           | c289b01f38064977aef485e1259f0e65             |
| interface    | internal                                     |
| region       | RegionOne                                    |
| region_id    | RegionOne                                    |
| service_id   | 7e10280ee3e64c8490a0c8452a3951c6             |
| service_name | swift                                        |
| service_type | object-store                                 |
| url          | http://controller:8080/v1/AUTH_%(tenant_id)s |
+--------------+----------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne object-store admin http://controller:8080/v1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne object-store admin http://controller:8080/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | d688da403cce48309d5e9dcf86bcf405 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 7e10280ee3e64c8490a0c8452a3951c6 |
| service_name | swift                            |
| service_type | object-store                     |
| url          | http://controller:8080/v1        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages swift swift-proxy python-swiftclient python-keystoneclient python-keystonemiddleware
+ [ ! 0 -eq 0 ]
+ are_packages_installed swift swift-proxy python-swiftclient python-keystoneclient python-keystonemiddleware
+ retval=1
+ [ ! -z swift ]
+ dpkg -s swift
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z swift-proxy ]
+ dpkg -s swift-proxy
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-swiftclient ]
+ dpkg -s python-swiftclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-keystoneclient ]
+ dpkg -s python-keystoneclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-keystonemiddleware ]
+ dpkg -s python-keystonemiddleware
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ mkdir -p /etc/swift
+ wget -O /etc/swift/proxy-server.conf https://git.openstack.org/cgit/openstack/swift/plain/etc/proxy-server.conf-sample?h=stable/rocky
--2019-05-10 14:19:51--  https://git.openstack.org/cgit/openstack/swift/plain/etc/proxy-server.conf-sample?h=stable/rocky
Resolving git.openstack.org (git.openstack.org)... 23.253.125.17, 2001:4800:7817:103:be76:4eff:fe04:e3e3
Connecting to git.openstack.org (git.openstack.org)|23.253.125.17|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/proxy-server.conf-sample [following]
--2019-05-10 14:19:52--  https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/proxy-server.conf-sample
Resolving opendev.org (opendev.org)... 38.108.68.124, 2604:e100:3:0:f816:3eff:fe6b:ad62
Connecting to opendev.org (opendev.org)|38.108.68.124|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified [text/plain]
Saving to: â€˜/etc/swift/proxy-server.confâ€™

     0K .......... .......... .......... .......... ........    359K=0.1s

2019-05-10 14:19:53 (359 KB/s) - â€˜/etc/swift/proxy-server.confâ€™ saved [49891]

+ [ ! 0 -eq 0 ]
+ crudini --set /etc/swift/proxy-server.conf DEFAULT bind_port 8080
+ crudini --set /etc/swift/proxy-server.conf DEFAULT user swift
+ crudini --set /etc/swift/proxy-server.conf DEFAULT swift_dir /etc/swift
+ crudini --get /etc/swift/proxy-server.conf pipeline:main pipeline
+ pipeline=catch_errors gatekeeper healthcheck proxy-logging cache listing_formats container_sync bulk tempurl ratelimit tempauth copy container-quotas account-quotas slo dlo versioned_writes symlink proxy-logging proxy-server
+ [ rocky = juno ]
+ [ 18 -eq 11 ]
+ crudini --set /etc/swift/proxy-server.conf pipeline:main pipeline catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk ratelimit authtoken keystoneauth container-quotas account-quotas slo dlo versioned_writes proxy-logging proxy-server
+ crudini --set /etc/swift/proxy-server.conf app:proxy-server use egg:swift#proxy
+ crudini --set /etc/swift/proxy-server.conf app:proxy-server allow_account_management true
+ crudini --set /etc/swift/proxy-server.conf app:proxy-server account_autocreate true
+ crudini --set /etc/swift/proxy-server.conf filter:keystoneauth use egg:swift#keystoneauth
+ [ rocky = juno ]
+ crudini --set /etc/swift/proxy-server.conf filter:keystoneauth operator_roles admin,user
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken paste.filter_factory keystonemiddleware.auth_token:filter_factory
+ [ rocky = juno ]
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken auth_uri http://controller:5000
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken auth_url http://controller:5000
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken auth_type password
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken project_domain_name default
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken user_domain_name default
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken project_name service
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken username swift
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken password c3a4899e89192a1e7eb8
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/swift/proxy-server.conf memcached_servers controller:11211
+ crudini --set /etc/swift/proxy-server.conf filter:authtoken delay_auth_decision true
+ crudini --set /etc/swift/proxy-server.conf filter:cache use egg:swift#memcache
+ crudini --set /etc/swift/proxy-server.conf filter:cache memcache_servers controller:11211
+ crudini --del /etc/swift/proxy-server.conf keystone_authtoken auth_host
+ crudini --del /etc/swift/proxy-server.conf keystone_authtoken auth_port
+ crudini --del /etc/swift/proxy-server.conf keystone_authtoken auth_protocol
+ mkdir -p /var/log/swift
+ chown -R syslog.adm /var/log/swift
+ crudini --set /etc/swift/proxy-server.conf DEFAULT log_facility LOG_LOCAL1
+ crudini --set /etc/swift/proxy-server.conf DEFAULT log_level INFO
+ crudini --set /etc/swift/proxy-server.conf DEFAULT log_name swift-proxy
+ echo if $programname == "swift-proxy" then { action(type="omfile" file="/var/log/swift/swift-proxy.log") }
+ wget -O /etc/swift/swift.conf https://git.openstack.org/cgit/openstack/swift/plain/etc/swift.conf-sample?h=stable/rocky
--2019-05-10 14:19:54--  https://git.openstack.org/cgit/openstack/swift/plain/etc/swift.conf-sample?h=stable/rocky
Resolving git.openstack.org (git.openstack.org)... 23.253.125.17, 2001:4800:7817:103:be76:4eff:fe04:e3e3
Connecting to git.openstack.org (git.openstack.org)|23.253.125.17|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/swift.conf-sample [following]
--2019-05-10 14:19:55--  https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/swift.conf-sample
Resolving opendev.org (opendev.org)... 38.108.68.124, 2604:e100:3:0:f816:3eff:fe6b:ad62
Connecting to opendev.org (opendev.org)|38.108.68.124|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified [text/plain]
Saving to: â€˜/etc/swift/swift.confâ€™

     0K .......                                                49.1M=0s

2019-05-10 14:19:55 (49.1 MB/s) - â€˜/etc/swift/swift.confâ€™ saved [7894]

+ [ ! 0 -eq 0 ]
+ crudini --set /etc/swift/swift.conf swift-hash swift_hash_path_suffix d51684ed7c48c231579a
+ crudini --set /etc/swift/swift.conf swift-hash swift_hash_path_prefix 86bb0f47011f3b72117b
+ crudini --set /etc/swift/swift.conf storage-policy:0 name Policy-0
+ crudini --set /etc/swift/swift.conf storage-policy:0 default yes
+ chown -R swift:swift /etc/swift
+ service_restart memcached
+ service=memcached
+ [ 1 -eq 0 ]
+ systemctl restart memcached
+ service_restart rsyslog
+ service=rsyslog
+ [ 1 -eq 0 ]
+ systemctl restart rsyslog
+ [ 1 -eq 0 ]
+ service_restart swift-proxy
+ service=swift-proxy
+ [ 1 -eq 0 ]
+ systemctl restart swift-proxy
+ service_enable swift-proxy
+ service=swift-proxy
+ [ 1 -eq 0 ]
+ systemctl enable swift-proxy
swift-proxy.service is not a native service, redirecting to systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable swift-proxy
+ echo SWIFT_PASS="c3a4899e89192a1e7eb8"
+ echo SWIFT_HASH_PATH_PREFIX="d51684ed7c48c231579a"
+ echo SWIFT_HASH_PATH_SUFFIX="86bb0f47011f3b72117b"
+ logtend swift
+ area=swift
+ echo swift
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=swift
+ date +%s
+ stamp=1557519597
+ date
+ date=Fri May 10 14:19:57 MDT 2019
+ eval tss=$LOGTIMESTART_swift
+ tss=1557519578
+ expr 1557519597 - 1557519578
+ tsres=19
+ perl -e print 19 / 60.0 . "\n"
+ resmin=0.316666666666667
+ echo END swift 1557519597 Fri May 10 14:19:57 MDT 2019
+ echo TOTAL swift 19 0.316666666666667
+ [ -z  ]
+ logtstart swift-host
+ area=swift-host
+ echo swift-host
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=swift_host
+ date +%s
+ stamp=1557519597
+ date
+ date=Fri May 10 14:19:57 MDT 2019
+ eval LOGTIMESTART_swift_host=1557519597
+ LOGTIMESTART_swift_host=1557519597
+ echo START swift-host 1557519597 Fri May 10 14:19:57 MDT 2019
+ getfqdn ctl
+ n=ctl
+ cat /root/setup/fqdn.map
+ grep -E ctl\s
+ cut -f2
+ fqdn=
+ echo
+ fqdn=
+ [ ctl = controller ]
+ scp -o StrictHostKeyChecking=no /root/setup/settings :/root/setup/settings
cp: cannot create regular file ':/root/setup/settings': No such file or directory
+ ssh -o StrictHostKeyChecking=no /local/repository/setup-object-storage.sh
Pseudo-terminal will not be allocated because stdin is not a terminal.
ssh: Could not resolve hostname /local/repository/setup-object-storage.sh: Name or service not known
+ echo OBJECT_HOST_DONE="1"
+ logtend swift-host
+ area=swift-host
+ echo swift-host
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=swift_host
+ date +%s
+ stamp=1557519597
+ date
+ date=Fri May 10 14:19:57 MDT 2019
+ eval tss=$LOGTIMESTART_swift_host
+ tss=1557519597
+ expr 1557519597 - 1557519597
+ tsres=0
+ perl -e print 0 / 60.0 . "\n"
+ resmin=0
+ echo END swift-host 1557519597 Fri May 10 14:19:57 MDT 2019
+ echo TOTAL swift-host 0 0
+ [ -z  ]
+ logtstart swift-rings
+ area=swift-rings
+ + echo swift-rings
sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=swift_rings
+ date +%s
+ stamp=1557519597
+ date
+ date=Fri May 10 14:19:57 MDT 2019
+ eval LOGTIMESTART_swift_rings=1557519597
+ LOGTIMESTART_swift_rings=1557519597
+ echo START swift-rings 1557519597 Fri May 10 14:19:57 MDT 2019
+ pwd
+ cdir=/root/setup
+ cd /etc/swift
+ cat /root/setup/mgmt-hosts
+ grep ctl
+ cut -d   -f 1
+ objip=
+ swift-ring-builder account.builder create 10 2 1
+ swift-ring-builder account.builder add r1z1-:6002/swiftv1 100
Invalid ip 
The on-disk ring builder is unchanged.
+ swift-ring-builder account.builder add r1z1-:6002/swiftv1-2 100
Invalid ip 
The on-disk ring builder is unchanged.
+ swift-ring-builder account.builder rebalance
-------------------------------------------------------------------------------
An error has occurred during ring validation. Common
causes of failure are rings that are empty or do not
have enough devices to accommodate the replica count.
Original exception message:
 There are no devices in this ring, or all devices have been deleted
-------------------------------------------------------------------------------
+ swift-ring-builder container.builder create 10 2 1
+ swift-ring-builder container.builder add r1z1-:6001/swiftv1 100
Invalid ip 
The on-disk ring builder is unchanged.
+ swift-ring-builder container.builder add r1z1-:6001/swiftv1-2 100
Invalid ip 
The on-disk ring builder is unchanged.
+ swift-ring-builder container.builder rebalance
-------------------------------------------------------------------------------
An error has occurred during ring validation. Common
causes of failure are rings that are empty or do not
have enough devices to accommodate the replica count.
Original exception message:
 There are no devices in this ring, or all devices have been deleted
-------------------------------------------------------------------------------
+ swift-ring-builder object.builder create 10 2 1
+ swift-ring-builder object.builder add r1z1-:6000/swiftv1 100
Invalid ip 
The on-disk ring builder is unchanged.
+ swift-ring-builder object.builder add r1z1-:6000/swiftv1-2 100
Invalid ip 
The on-disk ring builder is unchanged.
+ swift-ring-builder object.builder rebalance
-------------------------------------------------------------------------------
An error has occurred during ring validation. Common
causes of failure are rings that are empty or do not
have enough devices to accommodate the replica count.
Original exception message:
 There are no devices in this ring, or all devices have been deleted
-------------------------------------------------------------------------------
+ chown -R swift:swift /etc/swift
+ [ ctl != controller ]
+ scp -o StrictHostKeyChecking=no account.ring.gz container.ring.gz object.ring.gz ctl:/etc/swift
ssh: Could not resolve hostname ctl: Name or service not known
lost connection
+ cd /root/setup
+ [ 1 -eq 0 ]
+ service_restart swift-proxy
+ service=swift-proxy
+ [ 1 -eq 0 ]
+ systemctl restart swift-proxy
+ echo OBJECT_RING_DONE="1"
+ logtend swift-rings
+ area=swift-rings
+ echo swift-rings
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=swift_rings
+ date +%s
+ stamp=1557519602
+ date
+ date=Fri May 10 14:20:02 MDT 2019
+ eval tss=$LOGTIMESTART_swift_rings
+ tss=1557519597
+ expr 1557519602 - 1557519597
+ tsres=5
+ perl -e print 5 / 60.0 . "\n"
+ resmin=0.0833333333333333
+ echo END swift-rings 1557519602 Fri May 10 14:20:02 MDT 2019
+ echo TOTAL swift-rings 5 0.0833333333333333
+ [ -z  ]
+ logtstart heat
+ area=heat
+ echo heat
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=heat
+ date +%s
+ stamp=1557519602
+ date
+ date=Fri May 10 14:20:02 MDT 2019
+ eval LOGTIMESTART_heat=1557519602
+ LOGTIMESTART_heat=1557519602
+ echo START heat 1557519602 Fri May 10 14:20:02 MDT 2019
+ openssl rand -hex 10
+ HEAT_DBPASS=fe168d03a3bd636abfd7
+ openssl rand -hex 10
+ HEAT_PASS=74f093bf648a6352c634
+ openssl rand -hex 10
+ HEAT_DOMAIN_PASS=2e1b2a1126234f3aff39
+ echo create database heat
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on heat.* to 'heat'@'localhost' identified by 'fe168d03a3bd636abfd7'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on heat.* to 'heat'@'%' identified by 'fe168d03a3bd636abfd7'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -eq 10 ]
+ __openstack user create --domain default --password 74f093bf648a6352c634 heat
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 74f093bf648a6352c634 heat
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 8762264e85974a2981b31a270044f571 |
| name                | heat                             |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user heat --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user heat --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role create heat_stack_owner
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role create heat_stack_owner
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | 5662f20970404ee7ba0e53609af5e30c |
| name      | heat_stack_owner                 |
+-----------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role create heat_stack_user
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role create heat_stack_user
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | 89afde1865ad4db8881f23b7e429c3f4 |
| name      | heat_stack_user                  |
+-----------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name heat --description OpenStack Orchestration Service orchestration
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name heat --description OpenStack Orchestration Service orchestration
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Orchestration Service  |
| enabled     | True                             |
| id          | 22fe2a7408fe48099e775872fe082b2f |
| name        | heat                             |
| type        | orchestration                    |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name heat-cfn --description OpenStack Orchestration Service cloudformation
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name heat-cfn --description OpenStack Orchestration Service cloudformation
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Orchestration Service  |
| enabled     | True                             |
| id          | ff7e09066d5747f1998b63e8c4f86b68 |
| name        | heat-cfn                         |
| type        | cloudformation                   |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne orchestration public http://controller:8004/v1/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne orchestration public http://controller:8004/v1/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | ef1df7b6791b459fa5ede3d6a6381a12        |
| interface    | public                                  |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 22fe2a7408fe48099e775872fe082b2f        |
| service_name | heat                                    |
| service_type | orchestration                           |
| url          | http://controller:8004/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne orchestration internal http://controller:8004/v1/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne orchestration internal http://controller:8004/v1/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 9919f9d4dbd244d5adc0d84164188d0f        |
| interface    | internal                                |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 22fe2a7408fe48099e775872fe082b2f        |
| service_name | heat                                    |
| service_type | orchestration                           |
| url          | http://controller:8004/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne orchestration admin http://controller:8004/v1/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne orchestration admin http://controller:8004/v1/%(tenant_id)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 224598b311ef4701b6dcb9b0ffed2cc6        |
| interface    | admin                                   |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 22fe2a7408fe48099e775872fe082b2f        |
| service_name | heat                                    |
| service_type | orchestration                           |
| url          | http://controller:8004/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne cloudformation public http://controller:8000/v1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne cloudformation public http://controller:8000/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 311e32d4e45c4dff9a06bac6c0185a1f |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | ff7e09066d5747f1998b63e8c4f86b68 |
| service_name | heat-cfn                         |
| service_type | cloudformation                   |
| url          | http://controller:8000/v1        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne cloudformation internal http://controller:8000/v1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne cloudformation internal http://controller:8000/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 8d1fa7c4404947928b96905fe8a4b628 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | ff7e09066d5747f1998b63e8c4f86b68 |
| service_name | heat-cfn                         |
| service_type | cloudformation                   |
| url          | http://controller:8000/v1        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne cloudformation admin http://controller:8000/v1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne cloudformation admin http://controller:8000/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | ae6cc26d8ada47ffbebe2e5a8f77f23c |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | ff7e09066d5747f1998b63e8c4f86b68 |
| service_name | heat-cfn                         |
| service_type | cloudformation                   |
| url          | http://controller:8000/v1        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack domain create --description Stack projects and users heat
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack domain create --description Stack projects and users heat
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Stack projects and users         |
| enabled     | True                             |
| id          | 6d20436bab6f40f7b31532a751a834bc |
| name        | heat                             |
| tags        | []                               |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack user create --domain heat --password 2e1b2a1126234f3aff39 heat_domain_admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain heat --password 2e1b2a1126234f3aff39 heat_domain_admin
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | 6d20436bab6f40f7b31532a751a834bc |
| enabled             | True                             |
| id                  | 09c23c9810954e3b946d26da2a2890b0 |
| name                | heat_domain_admin                |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --domain heat --user heat_domain_admin admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --domain heat --user heat_domain_admin admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --project admin --user admin heat_stack_owner
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --project admin --user admin heat_stack_owner
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --project admin --user adminapi heat_stack_owner
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --project admin --user adminapi heat_stack_owner
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages heat-api heat-api-cfn heat-engine python-heatclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed heat-api heat-api-cfn heat-engine python-heatclient
+ retval=1
+ [ ! -z heat-api ]
+ dpkg -s heat-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z heat-api-cfn ]
+ dpkg -s heat-api-cfn
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z heat-engine ]
+ dpkg -s heat-engine
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-heatclient ]
+ dpkg -s python-heatclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -ge 17 ]
+ maybe_install_packages python-heat-dashboard
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-heat-dashboard
+ retval=1
+ [ ! -z python-heat-dashboard ]
+ dpkg -s python-heat-dashboard
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ crudini --set /etc/heat/heat.conf database connection mysql+pymysql://heat:fe168d03a3bd636abfd7@controller/heat
+ crudini --set /etc/heat/heat.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/heat/heat.conf DEFAULT my_ip 192.168.0.1
+ crudini --set /etc/heat/heat.conf glance host controller
+ crudini --set /etc/heat/heat.conf DEFAULT verbose False
+ crudini --set /etc/heat/heat.conf DEFAULT debug False
+ [ 18 -lt 11 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/heat/heat.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ [ 18 -lt 11 ]
+ crudini --set /etc/heat/heat.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/heat/heat.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/heat/heat.conf keystone_authtoken auth_type password
+ crudini --set /etc/heat/heat.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/heat/heat.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/heat/heat.conf keystone_authtoken project_name service
+ crudini --set /etc/heat/heat.conf keystone_authtoken username heat
+ crudini --set /etc/heat/heat.conf keystone_authtoken password 74f093bf648a6352c634
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/heat/heat.conf keystone_authtoken memcached_servers controller:11211
+ [ 18 -gt 13 ]
+ crudini --set /etc/heat/heat.conf trustee auth_type password
+ [ 18 -ge 12 ]
+ crudini --set /etc/heat/heat.conf trustee auth_url http://controller:5000
+ crudini --set /etc/heat/heat.conf trustee username heat
+ crudini --set /etc/heat/heat.conf trustee password 74f093bf648a6352c634
+ crudini --set /etc/heat/heat.conf trustee user_domain_name default
+ crudini --set /etc/heat/heat.conf clients_keystone auth_uri http://controller:5000
+ crudini --set /etc/heat/heat.conf DEFAULT heat_metadata_server_url http://controller:8000
+ crudini --set /etc/heat/heat.conf DEFAULT heat_waitcondition_server_url http://controller:8000/v1/waitcondition
+ [ x3 = x3 ]
+ crudini --set /etc/heat/heat.conf ec2authtoken auth_uri http://controller:5000
+ [ 18 -ge 11 ]
+ crudini --set /etc/heat/heat.conf DEFAULT stack_domain_admin heat_domain_admin
+ crudini --set /etc/heat/heat.conf DEFAULT stack_domain_admin_password 2e1b2a1126234f3aff39
+ crudini --set /etc/heat/heat.conf DEFAULT stack_user_domain_name heat
+ crudini --del /etc/heat/heat.conf DEFAULT auth_host
+ crudini --del /etc/heat/heat.conf DEFAULT auth_port
+ crudini --del /etc/heat/heat.conf DEFAULT auth_protocol
+ [ 18 -eq 11 ]
+ su -s /bin/sh -c /usr/bin/heat-manage db_sync heat
2019-05-10 14:20:33.477 4611 INFO migrate.versioning.api [-] 70 -> 71... [00m
2019-05-10 14:20:38.009 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:38.009 4611 INFO migrate.versioning.api [-] 71 -> 72... [00m
2019-05-10 14:20:38.964 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:38.964 4611 INFO migrate.versioning.api [-] 72 -> 73... [00m
2019-05-10 14:20:39.534 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:39.534 4611 INFO migrate.versioning.api [-] 73 -> 74... [00m
2019-05-10 14:20:39.559 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:39.559 4611 INFO migrate.versioning.api [-] 74 -> 75... [00m
2019-05-10 14:20:39.584 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:39.584 4611 INFO migrate.versioning.api [-] 75 -> 76... [00m
2019-05-10 14:20:39.609 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:39.609 4611 INFO migrate.versioning.api [-] 76 -> 77... [00m
2019-05-10 14:20:39.634 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:39.634 4611 INFO migrate.versioning.api [-] 77 -> 78... [00m
2019-05-10 14:20:39.660 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:39.660 4611 INFO migrate.versioning.api [-] 78 -> 79... [00m
2019-05-10 14:20:41.587 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:41.587 4611 INFO migrate.versioning.api [-] 79 -> 80... [00m
2019-05-10 14:20:42.652 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:42.652 4611 INFO migrate.versioning.api [-] 80 -> 81... [00m
2019-05-10 14:20:42.677 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:42.677 4611 INFO migrate.versioning.api [-] 81 -> 82... [00m
2019-05-10 14:20:42.702 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:42.702 4611 INFO migrate.versioning.api [-] 82 -> 83... [00m
2019-05-10 14:20:42.735 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:42.735 4611 INFO migrate.versioning.api [-] 83 -> 84... [00m
2019-05-10 14:20:42.794 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:42.794 4611 INFO migrate.versioning.api [-] 84 -> 85... [00m
2019-05-10 14:20:42.819 4611 INFO migrate.versioning.api [-] done[00m
2019-05-10 14:20:42.819 4611 INFO migrate.versioning.api [-] 85 -> 86... [00m
2019-05-10 14:20:43.273 4611 INFO migrate.versioning.api [-] done[00m
+ service_restart heat-api
+ service=heat-api
+ [ 1 -eq 0 ]
+ systemctl restart heat-api
+ service_enable heat-api
+ service=heat-api
+ [ 1 -eq 0 ]
+ systemctl enable heat-api
Synchronizing state of heat-api.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable heat-api
+ service_restart heat-api-cfn
+ service=heat-api-cfn
+ [ 1 -eq 0 ]
+ systemctl restart heat-api-cfn
+ service_enable heat-api-cfn
+ service=heat-api-cfn
+ [ 1 -eq 0 ]
+ systemctl enable heat-api-cfn
Synchronizing state of heat-api-cfn.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable heat-api-cfn
+ service_restart heat-engine
+ service=heat-engine
+ [ 1 -eq 0 ]
+ systemctl restart heat-engine
+ service_enable heat-engine
+ service=heat-engine
+ [ 1 -eq 0 ]
+ systemctl enable heat-engine
Synchronizing state of heat-engine.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable heat-engine
+ rm -f /var/lib/heat/heat.sqlite
+ echo HEAT_DBPASS="fe168d03a3bd636abfd7"
+ echo HEAT_PASS="74f093bf648a6352c634"
+ echo HEAT_DOMAIN_PASS="2e1b2a1126234f3aff39"
+ logtend heat
+ area=heat
+ echo heat
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=heat
+ date +%s
+ stamp=1557519644
+ date
+ date=Fri May 10 14:20:44 MDT 2019
+ eval tss=$LOGTIMESTART_heat
+ tss=1557519602
+ expr 1557519644 - 1557519602
+ tsres=42
+ perl -e print 42 / 60.0 . "\n"
+ resmin=0.7
+ echo END heat 1557519644 Fri May 10 14:20:44 MDT 2019
+ echo TOTAL heat 42 0.7
+ [ -z  ]
+ logtstart ceilometer
+ area=ceilometer
+ echo ceilometer
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer
+ date +%s
+ stamp=1557519644
+ date
+ date=Fri May 10 14:20:44 MDT 2019
+ eval LOGTIMESTART_ceilometer=1557519644
+ LOGTIMESTART_ceilometer=1557519644
+ echo START ceilometer 1557519644 Fri May 10 14:20:44 MDT 2019
+ openssl rand -hex 10
+ CEILOMETER_DBPASS=b907cdb748550b1172ef
+ openssl rand -hex 10
+ CEILOMETER_PASS=8604e762e767b5756f34
+ openssl rand -hex 10
+ CEILOMETER_SECRET=165eed9e2ad1fc410f41
+ USING_GNOCCHI=0
+ [ 18 -ge 15 ]
+ USING_GNOCCHI=1
+ [ 1 -eq 0 -a 0 = 1 ]
+ [ 1 -eq 0 ]
+ openssl rand -hex 10
+ GNOCCHI_DBPASS=53e1f32cc25233b8f63e
+ openssl rand -hex 10
+ GNOCCHI_PASS=c41720eb6415a6c5bac9
+ maybe_install_packages mariadb-server python-mysqldb
+ [ ! 0 -eq 0 ]
+ are_packages_installed mariadb-server python-mysqldb
+ retval=1
+ [ ! -z mariadb-server ]
+ dpkg -s mariadb-server
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-mysqldb ]
+ dpkg -s python-mysqldb
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ + echo create database gnocchi
mysql -u root --password=ad12065d4a6fcf049d20
+ + echo grant all privileges on gnocchi.* to 'gnocchi'@'localhost' identified by '53e1f32cc25233b8f63e'
mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on gnocchi.* to 'gnocchi'@'%' identified by '53e1f32cc25233b8f63e'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -eq 10 ]
+ [ 1 -eq 0 ]
+ __openstack user create --domain default --password 8604e762e767b5756f34 ceilometer
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 8604e762e767b5756f34 ceilometer
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 8172f4d8a2954d48823f38586ac2d193 |
| name                | ceilometer                       |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user ceilometer --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user ceilometer --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name ceilometer --description OpenStack Telemetry Service metering
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name ceilometer --description OpenStack Telemetry Service metering
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Telemetry Service      |
| enabled     | True                             |
| id          | 50bc2659db9f4b30ab29ba94e03bb796 |
| name        | ceilometer                       |
| type        | metering                         |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ openssl rand -hex 10
+ GNOCCHI_PASS=fbc724e02dff5d3cae2a
+ __openstack user create --domain default --password fbc724e02dff5d3cae2a gnocchi
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password fbc724e02dff5d3cae2a gnocchi
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 805e1e1cd289431ba64a3040e480df7d |
| name                | gnocchi                          |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user gnocchi --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user gnocchi --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name gnocchi --description OpenStack Metric Service metric
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name gnocchi --description OpenStack Metric Service metric
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Metric Service         |
| enabled     | True                             |
| id          | ad8efa6fe35a4614b0956a5603eed9d9 |
| name        | gnocchi                          |
| type        | metric                           |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne metric public http://controller:8041
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne metric public http://controller:8041
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 89971541c88645bdb3db32c650662d04 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | ad8efa6fe35a4614b0956a5603eed9d9 |
| service_name | gnocchi                          |
| service_type | metric                           |
| url          | http://controller:8041           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne metric internal http://controller:8041
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne metric internal http://controller:8041
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 6c887eb48ee14b33921e4e3dedcb6c40 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | ad8efa6fe35a4614b0956a5603eed9d9 |
| service_name | gnocchi                          |
| service_type | metric                           |
| url          | http://controller:8041           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne metric admin http://controller:8041
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne metric admin http://controller:8041
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | e0cf12ec66a9470285b4b6e6cf511253 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | ad8efa6fe35a4614b0956a5603eed9d9 |
| service_name | gnocchi                          |
| service_type | metric                           |
| url          | http://controller:8041           |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages ceilometer-agent-central ceilometer-agent-notification
+ [ ! 0 -eq 0 ]
+ are_packages_installed ceilometer-agent-central ceilometer-agent-notification
+ retval=1
+ [ ! -z ceilometer-agent-central ]
+ dpkg -s ceilometer-agent-central
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z ceilometer-agent-notification ]
+ dpkg -s ceilometer-agent-notification
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 1 -eq 0 ]
+ maybe_install_packages gnocchi-metricd python-gnocchiclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed gnocchi-metricd python-gnocchiclient
+ retval=1
+ [ ! -z gnocchi-metricd ]
+ dpkg -s gnocchi-metricd
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-gnocchiclient ]
+ dpkg -s python-gnocchiclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 = 17 ]
+ maybe_install_packages gnocchi-api
+ [ ! 0 -eq 0 ]
+ are_packages_installed gnocchi-api
+ retval=1
+ [ ! -z gnocchi-api ]
+ dpkg -s gnocchi-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ maybe_install_packages python-gnocchi
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-gnocchi
+ retval=1
+ [ ! -z python-gnocchi ]
+ dpkg -s python-gnocchi
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ chown -R ceilometer /etc/ceilometer
+ [ 1 -eq 0 -a 0 = 1 ]
+ [ 1 -eq 0 ]
+ crudini --set /etc/ceilometer/ceilometer.conf DEFAULT verbose False
+ crudini --set /etc/ceilometer/ceilometer.conf DEFAULT debug False
+ crudini --set /etc/ceilometer/ceilometer.conf DEFAULT log_dir /var/log/ceilometer
+ crudini --del /etc/ceilometer/ceilometer.conf DEFAULT auth_host
+ crudini --del /etc/ceilometer/ceilometer.conf DEFAULT auth_port
+ crudini --del /etc/ceilometer/ceilometer.conf DEFAULT auth_protocol
+ [ 18 -lt 11 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/ceilometer/ceilometer.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ [ 1 -eq 0 ]
+ [ 18 -lt 13 ]
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials auth_type password
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials auth_url http://controller:5000/v3
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials username ceilometer
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials project_domain_name default
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials user_domain_name default
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials project_name service
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials password 8604e762e767b5756f34
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials interface internalURL
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials region_name RegionOne
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/ceilometer/ceilometer.conf service_credentials memcached_servers controller:11211
+ [ 1 -eq 1 ]
+ crudini --del /etc/gnocchi/gnocchi.conf keystone_authtoken auth_host
+ crudini --del /etc/gnocchi/gnocchi.conf keystone_authtoken auth_port
+ crudini --del /etc/gnocchi/gnocchi.conf keystone_authtoken auth_protocol
+ crudini --del /etc/gnocchi/gnocchi.conf keystone_authtoken admin_user
+ crudini --del /etc/gnocchi/gnocchi.conf keystone_authtoken admin_password
+ crudini --del /etc/gnocchi/gnocchi.conf keystone_authtoken admin_tenant_name
+ crudini --set /etc/ceilometer/ceilometer.conf dispatcher_gnocchi filter_service_activity False
+ crudini --set /etc/ceilometer/ceilometer.conf dispatcher_gnocchi archive_policy low
+ crudini --set /etc/ceilometer/ceilometer.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ crudini --set /etc/gnocchi/gnocchi.conf api auth_mode keystone
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken auth_type password
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken project_name service
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken username gnocchi
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken password fbc724e02dff5d3cae2a
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken interface internalURL
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken region_name RegionOne
+ crudini --set /etc/gnocchi/gnocchi.conf keystone_authtoken memcached_servers controller:11211
+ crudini --set /etc/gnocchi/gnocchi.conf indexer url mysql+pymysql://gnocchi:53e1f32cc25233b8f63e@controller/gnocchi
+ crudini --set /etc/gnocchi/gnocchi.conf storage driver file
+ crudini --set /etc/gnocchi/gnocchi.conf storage file_basepath /var/lib/gnocchi
+ [ 1 -eq 0 ]
+ mkdir -p /var/lib/gnocchi/cache
+ mkdir -p /var/lib/gnocchi/measure
+ mkdir -p /var/lib/gnocchi/tmp
+ chown -R gnocchi:gnocchi /var/lib/gnocchi
+ usermod -a -G gnocchi ceilometer
+ chmod -R 770 /var/lib/gnocchi
+ [ 18 -lt 17 ]
+ service_restart gnocchi-api
+ service=gnocchi-api
+ [ 1 -eq 0 ]
+ systemctl restart gnocchi-api
Failed to restart gnocchi-api.service: Unit gnocchi-api.service not found.
+ sleep 4
+ gnocchi-upgrade --config-file=/etc/gnocchi/gnocchi.conf
2019-05-10 14:21:04,732 [5324] INFO     gnocchi.service: Gnocchi version 4.3.2
2019-05-10 14:21:05,904 [5324] INFO     gnocchi.cli.manage: Upgrading indexer SQLAlchemyIndexer: mysql+pymysql://gnocchi:53e1f32cc25233b8f63e@controller/gnocchi
2019-05-10 14:21:07,625 [5324] INFO     gnocchi.cli.manage: Upgrading storage FileStorage: /var/lib/gnocchi
2019-05-10 14:21:07,627 [5324] INFO     gnocchi.cli.manage: Upgrading incoming storage FileStorage: /var/lib/gnocchi
+ chown -R gnocchi:gnocchi /var/lib/gnocchi
+ service_restart gnocchi-api
+ service=gnocchi-api
+ [ 1 -eq 0 ]
+ systemctl restart gnocchi-api
Failed to restart gnocchi-api.service: Unit gnocchi-api.service not found.
+ ceilometer-upgrade --debug
+ service_restart ceilometer-agent-central
+ service=ceilometer-agent-central
+ [ 1 -eq 0 ]
+ systemctl restart ceilometer-agent-central
+ service_enable ceilometer-agent-central
+ service=ceilometer-agent-central
+ [ 1 -eq 0 ]
+ systemctl enable ceilometer-agent-central
Synchronizing state of ceilometer-agent-central.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable ceilometer-agent-central
+ service_restart ceilometer-agent-notification
+ service=ceilometer-agent-notification
+ [ 1 -eq 0 ]
+ systemctl restart ceilometer-agent-notification
+ service_enable ceilometer-agent-notification
+ service=ceilometer-agent-notification
+ [ 1 -eq 0 ]
+ systemctl enable ceilometer-agent-notification
Synchronizing state of ceilometer-agent-notification.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable ceilometer-agent-notification
+ [ 0 -eq 1 -a 1 -eq 0 ]
+ [ 1 -eq 0 ]
+ [ 18 -lt 17 ]
+ [ 1 -eq 0 ]
+ service_restart gnocchi-metricd
+ service=gnocchi-metricd
+ [ 1 -eq 0 ]
+ systemctl restart gnocchi-metricd
+ service_enable gnocchi-metricd
+ service=gnocchi-metricd
+ [ 1 -eq 0 ]
+ systemctl enable gnocchi-metricd
Synchronizing state of gnocchi-metricd.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable gnocchi-metricd
+ unified
+ [ controller = controller ]
+ return 0
+ service neutron-metering-agent restart
+ echo CEILOMETER_DBPASS="b907cdb748550b1172ef"
+ echo CEILOMETER_PASS="8604e762e767b5756f34"
+ echo CEILOMETER_SECRET="165eed9e2ad1fc410f41"
+ echo USING_GNOCCHI="1"
+ [ 1 -eq 1 ]
+ echo GNOCCHI_DBPASS="53e1f32cc25233b8f63e"
+ echo GNOCCHI_PASS="fbc724e02dff5d3cae2a"
+ logtend ceilometer
+ area=ceilometer
+ echo ceilometer
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer
+ date +%s
+ stamp=1557519707
+ date
+ date=Fri May 10 14:21:47 MDT 2019
+ eval tss=$LOGTIMESTART_ceilometer
+ tss=1557519644
+ expr 1557519707 - 1557519644
+ tsres=63
+ perl -e print 63 / 60.0 . "\n"
+ resmin=1.05
+ echo END ceilometer 1557519707 Fri May 10 14:21:47 MDT 2019
+ echo TOTAL ceilometer 63 1.05
+ [ 18 -ge 16 -a -z  ]
+ logtstart grafana
+ area=grafana
+ echo grafana
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=grafana
+ date +%s
+ stamp=1557519707
+ date
+ date=Fri May 10 14:21:47 MDT 2019
+ eval LOGTIMESTART_grafana=1557519707
+ LOGTIMESTART_grafana=1557519707
+ echo START grafana 1557519707 Fri May 10 14:21:47 MDT 2019
+ echo deb https://packages.grafana.com/oss/deb stable main
+ curl https://packages.grafana.com/gpg.key
+ sudo apt-key add -
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key output should not be parsed (stdout is not a terminal)
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  1694  100  1694    0     0   2286      0 --:--:-- --:--:-- --:--:--  2283
OK
+ apt-get update
Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease
Hit:2 http://us.archive.ubuntu.com/ubuntu bionic InRelease
Hit:3 http://us.archive.ubuntu.com/ubuntu bionic-updates InRelease
Hit:4 http://us.archive.ubuntu.com/ubuntu bionic-backports InRelease
Ign:5 http://ubuntu-cloud.archive.canonical.com/ubuntu bionic-updates/rocky InRelease
Hit:6 http://ubuntu-cloud.archive.canonical.com/ubuntu bionic-updates/rocky Release
Hit:8 https://packages.grafana.com/oss/deb stable InRelease
Reading package lists...
W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target CNF (main/cnf/Commands-amd64) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target CNF (main/cnf/Commands-all) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target CNF (main/cnf/Commands-amd64) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
W: Target CNF (main/cnf/Commands-all) is configured multiple times in /etc/apt/sources.list.d/grafana.list:1 and /etc/apt/sources.list.d/grafana.list:2
+ apt-get install -y grafana
Reading package lists...
Building dependency tree...
Reading state information...
The following packages were automatically installed and are no longer required:
  libegl-mesa0 libegl1 libgbm1 libglapi-mesa libglvnd0 libwayland-egl1-mesa
  libwayland-server0 libxcb-dri2-0 libxcb-dri3-0 libxcb-present0 libxcb-sync1
  libxcb-xfixes0 libxshmfence1
Use 'sudo apt autoremove' to remove them.
The following NEW packages will be installed:
  grafana
0 upgraded, 1 newly installed, 0 to remove and 4 not upgraded.
Need to get 56.7 MB of archives.
After this operation, 163 MB of additional disk space will be used.
Get:1 https://packages.grafana.com/oss/deb stable/main amd64 grafana amd64 6.1.6 [56.7 MB]
Fetched 56.7 MB in 2s (26.8 MB/s)
Selecting previously unselected package grafana.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 219754 files and directories currently installed.)
Preparing to unpack .../grafana_6.1.6_amd64.deb ...
Unpacking grafana (6.1.6) ...
Processing triggers for ureadahead (0.100.0-21) ...
ureadahead will be reprofiled on next reboot
Processing triggers for systemd (237-3ubuntu10.21) ...
Setting up grafana (6.1.6) ...
Adding system user `grafana' (UID 132) ...
Adding new user `grafana' (UID 132) with group `grafana' ...
Not creating home directory `/usr/share/grafana'.
### NOT starting on installation, please execute the following statements to configure grafana to start automatically using systemd
 sudo /bin/systemctl daemon-reload
 sudo /bin/systemctl enable grafana-server
### You can start grafana-server by executing
 sudo /bin/systemctl start grafana-server
Processing triggers for ureadahead (0.100.0-21) ...
Processing triggers for systemd (237-3ubuntu10.21) ...
+ maybe_install_packages sqlite3
+ [ ! 0 -eq 0 ]
+ are_packages_installed sqlite3
+ retval=1
+ [ ! -z sqlite3 ]
+ dpkg -s sqlite3
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ systemctl daemon-reload
+ crudini --set /etc/grafana/grafana.ini paths data /var/lib/grafana
+ [ x9da6fece4881 = x ]
+ GPASSWD=9da6fece4881
+ crudini --set /etc/grafana/grafana.ini security admin_user admin
+ crudini --set /etc/grafana/grafana.ini security admin_password 9da6fece4881
+ chown -R grafana:grafana /var/lib/grafana/grafana.db
chown: cannot access '/var/lib/grafana/grafana.db': No such file or directory
+ service_enable grafana-server
+ service=grafana-server
+ [ 1 -eq 0 ]
+ systemctl enable grafana-server
Synchronizing state of grafana-server.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable grafana-server
Created symlink /etc/systemd/system/multi-user.target.wants/grafana-server.service â†’ /usr/lib/systemd/system/grafana-server.service.
+ service_restart grafana-server
+ service=grafana-server
+ [ 1 -eq 0 ]
+ systemctl restart grafana-server
+ grafana-cli admin reset-admin-password --config /etc/grafana/grafana.ini --homepath /usr/share/grafana 9da6fece4881
t=2019-05-10T14:22:01-0600 lvl=info msg="Connecting to DB" logger=sqlstore dbtype=sqlite3
t=2019-05-10T14:22:01-0600 lvl=info msg="Starting DB migration" logger=migrator
t=2019-05-10T14:22:01-0600 lvl=info msg="Executing migration" logger=migrator id="create migration_log table"
t=2019-05-10T14:22:01-0600 lvl=info msg="Executing migration" logger=migrator id="create user table"
t=2019-05-10T14:22:01-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index user.login"
t=2019-05-10T14:22:01-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index user.email"
t=2019-05-10T14:22:01-0600 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_user_login - v1"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_user_email - v1"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="Rename table user to user_v1 - v1"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="create user table v2"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_user_login - v2"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_user_email - v2"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="copy data_source v1 to v2"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="Drop old table user_v1"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="Add column help_flags1 to user table"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="Update user table charset"
t=2019-05-10T14:22:02-0600 lvl=info msg="Executing migration" logger=migrator id="Add last_seen_at column to user"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="Add missing user data"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create temp user table v1-7"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_email - v1-7"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_org_id - v1-7"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_code - v1-7"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_status - v1-7"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="Update temp_user table charset"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create star table"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index star.user_id_dashboard_id"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create org table v1"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_org_name - v1"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create org_user table v1"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_org_user_org_id - v1"
t=2019-05-10T14:22:03-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_org_user_org_id_user_id - v1"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="Update org table charset"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="Update org_user table charset"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="Migrate all Read Only Viewers to Viewers"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard table"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="add index dashboard.account_id"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_account_id_slug"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard_tag table"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_tag.dasboard_id_term"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_dashboard_tag_dashboard_id_term - v1"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="Rename table dashboard to dashboard_v1 - v1"
t=2019-05-10T14:22:04-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard v2"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_org_id - v2"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_org_id_slug - v2"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="copy dashboard v1 to v2"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="drop table dashboard_v1"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="alter dashboard.data to mediumtext v1"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="Add column updated_by in dashboard - v2"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="Add column created_by in dashboard - v2"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="Add column gnetId in dashboard"
t=2019-05-10T14:22:05-0600 lvl=info msg="Executing migration" logger=migrator id="Add index for gnetId in dashboard"
t=2019-05-10T14:22:06-0600 lvl=info msg="Executing migration" logger=migrator id="Add column plugin_id in dashboard"
t=2019-05-10T14:22:06-0600 lvl=info msg="Executing migration" logger=migrator id="Add index for plugin_id in dashboard"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Add index for dashboard_id in dashboard_tag"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Update dashboard table charset"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Update dashboard_tag table charset"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Add column folder_id in dashboard"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Add column isFolder in dashboard"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Add column has_acl in dashboard"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Add column uid in dashboard"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Update uid column values in dashboard"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Add unique index dashboard_org_id_uid"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Remove unique index org_id_slug"
t=2019-05-10T14:22:07-0600 lvl=info msg="Executing migration" logger=migrator id="Update dashboard title length"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="Add unique index for dashboard_org_id_title_folder_id"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard_provisioning"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="Rename table dashboard_provisioning to dashboard_provisioning_tmp_qwerty - v1"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard_provisioning v2"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_provisioning_dashboard_id - v2"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_provisioning_dashboard_id_name - v2"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="copy dashboard_provisioning v1 to v2"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="drop dashboard_provisioning_tmp_qwerty"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="Add check_sum column"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="create data_source table"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="add index data_source.account_id"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index data_source.account_id_name"
t=2019-05-10T14:22:08-0600 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_data_source_account_id - v1"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_data_source_account_id_name - v1"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="Rename table data_source to data_source_v1 - v1"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="create data_source table v2"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_data_source_org_id - v2"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_data_source_org_id_name - v2"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="copy data_source v1 to v2"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="Drop old table data_source_v1 #2"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="Add column with_credentials"
t=2019-05-10T14:22:09-0600 lvl=info msg="Executing migration" logger=migrator id="Add secure json data column"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="Update data_source table charset"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="Update initial version to 1"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="Add read_only data column"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="Migrate logging ds to loki ds"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="Update json_data with nulls"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="create api_key table"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="add index api_key.account_id"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="add index api_key.key"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="add index api_key.account_id_name"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_api_key_account_id - v1"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_api_key_key - v1"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_api_key_account_id_name - v1"
t=2019-05-10T14:22:10-0600 lvl=info msg="Executing migration" logger=migrator id="Rename table api_key to api_key_v1 - v1"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="create api_key table v2"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_api_key_org_id - v2"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_api_key_key - v2"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_api_key_org_id_name - v2"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="copy api_key v1 to v2"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="Drop old table api_key_v1"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="Update api_key table charset"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard_snapshot table v4"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="drop table dashboard_snapshot_v4 #1"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard_snapshot table v5 #2"
t=2019-05-10T14:22:11-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_snapshot_key - v5"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_snapshot_delete_key - v5"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_snapshot_user_id - v5"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="alter dashboard_snapshot to mediumtext v2"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="Update dashboard_snapshot table charset"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="Add column external_delete_url to dashboard_snapshots table"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="create quota table v1"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_quota_org_id_user_id_target - v1"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="Update quota table charset"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="create plugin_setting table"
t=2019-05-10T14:22:12-0600 lvl=info msg="Executing migration" logger=migrator id="create index UQE_plugin_setting_org_id_plugin_id - v1"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="Add column plugin_version to plugin_settings"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="Update plugin_setting table charset"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="create session table"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="Drop old table playlist table"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="Drop old table playlist_item table"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="create playlist table v2"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="create playlist item table v2"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="Update playlist table charset"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="Update playlist_item table charset"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="drop preferences table v2"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="drop preferences table v3"
t=2019-05-10T14:22:13-0600 lvl=info msg="Executing migration" logger=migrator id="create preferences table v3"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="Update preferences table charset"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="Add column team_id in preferences"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="Update team_id column values in preferences"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="create alert table v1"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="add index alert org_id & id "
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="add index alert state"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="add index alert dashboard_id"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="create alert_notification table v1"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="Add column is_default"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="Add column frequency"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="Add column send_reminder"
t=2019-05-10T14:22:14-0600 lvl=info msg="Executing migration" logger=migrator id="Add column disable_resolve_message"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="add index alert_notification org_id & name"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="Update alert table charset"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="Update alert_notification table charset"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="create notification_journal table v1"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="add index notification_journal org_id & alert_id & notifier_id"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="drop alert_notification_journal"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="create alert_notification_state table v1"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="add index alert_notification_state org_id & alert_id & notifier_id"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="Add for to alert table"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="Add column uid in alert_notification"
t=2019-05-10T14:22:15-0600 lvl=info msg="Executing migration" logger=migrator id="Update uid column values in alert_notification"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="Add unique index alert_notification_org_id_uid"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="Remove unique index org_id_name"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="Drop old annotation table v4"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="create annotation table v5"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="add index annotation 0 v3"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="add index annotation 1 v3"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="add index annotation 2 v3"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="add index annotation 3 v3"
t=2019-05-10T14:22:16-0600 lvl=info msg="Executing migration" logger=migrator id="add index annotation 4 v3"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Update annotation table charset"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Add column region_id to annotation table"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Drop category_id index"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Add column tags to annotation table"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Create annotation_tag table v2"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Add unique index annotation_tag.annotation_id_tag_id"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Update alert annotations and set TEXT to empty"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Add created time to annotation table"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Add updated time to annotation table"
t=2019-05-10T14:22:17-0600 lvl=info msg="Executing migration" logger=migrator id="Add index for created in annotation table"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="Add index for updated in annotation table"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="Convert existing annotations from seconds to milliseconds"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="create test_data table"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard_version table v1"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="add index dashboard_version.dashboard_id"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_version.dashboard_id and dashboard_version.version"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="Set dashboard version to 1 where 0"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="save existing dashboard data in dashboard_version table v1"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="alter dashboard_version.data to mediumtext v1"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="create team table"
t=2019-05-10T14:22:18-0600 lvl=info msg="Executing migration" logger=migrator id="add index team.org_id"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index team_org_id_name"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="create team member table"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="add index team_member.org_id"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index team_member_org_id_team_id_user_id"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="Add column email to team table"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="Add column external to team_member table"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="Add column permission to team_member table"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="create dashboard acl table"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="add index dashboard_acl_dashboard_id"
t=2019-05-10T14:22:19-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_acl_dashboard_id_user_id"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_acl_dashboard_id_team_id"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="save default acl rules in dashboard_acl table"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="create tag table"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="add index tag.key_value"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="create login attempt table"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="add index login_attempt.username"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_login_attempt_username - v1"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="Rename table login_attempt to login_attempt_tmp_qwerty - v1"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="create login_attempt v2"
t=2019-05-10T14:22:20-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_login_attempt_username - v2"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="copy login_attempt v1 to v2"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="drop login_attempt_tmp_qwerty"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="create user auth table"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="create index IDX_user_auth_auth_module_auth_id - v1"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="alter user_auth.auth_id to length 190"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="Add OAuth access token to user_auth"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="Add OAuth refresh token to user_auth"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="Add OAuth token type to user_auth"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="Add OAuth expiry to user_auth"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="Add index to user_id column in user_auth"
t=2019-05-10T14:22:21-0600 lvl=info msg="Executing migration" logger=migrator id="create server_lock table"
t=2019-05-10T14:22:22-0600 lvl=info msg="Executing migration" logger=migrator id="add index server_lock.operation_uid"
t=2019-05-10T14:22:22-0600 lvl=info msg="Executing migration" logger=migrator id="create user auth token table"
t=2019-05-10T14:22:22-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index user_auth_token.auth_token"
t=2019-05-10T14:22:22-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index user_auth_token.prev_auth_token"
t=2019-05-10T14:22:22-0600 lvl=info msg="Executing migration" logger=migrator id="create cache_data table"
t=2019-05-10T14:22:22-0600 lvl=info msg="Executing migration" logger=migrator id="add unique index cache_data.cache_key"
t=2019-05-10T14:22:22-0600 lvl=info msg="Created default admin" logger=sqlstore user=admin

Admin password changed successfully âœ”

+ service_restart grafana-server
+ service=grafana-server
+ [ 1 -eq 0 ]
+ systemctl restart grafana-server
+ echo select id from org where id=1
+ sqlite3 /var/lib/grafana/grafana.db
+ grep -q 1
+ [ ! 0 -eq 0 ]
+ echo select login from user where login='admin'
+ sqlite3 /var/lib/grafana/grafana.db
+ grep -q admin
+ [ ! 0 -eq 0 ]
+ grafana-cli admin reset-admin-password --config /etc/grafana/grafana.ini --homepath /usr/share/grafana 9da6fece4881
t=2019-05-10T14:22:22-0600 lvl=info msg="Connecting to DB" logger=sqlstore dbtype=sqlite3
t=2019-05-10T14:22:22-0600 lvl=info msg="Starting DB migration" logger=migrator

Admin password changed successfully âœ”

+ grafana-cli plugins install gnocchixyz-gnocchi-datasource
installing gnocchixyz-gnocchi-datasource @ 1.7.0
from url: https://grafana.com/api/plugins/gnocchixyz-gnocchi-datasource/versions/1.7.0/download
into: /var/lib/grafana/plugins

âœ” Installed gnocchixyz-gnocchi-datasource successfully 

Restart grafana after installing plugins . <service grafana-server restart>

+ chown -R grafana:grafana /var/lib/grafana/grafana.db
+ service_restart grafana-server
+ service=grafana-server
+ [ 1 -eq 0 ]
+ systemctl restart grafana-server
+ openstack token issue
+ awk / id / { print $4 }
+ TMPTOKEN=gAAAAABc1d2A4ZA2UsjopKt-dw_gTTbSPOFcoIOmvhqEfvlhe_SvG1bNKtrsNuKIfCxwMC1MNWHgJ4fMQSTD3ezQNeHpDvCHS0dWa0MrIIuaISLuoprve_1mZ2uwHeWrzBMIhXib1XJrX-wiebrqvqLKKBtiJN-xTZjO4eQ4LV7SiSHzgKTUTz0
+ + sqlite3 /var/lib/grafana/grafana.db
echo INSERT INTO "data_source" (id,org_id,version,type,name,access,url,password,user,database,basic_auth,basic_auth_user,basic_auth_password,is_default,json_data,created,updated,with_credentials,secure_json_data) VALUES(1,1,1,'gnocchixyz-gnocchi-datasource','gnocchi','proxy','http://localhost:8041/','','','',0,'','',1,'{"mode":"token","token":"gAAAAABc1d2A4ZA2UsjopKt-dw_gTTbSPOFcoIOmvhqEfvlhe_SvG1bNKtrsNuKIfCxwMC1MNWHgJ4fMQSTD3ezQNeHpDvCHS0dWa0MrIIuaISLuoprve_1mZ2uwHeWrzBMIhXib1XJrX-wiebrqvqLKKBtiJN-xTZjO4eQ4LV7SiSHzgKTUTz0"}',datetime('now'),datetime('now'),0,'{}');
+ cat
+ systemctl daemon-reload
+ service_enable grafana-gnocchi-openstack-token-renewer
+ service=grafana-gnocchi-openstack-token-renewer
+ [ 1 -eq 0 ]
+ systemctl enable grafana-gnocchi-openstack-token-renewer
Created symlink /etc/systemd/system/multi-user.target.wants/grafana-gnocchi-openstack-token-renewer.service â†’ /etc/systemd/system/grafana-gnocchi-openstack-token-renewer.service.
+ service_restart grafana-gnocchi-openstack-token-renewer
+ service=grafana-gnocchi-openstack-token-renewer
+ [ 1 -eq 0 ]
+ systemctl restart grafana-gnocchi-openstack-token-renewer
+ [ 18 -lt 17 ]
+ ceilometer-upgrade --debug --skip-gnocchi-resource-types
+ echo import base64; import sys; sys.stdout.write(base64.b64encode('admin:9da6fece4881'));
+ python
+ AUTHSTR=YWRtaW46OWRhNmZlY2U0ODgx
+ [ -f /local/repository/etc/grafana-default-dashboard-rocky.json ]
+ curl -X POST -H Content-type: application/json -H Authorization: Basic YWRtaW46OWRhNmZlY2U0ODgx -d @/local/repository/etc/grafana-default-dashboard.json http://localhost:3000/api/dashboards/import
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100 33326  100   295  100 33031   1068   116k --:--:-- --:--:-- --:--:--  117k100 33326  100   295  100 33031   1064   116k --:--:-- --:--:-- --:--:--  117k
{"pluginId":"","title":"OpenStack Instance Statistics","imported":true,"importedUri":"db/openstack-instance-statistics","importedUrl":"/d/nzllhBmZz/openstack-instance-statistics","slug":"","dashboardId":0,"folderId":0,"importedRevision":1,"revision":1,"description":"","path":"","removed":false}+ echo TELEMETRY_GRAFANA_DONE="1"
+ logtend grafana
+ area=grafana
+ echo grafana
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=grafana
+ date +%s
+ stamp=1557519746
+ date
+ date=Fri May 10 14:22:26 MDT 2019
+ eval tss=$LOGTIMESTART_grafana
+ tss=1557519707
+ expr 1557519746 - 1557519707
+ tsres=39
+ perl -e print 39 / 60.0 . "\n"
+ resmin=0.65
+ echo END grafana 1557519746 Fri May 10 14:22:26 MDT 2019
+ echo TOTAL grafana 39 0.65
+ [ -z  ]
+ logtstart ceilometer-nodes
+ area=ceilometer-nodes
+ echo ceilometer-nodes
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_nodes
+ date +%s
+ stamp=1557519746
+ date
+ date=Fri May 10 14:22:26 MDT 2019
+ eval LOGTIMESTART_ceilometer_nodes=1557519746
+ LOGTIMESTART_ceilometer_nodes=1557519746
+ echo START ceilometer-nodes 1557519746 Fri May 10 14:22:26 MDT 2019
+ TELEMETRY_COMPUTENODES_DONE=1
+ PHOSTS=
+ mkdir -p /root/setup/pssh.setup-compute-telemetry.stdout /root/setup/pssh.setup-compute-telemetry.stderr
+ getfqdn compute-1
+ n=compute-1
+ + grep -E compute-1\s
cat /root/setup/fqdn.map
+ cut -f2
+ fqdn=compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ echo compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ fqdn=compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ scp -o StrictHostKeyChecking=no /root/setup/settings compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us:/root/setup/settings
+ PHOSTS= -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ echo *** Setting up Compute telemetry on nodes:  -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
*** Setting up Compute telemetry on nodes:  -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ /usr/bin/parallel-ssh -t 0 -O StrictHostKeyChecking=no -H compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us -o /root/setup/pssh.setup-compute-telemetry.stdout -e /root/setup/pssh.setup-compute-telemetry.stderr /local/repository/setup-compute-telemetry.sh
[1] 14:22:32 [SUCCESS] compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ touch /root/setup/compute-telemetry-done-compute-1
+ echo TELEMETRY_COMPUTENODES_DONE="1"
+ logtend ceilometer-nodes
+ area=ceilometer-nodes
+ echo ceilometer-nodes
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_nodes
+ date +%s
+ stamp=1557519752
+ date
+ date=Fri May 10 14:22:32 MDT 2019
+ eval tss=$LOGTIMESTART_ceilometer_nodes
+ tss=1557519746
+ expr 1557519752 - 1557519746
+ tsres=6
+ perl -e print 6 / 60.0 . "\n"
+ resmin=0.1
+ echo END ceilometer-nodes 1557519752 Fri May 10 14:22:32 MDT 2019
+ echo TOTAL ceilometer-nodes 6 0.1
+ [ -z  ]
+ logtstart ceilometer-glance
+ area=ceilometer-glance
+ echo ceilometer-glance
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_glance
+ date +%s
+ stamp=1557519752
+ date
+ date=Fri May 10 14:22:32 MDT 2019
+ eval LOGTIMESTART_ceilometer_glance=1557519752
+ LOGTIMESTART_ceilometer_glance=1557519752
+ echo START ceilometer-glance 1557519752 Fri May 10 14:22:32 MDT 2019
+ TELEMETRY_GLANCE_DONE=1
+ [ 18 -ge 12 ]
+ RIS=oslo_messaging_rabbit
+ [ 18 -lt 13 ]
+ crudini --set /etc/glance/glance-api.conf oslo_messaging_notifications driver messagingv2
+ [ 18 -lt 14 ]
+ crudini --set /etc/glance/glance-api.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ [ 18 -lt 13 ]
+ crudini --set /etc/glance/glance-registry.conf oslo_messaging_notifications driver messagingv2
+ [ 18 -lt 14 ]
+ crudini --set /etc/glance/glance-registry.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ service_restart glance-registry
+ service=glance-registry
+ [ 1 -eq 0 ]
+ systemctl restart glance-registry
+ service_restart glance-api
+ service=glance-api
+ [ 1 -eq 0 ]
+ systemctl restart glance-api
+ echo TELEMETRY_GLANCE_DONE="1"
+ logtend ceilometer-glance
+ area=ceilometer-glance
+ + echo ceilometer-glance
sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_glance
+ date +%s
+ stamp=1557519752
+ date
+ date=Fri May 10 14:22:32 MDT 2019
+ eval tss=$LOGTIMESTART_ceilometer_glance
+ tss=1557519752
+ expr 1557519752 - 1557519752
+ tsres=0
+ perl -e print 0 / 60.0 . "\n"
+ resmin=0
+ echo END ceilometer-glance 1557519752 Fri May 10 14:22:32 MDT 2019
+ echo TOTAL ceilometer-glance 0 0
+ [ -z  ]
+ logtstart ceilometer-cinder
+ area=ceilometer-cinder
+ echo ceilometer-cinder
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_cinder
+ date +%s
+ stamp=1557519752
+ date
+ date=Fri May 10 14:22:32 MDT 2019
+ eval LOGTIMESTART_ceilometer_cinder=1557519752
+ LOGTIMESTART_ceilometer_cinder=1557519752
+ echo START ceilometer-cinder 1557519752 Fri May 10 14:22:32 MDT 2019
+ TELEMETRY_CINDER_DONE=1
+ crudini --set /etc/cinder/cinder.conf DEFAULT control_exchange cinder
+ crudini --set /etc/cinder/cinder.conf DEFAULT notification_driver messagingv2
+ service_restart cinder-api
+ service=cinder-api
+ [ 1 -eq 0 ]
+ systemctl restart cinder-api
Failed to restart cinder-api.service: Unit cinder-api.service not found.
+ service_restart cinder-scheduler
+ service=cinder-scheduler
+ [ 1 -eq 0 ]
+ systemctl restart cinder-scheduler
+ getfqdn ctl
+ n=ctl
+ + cat /root/setup/fqdn.map
grep -E ctl\s
+ cut -f2
+ fqdn=
+ echo
+ fqdn=
+ [ ctl = controller ]
+ scp -o StrictHostKeyChecking=no /root/setup/settings :/root/setup/settings
cp: cannot create regular file ':/root/setup/settings': No such file or directory
+ ssh -o StrictHostKeyChecking=no /local/repository/setup-storage-telemetry.sh
Pseudo-terminal will not be allocated because stdin is not a terminal.
ssh: Could not resolve hostname /local/repository/setup-storage-telemetry.sh: Name or service not known
+ echo TELEMETRY_CINDER_DONE="1"
+ logtend ceilometer-cinder
+ area=ceilometer-cinder
+ echo ceilometer-cinder
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_cinder
+ date +%s
+ stamp=1557519758
+ date
+ date=Fri May 10 14:22:38 MDT 2019
+ eval tss=$LOGTIMESTART_ceilometer_cinder
+ tss=1557519752
+ expr 1557519758 - 1557519752
+ tsres=6
+ perl -e print 6 / 60.0 . "\n"
+ resmin=0.1
+ echo END ceilometer-cinder 1557519758 Fri May 10 14:22:38 MDT 2019
+ echo TOTAL ceilometer-cinder 6 0.1
+ [ -z  ]
+ logtstart ceilometer-swift
+ area=ceilometer-swift
+ echo ceilometer-swift
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_swift
+ date +%s
+ stamp=1557519758
+ date
+ date=Fri May 10 14:22:38 MDT 2019
+ eval LOGTIMESTART_ceilometer_swift=1557519758
+ LOGTIMESTART_ceilometer_swift=1557519758
+ echo START ceilometer-swift 1557519758 Fri May 10 14:22:38 MDT 2019
+ TELEMETRY_SWIFT_DONE=1
+ chmod g+w /var/log/ceilometer
+ [ ! 1 -eq 1 ]
+ maybe_install_packages python-ceilometermiddleware
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-ceilometermiddleware
+ retval=1
+ [ ! -z python-ceilometermiddleware ]
+ dpkg -s python-ceilometermiddleware
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -le 10 ]
+ __openstack role create ResellerAdmin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role create ResellerAdmin
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | 0bf040af584f466cb9a6eb1b93df7736 |
| name      | ResellerAdmin                    |
+-----------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --project service --user ceilometer ResellerAdmin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --project service --user ceilometer ResellerAdmin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 18 -le 11 ]
+ [ 18 -ge 11 ]
+ crudini --set /etc/swift/proxy-server.conf filter:keystoneauth operator_roles admin, user, ResellerAdmin
+ crudini --set /etc/swift/proxy-server.conf filter:ceilometer paste.filter_factory ceilometermiddleware.swift:filter_factory
+ crudini --set /etc/swift/proxy-server.conf filter:ceilometer control_exchange swift
+ crudini --set /etc/swift/proxy-server.conf filter:ceilometer url rabbit://openstack:0375d10f3c80e2774768@controller:5672/
+ crudini --set /etc/swift/proxy-server.conf filter:ceilometer driver messagingv2
+ crudini --set /etc/swift/proxy-server.conf filter:ceilometer topic notifications
+ crudini --set /etc/swift/proxy-server.conf filter:ceilometer log_level WARN
+ usermod -a -G ceilometer swift
+ sed -i -e s/^\(pipeline.*=\)\(.*\)$/\1 ceilometer \2/ /etc/swift/proxy-server.conf
+ sed -i -e s/^\(operator_roles.*=.*\)$/\1,ResellerAdmin/ /etc/swift/proxy-server.conf
+ service_restart swift-proxy
+ service=swift-proxy
+ [ 1 -eq 0 ]
+ systemctl restart swift-proxy
+ echo TELEMETRY_SWIFT_DONE="1"
+ logtend ceilometer-swift
+ area=ceilometer-swift
+ echo ceilometer-swift
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_swift
+ date +%s
+ stamp=1557519763
+ date
+ date=Fri May 10 14:22:43 MDT 2019
+ eval tss=$LOGTIMESTART_ceilometer_swift
+ tss=1557519758
+ expr 1557519763 - 1557519758
+ tsres=5
+ perl -e print 5 / 60.0 . "\n"
+ resmin=0.0833333333333333
+ echo END ceilometer-swift 1557519763 Fri May 10 14:22:43 MDT 2019
+ echo TOTAL ceilometer-swift 5 0.0833333333333333
+ [ -z  ]
+ logtstart ceilometer-heat
+ area=ceilometer-heat
+ + echosed ceilometer-heat -e
 s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_heat
+ date +%s
+ stamp=1557519763
+ date
+ date=Fri May 10 14:22:43 MDT 2019
+ eval LOGTIMESTART_ceilometer_heat=1557519763
+ LOGTIMESTART_ceilometer_heat=1557519763
+ echo START ceilometer-heat 1557519763 Fri May 10 14:22:43 MDT 2019
+ TELEMETRY_HEAT_DONE=1
+ [ 18 -lt 13 ]
+ crudini --set /etc/heat/heat.conf oslo_messaging_notifications driver messagingv2
+ service_restart heat-api
+ service=heat-api
+ [ 1 -eq 0 ]
+ systemctl restart heat-api
+ service_restart heat-api-cfn
+ service=heat-api-cfn
+ [ 1 -eq 0 ]
+ systemctl restart heat-api-cfn
+ service_restart heat-engine
+ service=heat-engine
+ [ 1 -eq 0 ]
+ systemctl restart heat-engine
+ echo TELEMETRY_HEAT_DONE="1"
+ logtend ceilometer-heat
+ area=ceilometer-heat
+ echo ceilometer-heat
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ceilometer_heat
+ date +%s
+ stamp=1557519763
+ date
+ date=Fri May 10 14:22:43 MDT 2019
+ eval tss=$LOGTIMESTART_ceilometer_heat
+ tss=1557519763
+ expr 1557519763 - 1557519763
+ tsres=0
+ perl -e print 0 / 60.0 . "\n"
+ resmin=0
+ echo END ceilometer-heat 1557519763 Fri May 10 14:22:43 MDT 2019
+ echo TOTAL ceilometer-heat 0 0
+ [ -z  ]
+ logtstart trove
+ area=trove
+ echo trove
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=trove
+ date +%s
+ stamp=1557519763
+ date
+ date=Fri May 10 14:22:43 MDT 2019
+ eval LOGTIMESTART_trove=1557519763
+ LOGTIMESTART_trove=1557519763
+ echo START trove 1557519763 Fri May 10 14:22:43 MDT 2019
+ openssl rand -hex 10
+ TROVE_DBPASS=69d72a7dd02aa8d0f960
+ openssl rand -hex 10
+ TROVE_PASS=95dda9ed60ab31c9e2ae
+ maybe_install_packages trove-common
+ [ ! 0 -eq 0 ]
+ are_packages_installed trove-common
+ retval=1
+ [ ! -z trove-common ]
+ dpkg -s trove-common
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ ! 0 -eq 0 ]
+ maybe_install_packages python-trove python-troveclient python-glanceclient trove-api trove-taskmanager trove-conductor
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-trove python-troveclient python-glanceclient trove-api trove-taskmanager trove-conductor
+ retval=1
+ [ ! -z python-trove ]
+ dpkg -s python-trove
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-troveclient ]
+ dpkg -s python-troveclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-glanceclient ]
+ dpkg -s python-glanceclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z trove-api ]
+ dpkg -s trove-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z trove-taskmanager ]
+ dpkg -s trove-taskmanager
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z trove-conductor ]
+ dpkg -s trove-conductor
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -ge 13 ]
+ apt-cache search --names-only ^python-trove-dashboard$
+ wc -l
+ sepdashpkg=1
+ [ ! 1 = 0 ]
+ madedir=0
+ [ ! -f /var/lib/openstack-dashboard/secret-key/.secret_key_store ]
+ [ ! -d /var/lib/openstack-dashboard/secret-key ]
+ touch /var/lib/openstack-dashboard/secret-key/.secret_key_store
+ maybe_install_packages python-trove-dashboard
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-trove-dashboard
+ retval=1
+ [ ! -z python-trove-dashboard ]
+ dpkg -s python-trove-dashboard
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 0 -eq 1 ]
+ echo create database trove
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on trove.* to 'trove'@'localhost' identified by '69d72a7dd02aa8d0f960'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ + mysql -u root --password=ad12065d4a6fcf049d20echo
 grant all privileges on trove.* to 'trove'@'%' identified by '69d72a7dd02aa8d0f960'
+ [ 18 -eq 10 ]
+ __openstack user create --domain default --password 95dda9ed60ab31c9e2ae trove
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 95dda9ed60ab31c9e2ae trove
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | d08b4c35791c4dfa80e139025934235f |
| name                | trove                            |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user trove --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user trove --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name trove --description OpenStack Database Service database
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name trove --description OpenStack Database Service database
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Database Service       |
| enabled     | True                             |
| id          | 1f8ece17f00245c9af283d7464f68543 |
| name        | trove                            |
| type        | database                         |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne database public http://controller:8779/v1.0/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne database public http://controller:8779/v1.0/%(tenant_id)s
+--------------+-------------------------------------------+
| Field        | Value                                     |
+--------------+-------------------------------------------+
| enabled      | True                                      |
| id           | 5ddcf0461600438a9e04e919f01eee08          |
| interface    | public                                    |
| region       | RegionOne                                 |
| region_id    | RegionOne                                 |
| service_id   | 1f8ece17f00245c9af283d7464f68543          |
| service_name | trove                                     |
| service_type | database                                  |
| url          | http://controller:8779/v1.0/%(tenant_id)s |
+--------------+-------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne database internal http://controller:8779/v1.0/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne database internal http://controller:8779/v1.0/%(tenant_id)s
+--------------+-------------------------------------------+
| Field        | Value                                     |
+--------------+-------------------------------------------+
| enabled      | True                                      |
| id           | e16cb958b9e14448a17212796b660b4b          |
| interface    | internal                                  |
| region       | RegionOne                                 |
| region_id    | RegionOne                                 |
| service_id   | 1f8ece17f00245c9af283d7464f68543          |
| service_name | trove                                     |
| service_type | database                                  |
| url          | http://controller:8779/v1.0/%(tenant_id)s |
+--------------+-------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne database admin http://controller:8779/v1.0/%(tenant_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne database admin http://controller:8779/v1.0/%(tenant_id)s
+--------------+-------------------------------------------+
| Field        | Value                                     |
+--------------+-------------------------------------------+
| enabled      | True                                      |
| id           | c3b23c2fe843433895cb68e91297f76e          |
| interface    | admin                                     |
| region       | RegionOne                                 |
| region_id    | RegionOne                                 |
| service_id   | 1f8ece17f00245c9af283d7464f68543          |
| service_name | trove                                     |
| service_type | database                                  |
| url          | http://controller:8779/v1.0/%(tenant_id)s |
+--------------+-------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ crudini --set /etc/trove/trove.conf DEFAULT verbose False
+ crudini --set /etc/trove/trove.conf DEFAULT debug False
+ crudini --set /etc/trove/trove.conf DEFAULT log_dir /var/log/trove
+ crudini --set /etc/ceilometer/ceilometer.conf DEFAULT bind_host 192.168.0.1
+ [ 18 -lt 12 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/trove/trove.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ crudini --set /etc/trove/trove.conf DEFAULT trove_auth_url http://controller:5000/v3
+ crudini --set /etc/trove/trove.conf DEFAULT nova_compute_url http://controller:8774/v2.1
+ crudini --set /etc/trove/trove.conf DEFAULT cinder_url http://controller:8776/v1
+ crudini --set /etc/trove/trove.conf DEFAULT swift_url http://controller:8080/v1/AUTH_
+ crudini --set /etc/trove/trove.conf DEFAULT sql_connection mysql+pymysql://trove:69d72a7dd02aa8d0f960@controller/trove
+ crudini --set /etc/trove/trove.conf database connection mysql+pymysql://trove:69d72a7dd02aa8d0f960@controller/trove
+ crudini --set /etc/trove/trove.conf DEFAULT notifier_queue_hostname controller
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT verbose False
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT debug False
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT log_dir /var/log/trove
+ [ 18 -lt 12 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT trove_auth_url http://controller:5000/v3
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT nova_compute_url http://controller:8774/v2.1
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT cinder_url http://controller:8776/v1
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT swift_url http://controller:8080/v1/AUTH_
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT sql_connection mysql+pymysql://trove:69d72a7dd02aa8d0f960@controller/trove
+ crudini --set /etc/trove/trove-taskmanager.conf database connection mysql+pymysql://trove:69d72a7dd02aa8d0f960@controller/trove
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT notifier_queue_hostname controller
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT verbose False
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT debug False
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT log_dir /var/log/trove
+ [ 18 -lt 12 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT trove_auth_url http://controller:5000/v3
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT nova_compute_url http://controller:8774/v2.1
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT cinder_url http://controller:8776/v1
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT swift_url http://controller:8080/v1/AUTH_
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT sql_connection mysql+pymysql://trove:69d72a7dd02aa8d0f960@controller/trove
+ crudini --set /etc/trove/trove-conductor.conf database connection mysql+pymysql://trove:69d72a7dd02aa8d0f960@controller/trove
+ crudini --set /etc/trove/trove-conductor.conf DEFAULT notifier_queue_hostname controller
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT nova_proxy_admin_user adminapi
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT nova_proxy_admin_pass 92748256c1e798f84f04
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT nova_proxy_admin_tenant_name service
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT taskmanager_manager trove.taskmanager.manager.Manager
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT
+ crudini --set /etc/trove/trove-taskmanager.conf DEFAULT
+ crudini --set /etc/trove/trove.conf DEFAULT default_datastore mysql
+ crudini --set /etc/trove/trove.conf DEFAULT add_addresses True
+ crudini --set /etc/trove/trove.conf DEFAULT network_label_regex ^NETWORK_LABEL$
+ crudini --set /etc/trove/trove.conf DEFAULT api_paste_config /etc/trove/api-paste.ini
+ cat
+ [ 18 -lt 11 ]
+ crudini --set /etc/trove/trove.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/trove/trove.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/trove/trove.conf keystone_authtoken auth_type password
+ crudini --set /etc/trove/trove.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/trove/trove.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/trove/trove.conf keystone_authtoken project_name service
+ crudini --set /etc/trove/trove.conf keystone_authtoken username trove
+ crudini --set /etc/trove/trove.conf keystone_authtoken password 95dda9ed60ab31c9e2ae
+ crudini --set /etc/trove/trove.conf keystone_authtoken region_name RegionOne
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/trove/trove.conf keystone_authtoken memcached_servers controller:11211
+ sed -i -e s/^\(.*auth_host.*=.*\)$/#\1/ /etc/trove/api-paste.ini
+ sed -i -e s/^\(.*auth_port.*=.*\)$/#\1/ /etc/trove/api-paste.ini
+ sed -i -e s/^\(.*auth_protocol.*=.*\)$/#\1/ /etc/trove/api-paste.ini
+ mkdir -p /var/cache/trove
+ chown -R trove:trove /var/cache/trove
+ sed -i.orig -E -e s|(CONFIG_FILE=.*)$|CONFIG_FILE="/etc/trove/trove-taskmanager.conf"| /etc/init/trove-taskmanager.conf
sed: can't read /etc/init/trove-taskmanager.conf: No such file or directory
+ sed -i.orig -E -e s|(CONFIG_FILE=.*)$|CONFIG_FILE="/etc/trove/trove-conductor.conf"| /etc/init/trove-conductor.conf
sed: can't read /etc/init/trove-conductor.conf: No such file or directory
+ sed -i.orig -E -e s|(CONFIG_FILE=.*)$|CONFIG_FILE="/etc/trove/trove-taskmanager.conf"| /etc/init.d/trove-taskmanager
+ sed -i.orig -E -e s|(CONFIG_FILE=.*)$|CONFIG_FILE="/etc/trove/trove-conductor.conf"| /etc/init.d/trove-conductor
+ [ 1 -eq 1 ]
+ systemctl daemon-reload
+ su -s /bin/sh -c /usr/bin/trove-manage db_sync trove
/usr/lib/python2.7/dist-packages/sqlalchemy/sql/elements.py:4360: SAWarning: Textual column expression 'id' should be explicitly declared with text('id'), or use column('id') for more specificity (this warning may be suppressed after 10 occurrences)
  if guess_is_literal else "column"
+ [ ! 0 -eq 0 ]
+ su -s /bin/sh -c trove-manage datastore_update mysql '' trove
Datastore 'mysql' updated.
+ service_restart trove-api
+ service=trove-api
+ [ 1 -eq 0 ]
+ systemctl restart trove-api
+ service_enable trove-api
+ service=trove-api
+ [ 1 -eq 0 ]
+ systemctl enable trove-api
Synchronizing state of trove-api.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable trove-api
+ service_restart trove-taskmanager
+ service=trove-taskmanager
+ [ 1 -eq 0 ]
+ systemctl restart trove-taskmanager
+ service_enable trove-taskmanager
+ service=trove-taskmanager
+ [ 1 -eq 0 ]
+ systemctl enable trove-taskmanager
Synchronizing state of trove-taskmanager.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable trove-taskmanager
+ service_restart trove-conductor
+ service=trove-conductor
+ [ 1 -eq 0 ]
+ systemctl restart trove-conductor
+ service_enable trove-conductor
+ service=trove-conductor
+ [ 1 -eq 0 ]
+ systemctl enable trove-conductor
Synchronizing state of trove-conductor.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable trove-conductor
+ service_restart apache2
+ service=apache2
+ [ 1 -eq 0 ]
+ systemctl restart apache2
+ service_restart memcached
+ service=memcached
+ [ 1 -eq 0 ]
+ systemctl restart memcached
+ echo TROVE_DBPASS="69d72a7dd02aa8d0f960"
+ echo TROVE_PASS="95dda9ed60ab31c9e2ae"
+ logtend trove
+ area=trove
+ echo trove
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=trove
+ date +%s
+ stamp=1557519803
+ date
+ date=Fri May 10 14:23:23 MDT 2019
+ eval tss=$LOGTIMESTART_trove
+ tss=1557519763
+ expr 1557519803 - 1557519763
+ tsres=40
+ perl -e print 40 / 60.0 . "\n"
+ resmin=0.666666666666667
+ echo END trove 1557519803 Fri May 10 14:23:23 MDT 2019
+ echo TOTAL trove 40 0.666666666666667
+ [ -z  ]
+ logtstart sahara
+ area=sahara
+ echo sahara
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=sahara
+ date +%s
+ stamp=1557519803
+ date
+ date=Fri May 10 14:23:23 MDT 2019
+ eval LOGTIMESTART_sahara=1557519803
+ LOGTIMESTART_sahara=1557519803
+ echo START sahara 1557519803 Fri May 10 14:23:23 MDT 2019
+ openssl rand -hex 10
+ SAHARA_DBPASS=5bbc4b86d0e78513a855
+ openssl rand -hex 10
+ SAHARA_PASS=3061a6bc4d5eb38ddf58
+ echo create database sahara
+ mysql -u root --password=ad12065d4a6fcf049d20
+ + echo grant all privileges on sahara.* to 'sahara'@'localhost' identified by '5bbc4b86d0e78513a855'
mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on sahara.* to 'sahara'@'%' identified by '5bbc4b86d0e78513a855'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ [ 18 -eq 10 ]
+ __openstack user create --domain default --password 3061a6bc4d5eb38ddf58 sahara
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 3061a6bc4d5eb38ddf58 sahara
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 80e707aaaaa743d8b6025033bb752959 |
| name                | sahara                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user sahara --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user sahara --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name sahara --description OpenStack Data Processing Service data-processing
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name sahara --description OpenStack Data Processing Service data-processing
+-------------+-----------------------------------+
| Field       | Value                             |
+-------------+-----------------------------------+
| description | OpenStack Data Processing Service |
| enabled     | True                              |
| id          | 93567621cf3a42449703f7a6553baeb6  |
| name        | sahara                            |
| type        | data-processing                   |
+-------------+-----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne data-processing public http://controller:8386/v1.1/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne data-processing public http://controller:8386/v1.1/%(project_id)s
+--------------+--------------------------------------------+
| Field        | Value                                      |
+--------------+--------------------------------------------+
| enabled      | True                                       |
| id           | a79e53950ff641f4b81e203c2846b57f           |
| interface    | public                                     |
| region       | RegionOne                                  |
| region_id    | RegionOne                                  |
| service_id   | 93567621cf3a42449703f7a6553baeb6           |
| service_name | sahara                                     |
| service_type | data-processing                            |
| url          | http://controller:8386/v1.1/%(project_id)s |
+--------------+--------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne data-processing internal http://controller:8386/v1.1/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne data-processing internal http://controller:8386/v1.1/%(project_id)s
+--------------+--------------------------------------------+
| Field        | Value                                      |
+--------------+--------------------------------------------+
| enabled      | True                                       |
| id           | ca33c3092b964a7bae4bda1a8b594f9a           |
| interface    | internal                                   |
| region       | RegionOne                                  |
| region_id    | RegionOne                                  |
| service_id   | 93567621cf3a42449703f7a6553baeb6           |
| service_name | sahara                                     |
| service_type | data-processing                            |
| url          | http://controller:8386/v1.1/%(project_id)s |
+--------------+--------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne data-processing admin http://controller:8386/v1.1/%(project_id)s
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne data-processing admin http://controller:8386/v1.1/%(project_id)s
+--------------+--------------------------------------------+
| Field        | Value                                      |
+--------------+--------------------------------------------+
| enabled      | True                                       |
| id           | 5f065d3901be42118cd76bcb4b639679           |
| interface    | admin                                      |
| region       | RegionOne                                  |
| region_id    | RegionOne                                  |
| service_id   | 93567621cf3a42449703f7a6553baeb6           |
| service_name | sahara                                     |
| service_type | data-processing                            |
| url          | http://controller:8386/v1.1/%(project_id)s |
+--------------+--------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ aserr=0
+ apt-cache search+  ^sahara$
grep -q sahara
+ [ 0 -eq 0 ]
+ APT_HAS_SAHARA=1
+ [ 1 -eq 0 ]
+ maybe_install_packages sahara-common
+ [ ! 0 -eq 0 ]
+ are_packages_installed sahara-common
+ retval=1
+ [ ! -z sahara-common ]
+ dpkg -s sahara-common
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ aserr=0
+ maybe_install_packages sahara-api sahara-engine
+ [ ! 0 -eq 0 ]
+ are_packages_installed sahara-api sahara-engine
+ retval=1
+ [ ! -z sahara-api ]
+ dpkg -s sahara-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z sahara-engine ]
+ dpkg -s sahara-engine
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 18 -ge 13 ]
+ apt-cache search --names-only ^python-sahara-dashboard$
+ wc -l
+ sepdashpkg=1
+ [ ! 1 = 0 ]
+ madedir=0
+ [ ! -f /var/lib/openstack-dashboard/secret-key/.secret_key_store ]
+ maybe_install_packages python-sahara-dashboard
+ [ ! 0 -eq 0 ]
+ are_packages_installed python-sahara-dashboard
+ retval=1
+ [ ! -z python-sahara-dashboard ]
+ dpkg -s python-sahara-dashboard
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ 0 -eq 1 ]
+ mkdir -p /etc/sahara
+ touch /etc/sahara/sahara.conf
+ chown -R sahara /etc/sahara
+ crudini --set /etc/sahara/sahara.conf database connection mysql+pymysql://sahara:5bbc4b86d0e78513a855@controller/sahara
+ crudini --set /etc/sahara/sahara.conf DEFAULT verbose False
+ crudini --set /etc/sahara/sahara.conf DEFAULT debug False
+ crudini --set /etc/sahara/sahara.conf DEFAULT auth_strategy keystone
+ crudini --set /etc/sahara/sahara.conf DEFAULT use_neutron true
+ [ 18 -lt 11 ]
+ [ 18 -lt 14 ]
+ crudini --set /etc/sahara/sahara.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ [ 18 -lt 11 ]
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken www_authenticate_uri http://controller:5000
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken auth_type password
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken project_name service
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken username sahara
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken password 3061a6bc4d5eb38ddf58
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken region_name RegionOne
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken os_region_name RegionOne
+ crudini --set /etc/sahara/sahara.conf trustee auth_url http://controller:5000
+ crudini --set /etc/sahara/sahara.conf trustee username sahara
+ crudini --set /etc/sahara/sahara.conf trustee password 3061a6bc4d5eb38ddf58
+ crudini --set /etc/sahara/sahara.conf trustee project_name admin
+ crudini --set /etc/sahara/sahara.conf trustee project_domain_name default
+ crudini --set /etc/sahara/sahara.conf trustee user_domain_name default
+ [ 18 -ge 13 -o 1 -eq 1 ]
+ crudini --set /etc/sahara/sahara.conf keystone_authtoken memcached_servers controller:11211
+ crudini --set /etc/sahara/sahara.conf ec2authtoken auth_uri http://controller:5000/v3
+ sed -i -e s/^\(.*auth_host.*=.*\)$/#\1/ /etc/sahara/sahara.conf
+ sed -i -e s/^\(.*auth_port.*=.*\)$/#\1/ /etc/sahara/sahara.conf
+ sed -i -e s/^\(.*auth_protocol.*=.*\)$/#\1/ /etc/sahara/sahara.conf
+ [ ! 0 -eq 0 ]
+ sahara-db-manage --config-file /etc/sahara/sahara.conf upgrade head
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 001, Icehouse release
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, placeholder
INFO  [alembic.runtime.migration] Running upgrade 002 -> 003, placeholder
INFO  [alembic.runtime.migration] Running upgrade 003 -> 004, placeholder
INFO  [alembic.runtime.migration] Running upgrade 004 -> 005, placeholder
INFO  [alembic.runtime.migration] Running upgrade 005 -> 006, placeholder
INFO  [alembic.runtime.migration] Running upgrade 006 -> 007, convert clusters.status_description to LongText
INFO  [alembic.runtime.migration] Running upgrade 007 -> 008, add security_groups field to node groups
INFO  [alembic.runtime.migration] Running upgrade 008 -> 009, add rollback info to cluster
INFO  [alembic.runtime.migration] Running upgrade 009 -> 010, add auto_security_groups flag to node group
INFO  [alembic.runtime.migration] Running upgrade 010 -> 011, add Sahara settings info to cluster
INFO  [alembic.runtime.migration] Running upgrade 011 -> 012, add availability_zone field to node groups
INFO  [alembic.runtime.migration] Running upgrade 012 -> 013, add volumes_availability_zone field to node groups
INFO  [alembic.runtime.migration] Running upgrade 013 -> 014, add_volume_type
INFO  [alembic.runtime.migration] Running upgrade 014 -> 015, add_events_objects
INFO  [alembic.runtime.migration] Running upgrade 015 -> 016, Add is_proxy_gateway
INFO  [alembic.runtime.migration] Running upgrade 016 -> 017, drop progress in JobExecution
INFO  [alembic.runtime.migration] Running upgrade 017 -> 018, add volume_local_to_instance flag
INFO  [alembic.runtime.migration] Running upgrade 018 -> 019, Add is_default field for cluster and node_group templates
INFO  [alembic.runtime.migration] Running upgrade 019 -> 020, remove redandunt progress ops
INFO  [alembic.runtime.migration] Running upgrade 020 -> 021, Add data_source_urls to job_executions to support placeholders
INFO  [alembic.runtime.migration] Running upgrade 021 -> 022, add_job_interface
INFO  [alembic.runtime.migration] Running upgrade 022 -> 023, add_use_autoconfig
INFO  [alembic.runtime.migration] Running upgrade 023 -> 024, manila_shares
INFO  [alembic.runtime.migration] Running upgrade 024 -> 025, Increase internal_ip and management_ip column size to work with IPv6
INFO  [alembic.runtime.migration] Running upgrade 025 -> 026, add is_public and is_protected flags
INFO  [alembic.runtime.migration] Running upgrade 026 -> 027, Rename oozie_job_id
INFO  [alembic.runtime.migration] Running upgrade 027 -> 028, add_storage_devices_number
INFO  [alembic.runtime.migration] Running upgrade 028 -> 029, set is_protected on is_default
INFO  [alembic.runtime.migration] Running upgrade 029 -> 030, health-check
INFO  [alembic.runtime.migration] Running upgrade 030 -> 031, added_plugins_table
INFO  [alembic.runtime.migration] Running upgrade 031 -> 032, 032_add_domain_name
INFO  [alembic.runtime.migration] Running upgrade 032 -> 033, 033_add anti_affinity_ratio field to cluster
INFO  [alembic.runtime.migration] Running upgrade 033 -> 034, Add boot_from_volumes field for node_groups and related classes
+ mkdir -p /var/log/sahara
+ [ 1 -eq 0 ]
+ service_restart sahara-api
+ service=sahara-api
+ [ 1 -eq 0 ]
+ systemctl restart sahara-api
Failed to restart sahara-api.service: Unit sahara-api.service not found.
+ service_enable sahara-api
+ service=sahara-api
+ [ 1 -eq 0 ]
+ systemctl enable sahara-api
Failed to enable unit: Unit file sahara-api.service does not exist.
+ service_restart sahara-engine
+ service=sahara-engine
+ [ 1 -eq 0 ]
+ systemctl restart sahara-engine
+ service_enable sahara-engine
+ service=sahara-engine
+ [ 1 -eq 0 ]
+ systemctl enable sahara-engine
Synchronizing state of sahara-engine.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable sahara-engine
+ service_restart apache2
+ service=apache2
+ [ 1 -eq 0 ]
+ systemctl restart apache2
+ service_restart memcached
+ service=memcached
+ [ 1 -eq 0 ]
+ systemctl restart memcached
+ echo SAHARA_DBPASS="5bbc4b86d0e78513a855"
+ echo SAHARA_PASS="3061a6bc4d5eb38ddf58"
+ logtend sahara
+ area=sahara
+ echo sahara
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=sahara
+ date +%s
+ stamp=1557519848
+ date
+ date=Fri May 10 14:24:08 MDT 2019
+ eval tss=$LOGTIMESTART_sahara
+ tss=1557519803
+ expr 1557519848 - 1557519803
+ tsres=45
+ perl -e print 45 / 60.0 . "\n"
+ resmin=0.75
+ echo END sahara 1557519848 Fri May 10 14:24:08 MDT 2019
+ echo TOTAL sahara 45 0.75
+ [ 0 = 1 -a rocky = kilo -a -n  -a -z  ]
+ [ 18 -ge 14 -a -z  ]
+ logtstart designate
+ area=designate
+ echo designate
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=designate
+ date +%s
+ stamp=1557519848
+ date
+ date=Fri May 10 14:24:08 MDT 2019
+ eval LOGTIMESTART_designate=1557519848
+ LOGTIMESTART_designate=1557519848
+ echo START designate 1557519848 Fri May 10 14:24:08 MDT 2019
+ openssl rand -hex 10
+ DESIGNATE_DBPASS=3d456060389042ecbd48
+ openssl rand -hex 10
+ DESIGNATE_PASS=2002dfe5f7494556215a
+ echo create database designate
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on designate.* to 'designate'@'localhost' identified by '3d456060389042ecbd48'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ echo grant all privileges on designate.* to 'designate'@'%' identified by '3d456060389042ecbd48'
+ mysql -u root --password=ad12065d4a6fcf049d20
+ __openstack user create --domain default --password 2002dfe5f7494556215a designate
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 2002dfe5f7494556215a designate
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 6bc74a283627441e9042f9e6edb685f1 |
| name                | designate                        |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user designate --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user designate --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name designate --description OpenStack Domain Name Service dns
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name designate --description OpenStack Domain Name Service dns
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Domain Name Service    |
| enabled     | True                             |
| id          | 28ed68c2c46b46ada8d540c49823e133 |
| name        | designate                        |
| type        | dns                              |
+-------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne dns public http://controller:9001/v2
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne dns public http://controller:9001/v2
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 6b608035ddb742ec9825e76c89fa8c8f |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 28ed68c2c46b46ada8d540c49823e133 |
| service_name | designate                        |
| service_type | dns                              |
| url          | http://controller:9001/v2        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne dns internal http://controller:9001/v2
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne dns internal http://controller:9001/v2
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 473c33e586be497fac279f6d8af5ca1a |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 28ed68c2c46b46ada8d540c49823e133 |
| service_name | designate                        |
| service_type | dns                              |
| url          | http://controller:9001/v2        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne dns admin http://controller:9001/v2
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne dns admin http://controller:9001/v2
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | b2997137574f4bce8c21c71557060d5b |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 28ed68c2c46b46ada8d540c49823e133 |
| service_name | designate                        |
| service_type | dns                              |
| url          | http://controller:9001/v2        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages designate bind9 bind9utils bind9-doc
+ [ ! 0 -eq 0 ]
+ are_packages_installed designate bind9 bind9utils bind9-doc
+ retval=1
+ [ ! -z designate ]
+ dpkg -s designate
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z bind9 ]
+ dpkg -s bind9
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z bind9utils ]
+ dpkg -s bind9utils
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z bind9-doc ]
+ dpkg -s bind9-doc
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ rndc-confgen -a -k designate -c /etc/designate/rndc.key
wrote key file "/etc/designate/rndc.key"
+ chgrp bind /etc/designate/rndc.key
+ chmod g+r /etc/designate/rndc.key
+ hostname
+ sed -n -e s/[^\.]*\.\(.*\)$/\1/p
+ mydomain=
+ sed -n -e s/^nameserver \([0-9]*\.[0-9]*\.[0-9]*\.[0-9]*\).*$/\1/p
+ head -1
+ mynameserver=130.127.132.51
+ [ -z 130.127.132.51 ]
+ [ -z 130.127.132.51 ]
+ fstr=forwarders { 130.127.132.51; };
+ cat
+ service_enable bind9
+ service=bind9
+ [ 1 -eq 0 ]
+ systemctl enable bind9
Synchronizing state of bind9.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable bind9
+ service_restart bind9
+ service=bind9
+ [ 1 -eq 0 ]
+ systemctl restart bind9
+ crudini --set /etc/designate/designate.conf storage:sqlalchemy connection mysql+pymysql://designate:3d456060389042ecbd48@controller/designate
+ crudini --del /etc/designate/designate.conf keystone_authtoken auth_host
+ crudini --del /etc/designate/designate.conf keystone_authtoken auth_port
+ crudini --del /etc/designate/designate.conf keystone_authtoken auth_protocol
+ crudini --set /etc/designate/designate.conf service:api auth_strategy keystone
+ crudini --set /etc/designate/designate.conf service:api api_host 0.0.0.0
+ crudini --set /etc/designate/designate.conf service:api api_port 9001
+ crudini --set /etc/designate/designate.conf service:api listen 0.0.0.0:9001
+ crudini --set /etc/designate/designate.conf service:api enable_api_v1 True
+ crudini --set /etc/designate/designate.conf service:api api_base_url http://controller:9001/
+ crudini --set /etc/designate/designate.conf service:api enabled_extensions_v1 quotas,reports
+ crudini --set /etc/designate/designate.conf service:api enable_api_v2 True
+ crudini --set /etc/designate/designate.conf service:api enabled_extensions_v2 quotas,reports
+ crudini --set /etc/designate/designate.conf service:worker enabled True
+ crudini --set /etc/designate/designate.conf service:worker notify True
+ crudini --set /etc/designate/designate.conf DEFAULT verbose False
+ crudini --set /etc/designate/designate.conf DEFAULT debug False
+ [ 18 -lt 14 ]
+ crudini --set /etc/designate/designate.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ crudini --del /etc/designate/designate.conf keystone_authtoken project_domain_id
+ crudini --del /etc/designate/designate.conf keystone_authtoken user_domain_id
+ crudini --set /etc/designate/designate.conf keystone_authtoken auth_uri http://controller:5000
+ crudini --set /etc/designate/designate.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/designate/designate.conf keystone_authtoken auth_type password
+ crudini --set /etc/designate/designate.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/designate/designate.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/designate/designate.conf keystone_authtoken project_name service
+ crudini --set /etc/designate/designate.conf keystone_authtoken username designate
+ crudini --set /etc/designate/designate.conf keystone_authtoken password 2002dfe5f7494556215a
+ crudini --set /etc/designate/designate.conf keystone_authtoken region_name RegionOne
+ crudini --set /etc/designate/designate.conf keystone_authtoken memcached_servers controller:11211
+ su -s /bin/sh -c designate-manage database sync designate
2019-05-10 14:24:27.089 9399 INFO migrate.versioning.api [designate-manage - - - - -] 69 -> 70... [00m
2019-05-10 14:24:31.695 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:31.696 9399 INFO migrate.versioning.api [designate-manage - - - - -] 70 -> 71... [00m
2019-05-10 14:24:31.772 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:31.773 9399 INFO migrate.versioning.api [designate-manage - - - - -] 71 -> 72... [00m
2019-05-10 14:24:31.806 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:31.806 9399 INFO migrate.versioning.api [designate-manage - - - - -] 72 -> 73... [00m
2019-05-10 14:24:31.839 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:31.840 9399 INFO migrate.versioning.api [designate-manage - - - - -] 73 -> 74... [00m
2019-05-10 14:24:31.875 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:31.877 9399 INFO migrate.versioning.api [designate-manage - - - - -] 74 -> 75... [00m
2019-05-10 14:24:31.931 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:31.931 9399 INFO migrate.versioning.api [designate-manage - - - - -] 75 -> 76... [00m
2019-05-10 14:24:31.964 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:31.965 9399 INFO migrate.versioning.api [designate-manage - - - - -] 76 -> 77... [00m
2019-05-10 14:24:32.006 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:32.007 9399 INFO migrate.versioning.api [designate-manage - - - - -] 77 -> 78... [00m
2019-05-10 14:24:32.040 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:32.040 9399 INFO migrate.versioning.api [designate-manage - - - - -] 78 -> 79... [00m
2019-05-10 14:24:32.073 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:32.074 9399 INFO migrate.versioning.api [designate-manage - - - - -] 79 -> 80... [00m
2019-05-10 14:24:32.955 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:32.956 9399 INFO migrate.versioning.api [designate-manage - - - - -] 80 -> 81... [00m
2019-05-10 14:24:37.053 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:37.053 9399 INFO migrate.versioning.api [designate-manage - - - - -] 81 -> 82... [00m
2019-05-10 14:24:37.253 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:37.254 9399 INFO migrate.versioning.api [designate-manage - - - - -] 82 -> 83... [00m
2019-05-10 14:24:37.312 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:37.313 9399 INFO migrate.versioning.api [designate-manage - - - - -] 83 -> 84... [00m
2019-05-10 14:24:37.313 9399 INFO 084_add_delayed_notify_column [designate-manage - - - - -] Adding boolean column delayed_notify to table 'zones'[00m
2019-05-10 14:24:37.899 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:37.900 9399 INFO migrate.versioning.api [designate-manage - - - - -] 84 -> 85... [00m
2019-05-10 14:24:38.579 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:38.580 9399 INFO migrate.versioning.api [designate-manage - - - - -] 85 -> 86... [00m
2019-05-10 14:24:39.836 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:39.837 9399 INFO migrate.versioning.api [designate-manage - - - - -] 86 -> 87... [00m
2019-05-10 14:24:39.861 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:39.861 9399 INFO migrate.versioning.api [designate-manage - - - - -] 87 -> 88... [00m
2019-05-10 14:24:39.895 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:39.895 9399 INFO migrate.versioning.api [designate-manage - - - - -] 88 -> 89... [00m
2019-05-10 14:24:39.945 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:39.945 9399 INFO migrate.versioning.api [designate-manage - - - - -] 89 -> 90... [00m
2019-05-10 14:24:39.970 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:39.970 9399 INFO migrate.versioning.api [designate-manage - - - - -] 90 -> 91... [00m
2019-05-10 14:24:40.003 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:40.003 9399 INFO migrate.versioning.api [designate-manage - - - - -] 91 -> 92... [00m
2019-05-10 14:24:40.028 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:40.028 9399 INFO migrate.versioning.api [designate-manage - - - - -] 92 -> 93... [00m
2019-05-10 14:24:40.065 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:40.065 9399 INFO migrate.versioning.api [designate-manage - - - - -] 93 -> 94... [00m
2019-05-10 14:24:40.095 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:40.096 9399 INFO migrate.versioning.api [designate-manage - - - - -] 94 -> 95... [00m
2019-05-10 14:24:40.121 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:40.121 9399 INFO migrate.versioning.api [designate-manage - - - - -] 95 -> 96... [00m
2019-05-10 14:24:40.146 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:40.146 9399 INFO migrate.versioning.api [designate-manage - - - - -] 96 -> 97... [00m
2019-05-10 14:24:40.355 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:40.356 9399 INFO migrate.versioning.api [designate-manage - - - - -] 97 -> 98... [00m
2019-05-10 14:24:40.406 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:40.406 9399 INFO migrate.versioning.api [designate-manage - - - - -] 98 -> 99... [00m
2019-05-10 14:24:41.243 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
2019-05-10 14:24:41.244 9399 INFO migrate.versioning.api [designate-manage - - - - -] 99 -> 100... [00m
2019-05-10 14:24:41.436 9399 INFO migrate.versioning.api [designate-manage - - - - -] done[00m
+ service_restart designate-central
+ service=designate-central
+ [ 1 -eq 0 ]
+ systemctl restart designate-central
+ service_enable designate-central
+ service=designate-central
+ [ 1 -eq 0 ]
+ systemctl enable designate-central
Synchronizing state of designate-central.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable designate-central
+ service_restart designate-api
+ service=designate-api
+ [ 1 -eq 0 ]
+ systemctl restart designate-api
+ service_enable designate-api
+ service=designate-api
+ [ 1 -eq 0 ]
+ systemctl enable designate-api
Synchronizing state of designate-api.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable designate-api
+ cat
+ chown designate /etc/designate/pools.yaml
+ su -s /bin/sh -c designate-manage pool update designate
Updating Pools Configuration
****************************
2019-05-10 14:24:43.727 9644 INFO designate.manage.pool [designate-manage - - - - -] Updating existing pool: <Pool id:'794ccc2c-d751-44fe-b57f-8894c9f5c842' name:'default'>[00m

+ maybe_install_packages designate-worker designate-producer designate-mdns
+ [ ! 0 -eq 0 ]
+ are_packages_installed designate-worker designate-producer designate-mdns
+ retval=1
+ [ ! -z designate-worker ]
+ dpkg -s designate-worker
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z designate-producer ]
+ dpkg -s designate-producer
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z designate-mdns ]
+ dpkg -s designate-mdns
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ service_restart designate-worker
+ service=designate-worker
+ [ 1 -eq 0 ]
+ systemctl restart designate-worker
+ service_enable designate-worker
+ service=designate-worker
+ [ 1 -eq 0 ]
+ systemctl enable designate-worker
Synchronizing state of designate-worker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable designate-worker
+ service_restart designate-producer
+ service=designate-producer
+ [ 1 -eq 0 ]
+ systemctl restart designate-producer
+ service_enable designate-producer
+ service=designate-producer
+ [ 1 -eq 0 ]
+ systemctl enable designate-producer
Synchronizing state of designate-producer.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable designate-producer
+ service_restart designate-mdns
+ service=designate-mdns
+ [ 1 -eq 0 ]
+ systemctl restart designate-mdns
+ service_enable designate-mdns
+ service=designate-mdns
+ [ 1 -eq 0 ]
+ systemctl enable designate-mdns
Synchronizing state of designate-mdns.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable designate-mdns
+ rm -f /var/lib/designate/designate.sqlite
+ crudini --set /etc/neutron/neutron.conf DEFAULT dns_domain .
+ crudini --set /etc/neutron/neutron.conf DEFAULT external_dns_driver designate
+ crudini --set /etc/neutron/neutron.conf designate url http://controller:9001/v2
+ crudini --set /etc/neutron/neutron.conf designate auth_url http://controller:5000
+ crudini --set /etc/neutron/neutron.conf designate allow_reverse_dns_lookup True
+ crudini --set /etc/neutron/neutron.conf designate ipv4_ptr_zone_prefix_size 24
+ crudini --set /etc/neutron/neutron.conf designate ipv6_ptr_zone_prefix_size 116
+ crudini --set /etc/neutron/neutron.conf designate project_domain_name default
+ crudini --set /etc/neutron/neutron.conf designate user_domain_name default
+ crudini --set /etc/neutron/neutron.conf designate auth_type password
+ crudini --set /etc/neutron/neutron.conf designate project_name service
+ crudini --set /etc/neutron/neutron.conf designate username designate
+ crudini --set /etc/neutron/neutron.conf designate password 2002dfe5f7494556215a
+ crudini --set /etc/neutron/neutron.conf designate region_name RegionOne
+ crudini --set /etc/neutron/neutron.conf designate memcached_servers controller:11211
+ crudini --set /etc/neutron/neutron.conf designate insecure True
+ service_restart neutron-server
+ service=neutron-server
+ [ 1 -eq 0 ]
+ systemctl restart neutron-server
+ echo DESIGNATE_DBPASS="3d456060389042ecbd48"
+ echo DESIGNATE_PASS="2002dfe5f7494556215a"
+ logtend designate
+ area=designate
+ echo designate
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=designate
+ date +%s
+ stamp=1557519887
+ date
+ date=Fri May 10 14:24:47 MDT 2019
+ eval tss=$LOGTIMESTART_designate
+ tss=1557519848
+ expr 1557519887 - 1557519848
+ tsres=39
+ perl -e print 39 / 60.0 . "\n"
+ resmin=0.65
+ echo END designate 1557519887 Fri May 10 14:24:47 MDT 2019
+ echo TOTAL designate 39 0.65
+ [ 18 -ge 18 -a -z  ]
+ logtstart magnum
+ area=magnum
+ echo magnum
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=magnum
+ date +%s
+ stamp=1557519887
+ date
+ date=Fri May 10 14:24:47 MDT 2019
+ eval LOGTIMESTART_magnum=1557519887
+ LOGTIMESTART_magnum=1557519887
+ echo START magnum 1557519887 Fri May 10 14:24:47 MDT 2019
+ openssl rand -hex 10
+ MAGNUM_DBPASS=cce16924b9bfc0aa57a2
+ openssl rand -hex 10
+ MAGNUM_PASS=28694c367e44bbbe00c4
+ + mysql -u root --password=ad12065d4a6fcf049d20
echo create database magnum
+ + mysql -u root --password=ad12065d4a6fcf049d20
echo grant all privileges on magnum.* to 'magnum'@'localhost' identified by 'cce16924b9bfc0aa57a2'
+ + mysql -u root --password=ad12065d4a6fcf049d20
echo grant all privileges on magnum.* to 'magnum'@'%' identified by 'cce16924b9bfc0aa57a2'
+ __openstack user create --domain default --password 28694c367e44bbbe00c4 magnum
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain default --password 28694c367e44bbbe00c4 magnum
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | a0bce07342314b118ebf8e33e1eeb2df |
| enabled             | True                             |
| id                  | 53620e8e19e04f778716dcde53026669 |
| name                | magnum                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --user magnum --project service admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --user magnum --project service admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack service create --name magnum --description OpenStack Container Infrastructure Management Service container-infra
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack service create --name magnum --description OpenStack Container Infrastructure Management Service container-infra
+-------------+-------------------------------------------------------+
| Field       | Value                                                 |
+-------------+-------------------------------------------------------+
| description | OpenStack Container Infrastructure Management Service |
| enabled     | True                                                  |
| id          | 5023b2c8e5f744b294b18a7e7eee00f3                      |
| name        | magnum                                                |
| type        | container-infra                                       |
+-------------+-------------------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ [ 3 -lt 3 ]
+ __openstack endpoint create --region RegionOne container-infra public http://controller:9511/v1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne container-infra public http://controller:9511/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 688576d2be404c8cbea8e266406fa5b1 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 5023b2c8e5f744b294b18a7e7eee00f3 |
| service_name | magnum                           |
| service_type | container-infra                  |
| url          | http://controller:9511/v1        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne container-infra internal http://controller:9511/v1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne container-infra internal http://controller:9511/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | eae63fb8cfdc4ab1a1dda41e5f5fa884 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 5023b2c8e5f744b294b18a7e7eee00f3 |
| service_name | magnum                           |
| service_type | container-infra                  |
| url          | http://controller:9511/v1        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack endpoint create --region RegionOne container-infra admin http://controller:9511/v1
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack endpoint create --region RegionOne container-infra admin http://controller:9511/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | d731db8a96744fc8a74627b8d5a3b977 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 5023b2c8e5f744b294b18a7e7eee00f3 |
| service_name | magnum                           |
| service_type | container-infra                  |
| url          | http://controller:9511/v1        |
+--------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ MAGNUM_DOMAIN_NAME=magnum
+ openssl rand -hex 10
+ MAGNUM_DOMADMIN_PASS=124867e73b9dd9809a8b
+ MAGNUM_DOMADMIN_USER=magnum_domain_admin
+ __openstack domain create --description Owns users and projects created by magnum magnum
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack domain create --description Owns users and projects created by magnum magnum
+-------------+-------------------------------------------+
| Field       | Value                                     |
+-------------+-------------------------------------------+
| description | Owns users and projects created by magnum |
| enabled     | True                                      |
| id          | 16b35421f70e44c6b7dee7792d2d2481          |
| name        | magnum                                    |
| tags        | []                                        |
+-------------+-------------------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack user create --domain magnum --password 124867e73b9dd9809a8b magnum_domain_admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack user create --domain magnum --password 124867e73b9dd9809a8b magnum_domain_admin
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | 16b35421f70e44c6b7dee7792d2d2481 |
| enabled             | True                             |
| id                  | 12f1f16538744bdeb5d46c6a963bdb31 |
| name                | magnum_domain_admin              |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ __openstack role add --domain magnum --user-domain magnum --user magnum_domain_admin admin
+ __err=1
+ __debug=
+ __times=0
+ [ 0 -lt 16 -a ! 1 -eq 0 ]
+ openstack role add --domain magnum --user-domain magnum --user magnum_domain_admin admin
+ __err=0
+ [ 0 -eq 0 ]
+ break
+ maybe_install_packages magnum-api magnum-conductor python-magnumclient
+ [ ! 0 -eq 0 ]
+ are_packages_installed magnum-api magnum-conductor python-magnumclient
+ retval=1
+ [ ! -z magnum-api ]
+ dpkg -s magnum-api
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z magnum-conductor ]
+ dpkg -s magnum-conductor
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z python-magnumclient ]
+ dpkg -s python-magnumclient
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ crudini --set /etc/magnum/magnum.conf api host 192.168.0.1
+ crudini --set /etc/magnum/magnum.conf certificates cert_manager_type x509keypair
+ crudini --set /etc/magnum/magnum.conf cinder_client region_name RegionOne
+ crudini --set /etc/magnum/magnum.conf database connection mysql+pymysql://magnum:cce16924b9bfc0aa57a2@controller/magnum
+ crudini --set /etc/magnum/magnum.conf DEFAULT verbose False
+ crudini --set /etc/magnum/magnum.conf DEFAULT debug False
+ crudini --set /etc/magnum/magnum.conf oslo_messaging_notifications driver messaging
+ crudini --set /etc/magnum/magnum.conf DEFAULT transport_url rabbit://openstack:0375d10f3c80e2774768@controller
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken memcached_servers controller:11211
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken auth_version v3
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken auth_uri http://controller:5000/v3
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken project_domain_name default
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken user_domain_name default
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken project_name service
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken username magnum
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken password 28694c367e44bbbe00c4
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken auth_url http://controller:5000
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken auth_type password
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken admin_user magnum
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken admin_password 28694c367e44bbbe00c4
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken admin_tenant_name service
+ crudini --set /etc/magnum/magnum.conf keystone_authtoken region_name RegionOne
+ crudini --set /etc/magnum/magnum.conf trust trustee_domain_name magnum
+ crudini --set /etc/magnum/magnum.conf trust trustee_domain_admin_name magnum_domain_admin
+ crudini --set /etc/magnum/magnum.conf trust trustee_domain_admin_password 124867e73b9dd9809a8b
+ crudini --set /etc/magnum/magnum.conf trust trustee_keystone_interface public
+ su -s /bin/sh -c magnum-db-manage upgrade magnum
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 2581ebaf0cb2, initial migration
INFO  [alembic.runtime.migration] Running upgrade 2581ebaf0cb2 -> 3bea56f25597, Multi Tenant Support
INFO  [alembic.runtime.migration] Running upgrade 3bea56f25597 -> 5793cd26898d, Add bay status
INFO  [alembic.runtime.migration] Running upgrade 5793cd26898d -> 3a938526b35d, Add docker volume size column
INFO  [alembic.runtime.migration] Running upgrade 3a938526b35d -> 35cff7c86221, add private network to baymodel
INFO  [alembic.runtime.migration] Running upgrade 35cff7c86221 -> 1afee1db6cd0, Add master flavor
INFO  [alembic.runtime.migration] Running upgrade 1afee1db6cd0 -> 2d1354bbf76e, ssh authorized key
INFO  [alembic.runtime.migration] Running upgrade 2d1354bbf76e -> 29affeaa2bc2, rename-bay-master-address
INFO  [alembic.runtime.migration] Running upgrade 29affeaa2bc2 -> 2ace4006498, rename-bay-minions-address
INFO  [alembic.runtime.migration] Running upgrade 2ace4006498 -> 456126c6c9e9, create baylock table
INFO  [alembic.runtime.migration] Running upgrade 456126c6c9e9 -> 4ea34a59a64c, add-discovery-url-to-bay
INFO  [alembic.runtime.migration] Running upgrade 4ea34a59a64c -> e772b2598d9, add-container-command
INFO  [alembic.runtime.migration] Running upgrade e772b2598d9 -> 2d8657c0cdc, add bay uuid
INFO  [alembic.runtime.migration] Running upgrade 2d8657c0cdc -> 4956f03cabad, add cluster distro
INFO  [alembic.runtime.migration] Running upgrade 4956f03cabad -> 592131657ca1, Add coe column to BayModel
INFO  [alembic.runtime.migration] Running upgrade 592131657ca1 -> 3b6c4c42adb4, Add unique constraints
INFO  [alembic.runtime.migration] Running upgrade 3b6c4c42adb4 -> 2b5f24dd95de, rename service port
INFO  [alembic.runtime.migration] Running upgrade 2b5f24dd95de -> 59e7664a8ba1, add_container_status
INFO  [alembic.runtime.migration] Running upgrade 59e7664a8ba1 -> 156ceb17fb0a, add_bay_status_reason
INFO  [alembic.runtime.migration] Running upgrade 156ceb17fb0a -> 1c1ff5e56048, rename_container_image_id
INFO  [alembic.runtime.migration] Running upgrade 1c1ff5e56048 -> 53882537ac57, add host column to pod
INFO  [alembic.runtime.migration] Running upgrade 53882537ac57 -> 14328d6a57e3, add master count to bay
INFO  [alembic.runtime.migration] Running upgrade 14328d6a57e3 -> 421102d1f2d2, create x509keypair table
INFO  [alembic.runtime.migration] Running upgrade 421102d1f2d2 -> 6f21dc998bb, Add master_addresses to bay
INFO  [alembic.runtime.migration] Running upgrade 6f21dc998bb -> 966a99e70ff, add-proxy
INFO  [alembic.runtime.migration] Running upgrade 966a99e70ff -> 6f21dc920bb, Add cert_uuuid to bay
INFO  [alembic.runtime.migration] Running upgrade 6f21dc920bb -> 5518af8dbc21, Rename cert_uuid
INFO  [alembic.runtime.migration] Running upgrade 5518af8dbc21 -> 4e263f236334, Add registry_enabled
INFO  [alembic.runtime.migration] Running upgrade 4e263f236334 -> 3be65537a94a, add_network_driver_baymodel_column
INFO  [alembic.runtime.migration] Running upgrade 3be65537a94a -> 1481f5b560dd, add labels column to baymodel table
INFO  [alembic.runtime.migration] Running upgrade 1481f5b560dd -> 1d045384b966, add-insecure-baymodel-attr
INFO  [alembic.runtime.migration] Running upgrade 1d045384b966 -> 27ad304554e2, adding magnum_service functionality
INFO  [alembic.runtime.migration] Running upgrade 27ad304554e2 -> 5ad410481b88, rename-insecure
INFO  [alembic.runtime.migration] Running upgrade 5ad410481b88 -> 2ae93c9c6191, add public column to baymodel table
INFO  [alembic.runtime.migration] Running upgrade 2ae93c9c6191 -> 33ef79969018, Add memory to container
INFO  [alembic.runtime.migration] Running upgrade 33ef79969018 -> 417917e778f5, Add server_type column to baymodel
INFO  [alembic.runtime.migration] Running upgrade 417917e778f5 -> 5977879072a7, add-env-to-container
INFO  [alembic.runtime.migration] Running upgrade 5977879072a7 -> 40f325033343, add bay_create_timeout to bay
INFO  [alembic.runtime.migration] Running upgrade 40f325033343 -> adc3b7679ae, add registry_trust_id to bay
INFO  [alembic.runtime.migration] Running upgrade adc3b7679ae -> 57fbdf2327a2, remove baylock
INFO  [alembic.runtime.migration] Running upgrade 57fbdf2327a2 -> 05d3e97de9ee, add volume driver
INFO  [alembic.runtime.migration] Running upgrade 05d3e97de9ee -> bb42b7cad130, remove node object
INFO  [alembic.runtime.migration] Running upgrade bb42b7cad130 -> 5d4caa6e0a42, create trustee for each bay
INFO  [alembic.runtime.migration] Running upgrade 5d4caa6e0a42 -> ee92b41b8809, Introduce Quotas
INFO  [alembic.runtime.migration] Running upgrade ee92b41b8809 -> 049f81f6f584, remove_ssh_authorized_key_from_baymodel
INFO  [alembic.runtime.migration] Running upgrade 049f81f6f584 -> e647f5931da8, add insecure_registry to baymodel
INFO  [alembic.runtime.migration] Running upgrade e647f5931da8 -> ef08a5e057bd, remove pod object
INFO  [alembic.runtime.migration] Running upgrade ef08a5e057bd -> d072f58ab240, modify x509keypair table
INFO  [alembic.runtime.migration] Running upgrade d072f58ab240 -> a1136d335540, Add docker storage driver column
INFO  [alembic.runtime.migration] Running upgrade a1136d335540 -> 085e601a39f6, remove service object
INFO  [alembic.runtime.migration] Running upgrade 085e601a39f6 -> 68ce16dfd341, add master_lb_enabled column to baymodel table
INFO  [alembic.runtime.migration] Running upgrade 68ce16dfd341 -> e0653b2d5271, Add fixed_subnet column to baymodel table
INFO  [alembic.runtime.migration] Running upgrade e0653b2d5271 -> 1f196a3dabae, remove container object
INFO  [alembic.runtime.migration] Running upgrade 1f196a3dabae -> 859fb45df249, remove replication controller
INFO  [alembic.runtime.migration] Running upgrade 859fb45df249 -> b1f612248cab, Add floating_ip_enabled column to baymodel table
INFO  [alembic.runtime.migration] Running upgrade b1f612248cab -> fcb4efee8f8b, add version info to bay
INFO  [alembic.runtime.migration] Running upgrade fcb4efee8f8b -> fb03fdef8919, rename_baymodel_to_clustertemplate
INFO  [alembic.runtime.migration] Running upgrade fb03fdef8919 -> 720f640f43d1, rename bay table to cluster
INFO  [alembic.runtime.migration] Running upgrade 720f640f43d1 -> bc46ba6cf949, add keypair to cluster
INFO  [alembic.runtime.migration] Running upgrade bc46ba6cf949 -> aa0cc27839af, add docker_volume_size to cluster
INFO  [alembic.runtime.migration] Running upgrade aa0cc27839af -> a0e7c8450ab1, add labels to cluster
INFO  [alembic.runtime.migration] Running upgrade a0e7c8450ab1 -> 52bcaf58fecb, add master_flavor_id to cluster
INFO  [alembic.runtime.migration] Running upgrade 52bcaf58fecb -> 04c625aa95ba, change storage driver to string
INFO  [alembic.runtime.migration] Running upgrade 04c625aa95ba -> 041d9a0f1159, add flavor_id to cluster
INFO  [alembic.runtime.migration] Running upgrade 041d9a0f1159 -> 9a1539f1cd2c, "add federation table
+ service_restart magnum-api
+ service=magnum-api
+ [ 1 -eq 0 ]
+ systemctl restart magnum-api
+ service_enable magnum-api
+ service=magnum-api
+ [ 1 -eq 0 ]
+ systemctl enable magnum-api
Synchronizing state of magnum-api.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable magnum-api
+ service_restart magnum-conductor
+ service=magnum-conductor
+ [ 1 -eq 0 ]
+ systemctl restart magnum-conductor
+ service_enable magnum-conductor
+ service=magnum-conductor
+ [ 1 -eq 0 ]
+ systemctl enable magnum-conductor
Synchronizing state of magnum-conductor.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable magnum-conductor
+ rm -f /var/lib/magnum/magnum.sqlite
+ echo MAGNUM_DBPASS="cce16924b9bfc0aa57a2"
+ echo MAGNUM_PASS="28694c367e44bbbe00c4"
+ echo MAGNUM_DOMAIN_NAME="magnum"
+ echo MAGNUM_DOMADMIN_USER="magnum_domain_admin"
+ echo MAGNUM_DOMADMIN_PASS="124867e73b9dd9809a8b"
+ logtend magnum
+ area=magnum
+ echo magnum
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=magnum
+ date +%s
+ stamp=1557519932
+ date
+ date=Fri May 10 14:25:32 MDT 2019
+ eval tss=$LOGTIMESTART_magnum
+ tss=1557519887
+ expr 1557519932 - 1557519887
+ tsres=45
+ perl -e print 45 / 60.0 . "\n"
+ resmin=0.75
+ echo END magnum 1557519932 Fri May 10 14:25:32 MDT 2019
+ echo TOTAL magnum 45 0.75
+ [ -z  ]
+ /local/repository/setup-basic.sh
+ dirname /local/repository/setup-basic.sh
+ DIRNAME=/local/repository
+ [ -ne 0 ]
/local/repository/setup-basic.sh: 12: [: -ne: unexpected operator
+ . /local/repository/setup-lib.sh
+ dirname /local/repository/setup-basic.sh
+ DIRNAME=/local/repository
+ OURDIR=/root/setup
+ SETTINGS=/root/setup/settings
+ LOCALSETTINGS=/root/setup/settings.local
+ TOPOMAP=/root/setup/topomap
+ BOOTDIR=/var/emulab/boot
+ TMCC=/usr/local/etc/emulab/tmcc
+ TIMELOGFILE=/root/setup/setup-time.log
+ FIRSTTIME=0
+ [ ! -f /root/setup/setup-lib-first ]
+ [ 0 -ne 0 ]
+ mkdir -p /root/setup
+ touch /root/setup/settings
+ touch /root/setup/settings.local
+ cd /root/setup
+ LOCKFILE=lockfile-create --retry 65535 
+ RMLOCKFILE=lockfile-remove 
+ PSWDGEN=openssl rand -hex 10
+ SSH=ssh -o StrictHostKeyChecking=no
+ SCP=scp -p -o StrictHostKeyChecking=no
+ CONTROLLER=ctl
+ NETWORKMANAGER=nm
+ STORAGEHOST=ctl
+ SHAREHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=
+ BAREMETALNODES=
+ BLOCKNODES=
+ OBJECTNODES=
+ DATALAN=lan-1
+ MGMTLAN=lan-2
+ BLOCKLAN=
+ OBJECTLAN=
+ DATATUNNELS=1
+ DATAFLATLANS=lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATAOTHERLANS=
+ USE_EXISTING_IPS=1
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=0
+ DO_APT_UPDATE=1
+ UBUNTUMIRRORHOST=
+ UBUNTUMIRRORPATH=
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DO_UBUNTU_CLOUDARCHIVE=0
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ BUILD_AARCH64_FROM_CORE=0
+ DISABLE_SECURITY_GROUPS=0
+ ENABLE_HOST_PASSTHROUGH=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ SUPPORT_DYNAMIC_NODES=0
+ KEYSTONEAPIVERSION=
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ GLANCE_LV_SIZE=32
+ SWIFT_LV_SIZE=4
+ CEILOMETER_USE_WSGI=0
+ QUOTASOFF=1
+ KEYSTONEUSEMEMCACHE=0
+ KEYSTONEUSEWSGI=
+ COMPUTE_EXTRA_NOVA_DISK_SPACE=1
+ ML2PLUGIN=openvswitch
+ MANILADRIVER=generic
+ EXTRAIMAGEURLS=
+ LINUXBRIDGE_STATIC=0
+ USE_DESIGNATE_AS_RESOLVER=1
+ USE_NEUTRON_LBAAS=1
+ ENABLE_OPENSTACK_SLOTHD=0
+ OSRELEASE=
+ ADMIN_API=adminapi
+ openssl rand -hex 10
+ ADMIN_API_PASS=78cbabf0cdbe2e8e2279
+ ADMIN=admin
+ ADMIN_PASS=
+ ADMIN_PASS_HASH=
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ [ x = x ]
+ UPDATING=0
+ NEWNODELIST=
+ OLDNODELIST=
+ [ ! -e /root/setup/apt-configured ]
+ export DEBIAN_FRONTEND=noninteractive
+ DPKGOPTS=
+ APTGETINSTALLOPTS=-y
+ APTGETINSTALL=apt-get  install -y
+ [ 1 -eq 0 ]
+ grep GENIUSER /root/setup/settings
GENIUSER=1
+ [ ! 0 -eq 0 ]
+ grep GENIUSER=1 /root/setup/settings
GENIUSER=1
+ [ 0 -eq 0 ]
+ GENIUSER=1
+ [ 1 -eq 1 ]
+ dpkg -s python-m2crypto
+ [ ! 0 -eq 0 ]
+ [ ! -e /root/setup/geni.key ]
+ HAS_GENI_KEY=1
+ [ ! -e /root/setup/geni.certificate ]
+ HAS_GENI_CERT=1
+ [ ! -e /root/.ssl/encrypted.pem ]
+ [ ! -e /root/setup/manifests.xml -o 0 -ne 0 ]
+ [ ! -e /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/decrypted_admin_pass -a -s /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/parameters ]
+ . /root/setup/parameters
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ COMPUTENODES=compute-1 
+ DATALANS=flat-lan-1
+ DATAFLATLANS=flat-lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATATUNNELS=1
+ MGMTLAN=
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=1
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ DO_APT_UPDATE=1
+ ADMIN_PASS_HASH=
+ ENABLE_HOST_PASSTHROUGH=1
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DISABLE_SECURITY_GROUPS=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ USE_NEUTRON_LBAAS=1
+ CEILOMETER_USE_MONGODB=0
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ KEYSTONEUSEMEMCACHE=0
+ QUOTASOFF=1
+ ML2PLUGIN=openvswitch
+ USE_DESIGNATE_AS_RESOLVER=1
+ EXTRAIMAGEURLS=
+ OSRELEASE=rocky
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ ADMIN_PASS=9da6fece4881
+ ADMIN_PASS_HASH=$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA.
+ [ x$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA. = x ]
+ cat /var/emulab/boot/creator
+ CREATOR=tboudw0
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ + cat /var/emulab/boot/nickname
cut -d . -f 1
+ NODEID=controller
+ cat /var/emulab/boot/nodeid
+ PNODEID=clnode234
+ cat /var/emulab/boot/nickname
+ cut -d . -f 2
+ EEID=tboudwin-QV52139
+ cat /var/emulab/boot/nickname
+ cut -d . -f 3
+ EPID=pdc-edu-lab-PG0
+ cat /var/emulab/boot/mydomain
+ OURDOMAIN=clemson.cloudlab.us
+ cat /var/emulab/boot/nickname
+ NFQDN=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ cat /var/emulab/boot/nodeid
+ PFQDN=clnode234.clemson.cloudlab.us
+ cat /var/emulab/boot/myip
+ MYIP=130.127.133.243
+ cat /var/emulab/boot/controlif
+ EXTERNAL_NETWORK_INTERFACE=br-ex
+ cat /var/emulab/boot/nickname
+ cut -f1 -d.
+ HOSTNAME=controller
+ uname -m
+ ARCH=x86_64
+ dpkg-query -S /sbin/init
+ grep -q systemd
+ expr 0 = 0
+ HAVE_SYSTEMD=1
+ OSJUNO=10
+ OSKILO=11
+ OSLIBERTY=12
+ OSMITAKA=13
+ OSNEWTON=14
+ OSOCATA=15
+ OSPIKE=16
+ OSQUEENS=17
+ OSROCKY=18
+ . /etc/lsb-release
+ DISTRIB_ID=Ubuntu
+ DISTRIB_RELEASE=18.04
+ DISTRIB_CODENAME=bionic
+ DISTRIB_DESCRIPTION=Ubuntu 18.04.2 LTS
+ [ ! xrocky = x ]
+ OSCODENAME=rocky
+ [ rocky = juno ]
+ [ rocky = kilo ]
+ [ rocky = liberty ]
+ [ rocky = mitaka ]
+ [ rocky = newton ]
+ [ rocky = ocata ]
+ [ rocky = pike ]
+ [ rocky = queens ]
+ [ rocky = rocky ]
+ OSVERSION=18
+ echo Ubuntu 18.04.2 LTS
+ grep -qi LTS
+ [ 0 -eq 0 ]
+ DO_UBUNTU_CLOUDARCHIVE=1
+ echo 18.04
+ cut -d. -f1
+ DISTRIB_MAJOR=18
+ [ 18 -ge 13 ]
+ KEYSTONEUSEMEMCACHE=1
+ [ 18 -eq 10 ]
+ REGION=RegionOne
+ [ 18 -ge 17 ]
+ KADMINPORT=5000
+ [ x = x3 ]
+ [  != 2 -a 18 -ge 12 ]
+ KAPISTR=v3
+ KEYSTONEAPIVERSION=3
+ NAPISTR=v2
+ [ 18 -ge 13 ]
+ NAPISTR=v2.1
+ [ x = x -a 18 -ge 11 ]
+ KEYSTONEUSEWSGI=1
+ [ 18 -ge 13 ]
+ PROJECT_DOMAIN_PARAM=project_domain_name
+ USER_DOMAIN_PARAM=user_domain_name
+ AUTH_TYPE_PARAM=auth_type
+ [ 18 -ge 14 ]
+ DBDPACKAGE=python-pymysql
+ DBDSTRING=mysql+pymysql
+ [ 1 -eq 1 ]
+ geni-get slice_email
+ SWAPPER_EMAIL=tboudwin@wcupa.edu
+ [ 1 -eq 1 ]
+ + perl -ecat $found = 0; while (<STDIN>) { if ($_ =~ /\<[\d\w:]*routable_pool [^\>\<]*\/>/) { print STDERR "DEBUG: found empty pool: $_\n"; next; } if ($_ =~ /\<[\d\w:]*routable_pool [^\>]*client_id=['"]controller['"]/) { $found = 1; print STDERR "DEBUG: found: $_\n" } if ($found) { while ($_ =~ m/\<emulab:ipv4 address="([\d.]+)\" netmask=\"([\d\.]+)\"/g) { print "$1\n"; } } if ($found && $_ =~ /routable_pool\>/) { print STDERR "DEBUG: end found: $_\n"; $found = 0; } } /root/setup/manifests.0.xml

+ xargs
DEBUG: found:   <emulab:routable_pool client_id="controller" count="4" type="any" component_manager_id="urn:publicid:IDN+clemson.cloudlab.us+authority+cm">

DEBUG: end found:   <emulab:ipv4 address="130.127.132.210" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.226" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.238" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.239" netmask="255.255.252.0"/></emulab:routable_pool>

+ PUBLICADDRS=130.127.132.210 130.127.132.226 130.127.132.238 130.127.132.239
+ PUBLICCOUNT=0
+ expr 0 + 1
+ PUBLICCOUNT=1
+ expr 1 + 1
+ PUBLICCOUNT=2
+ expr 2 + 1
+ PUBLICCOUNT=3
+ expr 3 + 1
+ PUBLICCOUNT=4
+ [ ! -f /root/setup/topomap -o 0 -ne 0 ]
+ [ ! -z  ]
+ [ ( -s /root/setup/manifests.xml ) -a ( ! ( -s /root/setup/fqdn.map ) ) ]
+ [ ! -s /root/setup/fqdn.map ]
+ cat /root/setup/fqdn.map
+ + cut -f1
xargs
+ NODES=controller compute-1
+ + cat /root/setup/fqdn.map
cut -f2
+ xargs
+ FQDNS=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ [ -z compute-1  ]
+ OTHERNODES=
+ [ controller = controller ]
+ continue
+ [ compute-1 = controller ]
+ OTHERNODES= compute-1
+ grep CONTROLLER /root/setup/settings
CONTROLLER="controller"
+ [ ! 0 = 0 ]
+ [ 0 -ne 0 ]
+ grep MIRRORSETUP /root/setup/settings
MIRRORSETUP=1
+ [ ! 0 -eq 0 ]
+ [ ! -f /root/setup/apt-updated -a 1 = 1 ]
+ [ ! -f /root/setup/cloudarchive-added -a 1 = 1 ]
+ [ ! -f /root/setup/apt-dist-upgraded -a 1 = 1 ]
+ maybe_install_packages crudini
+ [ ! 0 -eq 0 ]
+ are_packages_installed crudini
+ retval=1
+ [ ! -z crudini ]
+ dpkg -s crudini
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ ! -f /root/setup/nextsparesubnet ]
+ cat /root/setup/nextsparesubnet
+ NEXTSPARESUBNET=253
+ [ ! -f /root/setup/mgmt-hosts -o 0 -ne 0 ]
+ [ 1 -gt 0 ]
+ i=0
+ [ 0 -lt 1 ]
+ [ -f /root/setup/ipinfo.tun0 ]
+ expr 0 + 1
+ i=1
+ continue
+ [ 1 -lt 1 ]
+ echo 253
+ echo 253
+ [ 0 -gt 0 ]
+ [ ! -e /root/setup/info.mgmt ]
+ . /root/setup/info.mgmt
+ MGMTIP=192.168.0.1
+ MGMTNETMASK=255.255.0.0
+ MGMTPREFIX=16
+ MGMTVLAN=0
+ MGMTMAC=
+ MGMT_NETWORK_INTERFACE=tun0
+ MGMTVLANDEV=
+ MGMTVLANTAG=
+ [ -e /root/setup/info.flat-lan-1 ]
+ continue
+ [ ! -f /root/setup/neutron.vars ]
+ [ ! -f /etc/emulab/bossnode -a 18 -ge 14 -a 1 = 1 ]
+ [ 0 -ne 0 ]
+ which wget
+ GETTER=/usr/bin/wget
+ [ -n /usr/bin/wget ]
+ GETTEROUT=/usr/bin/wget --remote-encoding=unix -c -O
+ GETTER=/usr/bin/wget --remote-encoding=unix -c -N
+ GETTERLOGARG=-o
+ [ 0 -ne 0 ]
+ [ controller != controller ]
+ logtstart basic
+ area=basic
+ echo basic
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=basic
+ date +%s
+ stamp=1557519932
+ date
+ date=Fri May 10 14:25:32 MDT 2019
+ eval LOGTIMESTART_basic=1557519932
+ LOGTIMESTART_basic=1557519932
+ echo START basic 1557519932 Fri May 10 14:25:32 MDT 2019
+ [ -f /root/setup/settings ]
+ . /root/setup/settings
+ GENIUSER=1
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ STORAGEHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=compute-1 
+ MIRRORSETUP=1
+ DB_ROOT_PASS=ad12065d4a6fcf049d20
+ RABBIT_USER=openstack
+ RABBIT_PASS=0375d10f3c80e2774768
+ RABBIT_URL=rabbit://openstack:0375d10f3c80e2774768@controller
+ MEMCACHE_DONE=1
+ ETCD_DONE=1
+ ADMIN_API=adminapi
+ ADMIN_API_PASS=92748256c1e798f84f04
+ KEYSTONE_DBPASS=475bd45587c7b7ebea74
+ GLANCE_DBPASS=90422ef6606c271c3df3
+ GLANCE_PASS=8730282cd9b68ed94645
+ NOVA_DBPASS=8f182a0cc87fc8fe28e1
+ PLACEMENT_DBPASS=183a130e6978d3eefbd9
+ NOVA_PASS=70f8743910a95e3a54fe
+ PLACEMENT_PASS=c650059292e41b9adf49
+ NOVA_COMPUTENODES_DONE=1
+ NEUTRON_DBPASS=afeb2f23fd61fc63b2f7
+ NEUTRON_PASS=398d7129a22f6c80b3c3
+ NEUTRON_METADATA_SECRET=e49934e1536e9d8ba189
+ NEUTRON_NETWORKMANAGER_DONE=1
+ NEUTRON_COMPUTENODES_DONE=1
+ NEUTRON_NETWORKS_DONE=1
+ DASHBOARD_DONE=1
+ CINDER_DBPASS=5a3b8b798010f2d95066
+ CINDER_PASS=f61e53efc351839e2af6
+ STORAGE_HOST_DONE=1
+ MANILA_DBPASS=b2bd23d86e44b7407596
+ MANILA_PASS=2eade20daad922a8057c
+ SHARE_HOST_DONE=1
+ SWIFT_PASS=c3a4899e89192a1e7eb8
+ SWIFT_HASH_PATH_PREFIX=d51684ed7c48c231579a
+ SWIFT_HASH_PATH_SUFFIX=86bb0f47011f3b72117b
+ OBJECT_HOST_DONE=1
+ OBJECT_RING_DONE=1
+ HEAT_DBPASS=fe168d03a3bd636abfd7
+ HEAT_PASS=74f093bf648a6352c634
+ HEAT_DOMAIN_PASS=2e1b2a1126234f3aff39
+ CEILOMETER_DBPASS=b907cdb748550b1172ef
+ CEILOMETER_PASS=8604e762e767b5756f34
+ CEILOMETER_SECRET=165eed9e2ad1fc410f41
+ USING_GNOCCHI=1
+ GNOCCHI_DBPASS=53e1f32cc25233b8f63e
+ GNOCCHI_PASS=fbc724e02dff5d3cae2a
+ TELEMETRY_GRAFANA_DONE=1
+ TELEMETRY_COMPUTENODES_DONE=1
+ TELEMETRY_GLANCE_DONE=1
+ TELEMETRY_CINDER_DONE=1
+ TELEMETRY_SWIFT_DONE=1
+ TELEMETRY_HEAT_DONE=1
+ TROVE_DBPASS=69d72a7dd02aa8d0f960
+ TROVE_PASS=95dda9ed60ab31c9e2ae
+ SAHARA_DBPASS=5bbc4b86d0e78513a855
+ SAHARA_PASS=3061a6bc4d5eb38ddf58
+ DESIGNATE_DBPASS=3d456060389042ecbd48
+ DESIGNATE_PASS=2002dfe5f7494556215a
+ MAGNUM_DBPASS=cce16924b9bfc0aa57a2
+ MAGNUM_PASS=28694c367e44bbbe00c4
+ MAGNUM_DOMAIN_NAME=magnum
+ MAGNUM_DOMADMIN_USER=magnum_domain_admin
+ MAGNUM_DOMADMIN_PASS=124867e73b9dd9809a8b
+ . /root/setup/admin-openrc.sh
+ export OS_PROJECT_DOMAIN_NAME=default
+ export OS_USER_DOMAIN_NAME=default
+ export OS_PROJECT_NAME=admin
+ export OS_TENANT_NAME=admin
+ export OS_USERNAME=adminapi
+ export OS_PASSWORD=92748256c1e798f84f04
+ export OS_AUTH_URL=http://controller:5000/v3
+ export OS_IDENTITY_API_VERSION=3
+ export OS_IMAGE_API_VERSION=2
+ export OS_AUTH_TYPE=password
+ echo *** Backgrounding quota setup...
*** Backgrounding quota setup...
+ quotaspid=10439
+ echo *** Backgrounding network setup...
*** Backgrounding network setup...
+ networkspid=10440
+ echo *** Backgrounding user setup...
*** Backgrounding user setup...
+ /local/repository/setup-basic-quotas.sh
+ /local/repository/setup-basic-networks.sh
+ userspid=10441
+ . /local/repository/setup-images-lib.sh
+ /local/repository/setup-basic-users.sh
+ dirname /local/repository/setup-basic.sh
+ DIRNAME=/local/repository
+ id -u
+ [ 0 -ne 0 ]
+ . /local/repository/setup-lib.sh
+ dirname /local/repository/setup-basic.sh
+ DIRNAME=/local/repository
+ OURDIR=/root/setup
+ SETTINGS=/root/setup/settings
+ LOCALSETTINGS=/root/setup/settings.local
+ TOPOMAP=/root/setup/topomap
+ BOOTDIR=/var/emulab/boot
+ TMCC=/usr/local/etc/emulab/tmcc
+ TIMELOGFILE=/root/setup/setup-time.log
+ FIRSTTIME=0
+ [ ! -f /root/setup/setup-lib-first ]
+ [ 0 -ne 0 ]
+ mkdir -p /root/setup
+ touch /root/setup/settings
+ touch /root/setup/settings.local
+ cd /root/setup
+ LOCKFILE=lockfile-create --retry 65535 
+ RMLOCKFILE=lockfile-remove 
+ PSWDGEN=openssl rand -hex 10
+ SSH=ssh -o StrictHostKeyChecking=no
+ SCP=scp -p -o StrictHostKeyChecking=no
+ CONTROLLER=ctl
+ NETWORKMANAGER=nm
+ STORAGEHOST=ctl
+ SHAREHOST=ctl
+ OBJECTHOST=ctl
+ COMPUTENODES=
+ BAREMETALNODES=
+ BLOCKNODES=
+ OBJECTNODES=
+ DATALAN=lan-1
+ MGMTLAN=lan-2
+ BLOCKLAN=
+ OBJECTLAN=
+ DATATUNNELS=1
+ DATAFLATLANS=lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATAOTHERLANS=
+ USE_EXISTING_IPS=1
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=0
+ DO_APT_UPDATE=1
+ UBUNTUMIRRORHOST=
+ UBUNTUMIRRORPATH=
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DO_UBUNTU_CLOUDARCHIVE=0
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ BUILD_AARCH64_FROM_CORE=0
+ DISABLE_SECURITY_GROUPS=0
+ ENABLE_HOST_PASSTHROUGH=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ SUPPORT_DYNAMIC_NODES=0
+ KEYSTONEAPIVERSION=
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ GLANCE_LV_SIZE=32
+ SWIFT_LV_SIZE=4
+ CEILOMETER_USE_WSGI=0
+ QUOTASOFF=1
+ KEYSTONEUSEMEMCACHE=0
+ KEYSTONEUSEWSGI=
+ COMPUTE_EXTRA_NOVA_DISK_SPACE=1
+ ML2PLUGIN=openvswitch
+ MANILADRIVER=generic
+ EXTRAIMAGEURLS=
+ LINUXBRIDGE_STATIC=0
+ USE_DESIGNATE_AS_RESOLVER=1
+ USE_NEUTRON_LBAAS=1
+ ENABLE_OPENSTACK_SLOTHD=0
+ OSRELEASE=
+ ADMIN_API=adminapi
+ openssl rand -hex 10
+ ADMIN_API_PASS=abed4b0e6acb0eb9e755
+ ADMIN=admin
+ ADMIN_PASS=
+ ADMIN_PASS_HASH=
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ [ x0 = x ]
+ [ ! 0 -eq 0 ]
+ NEWNODELIST=
+ OLDNODELIST=
+ [ ! -e /root/setup/apt-configured ]
+ export DEBIAN_FRONTEND=noninteractive
+ DPKGOPTS=
+ APTGETINSTALLOPTS=-y
+ APTGETINSTALL=apt-get  install -y
+ [ 1 -eq 0 ]
+ grep GENIUSER /root/setup/settings
GENIUSER=1
+ [ ! 0 -eq 0 ]
+ grep GENIUSER=1 /root/setup/settings
GENIUSER=1
+ [ 0 -eq 0 ]
+ GENIUSER=1
+ [ 1 -eq 1 ]
+ dpkg -s python-m2crypto
+ [ ! 0 -eq 0 ]
+ [ ! -e /root/setup/geni.key ]
+ HAS_GENI_KEY=1
+ [ ! -e /root/setup/geni.certificate ]
+ HAS_GENI_CERT=1
+ [ ! -e /root/.ssl/encrypted.pem ]
+ [ ! -e /root/setup/manifests.xml -o 0 -ne 0 ]
+ [ ! -e /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/decrypted_admin_pass -a -s /root/setup/encrypted_admin_pass ]
+ [ ! -e /root/setup/parameters ]
+ . /root/setup/parameters
+ CONTROLLER=controller
+ NETWORKMANAGER=controller
+ COMPUTENODES=compute-1 
+ DATALANS=flat-lan-1
+ DATAFLATLANS=flat-lan-1
+ DATAVLANS=
+ DATAVXLANS=0
+ DATATUNNELS=1
+ MGMTLAN=
+ DO_APT_INSTALL=1
+ DO_APT_UPGRADE=0
+ DO_APT_DIST_UPGRADE=1
+ DO_UBUNTU_CLOUDARCHIVE_STAGING=0
+ DO_APT_UPDATE=1
+ ADMIN_PASS_HASH=
+ ENABLE_HOST_PASSTHROUGH=1
+ ENABLE_NEW_SERIAL_SUPPORT=0
+ DISABLE_SECURITY_GROUPS=0
+ DEFAULT_SECGROUP_ENABLE_SSH_ICMP=1
+ USE_NEUTRON_LBAAS=1
+ CEILOMETER_USE_MONGODB=0
+ VERBOSE_LOGGING=False
+ DEBUG_LOGGING=False
+ TOKENTIMEOUT=14400
+ SESSIONTIMEOUT=14400
+ KEYSTONEUSEMEMCACHE=0
+ QUOTASOFF=1
+ ML2PLUGIN=openvswitch
+ USE_DESIGNATE_AS_RESOLVER=1
+ EXTRAIMAGEURLS=
+ OSRELEASE=rocky
+ SWIFT_LV_SIZE=4
+ GLANCE_LV_SIZE=32
+ ADMIN_PASS=9da6fece4881
+ ADMIN_PASS_HASH=$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA.
+ [ x$1$5vLvsUwf$ZX3uBiXcwBW3GmJOebSbA. = x ]
+ cat /var/emulab/boot/creator
+ CREATOR=tboudw0
+ cat /var/emulab/boot/swapper
+ SWAPPER=geniuser
+ cat /var/emulab/boot/nickname
+ cut -d . -f 1
+ NODEID=controller
+ cat /var/emulab/boot/nodeid
+ PNODEID=clnode234
+ cat /var/emulab/boot/nickname
+ cut -d . -f 2
+ EEID=tboudwin-QV52139
+ cat /var/emulab/boot/nickname
+ cut -d . -f 3
+ EPID=pdc-edu-lab-PG0
+ cat /var/emulab/boot/mydomain
+ OURDOMAIN=clemson.cloudlab.us
+ cat /var/emulab/boot/nickname
+ NFQDN=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ cat /var/emulab/boot/nodeid
+ PFQDN=clnode234.clemson.cloudlab.us
+ cat /var/emulab/boot/myip
+ MYIP=130.127.133.243
+ cat /var/emulab/boot/controlif
+ EXTERNAL_NETWORK_INTERFACE=br-ex
+ cat /var/emulab/boot/nickname
+ cut -f1 -d.
+ HOSTNAME=controller
+ uname -m
+ ARCH=x86_64
+ dpkg-query -S /sbin/init
+ grep -q systemd
+ expr 0 = 0
+ HAVE_SYSTEMD=1
+ OSJUNO=10
+ OSKILO=11
+ OSLIBERTY=12
+ OSMITAKA=13
+ OSNEWTON=14
+ OSOCATA=15
+ OSPIKE=16
+ OSQUEENS=17
+ OSROCKY=18
+ . /etc/lsb-release
+ DISTRIB_ID=Ubuntu
+ DISTRIB_RELEASE=18.04
+ DISTRIB_CODENAME=bionic
+ DISTRIB_DESCRIPTION=Ubuntu 18.04.2 LTS
+ [ ! xrocky = x ]
+ OSCODENAME=rocky
+ [ rocky = juno ]
+ [ rocky = kilo ]
+ [ rocky = liberty ]
+ [ rocky = mitaka ]
+ [ rocky = newton ]
+ [ rocky = ocata ]
+ [ rocky = pike ]
+ [ rocky = queens ]
+ [ rocky = rocky ]
+ OSVERSION=18
+ echo Ubuntu 18.04.2 LTS
+ grep -qi LTS
+ [ 0 -eq 0 ]
+ DO_UBUNTU_CLOUDARCHIVE=1
+ cut -d. -f1
+ echo 18.04
+ DISTRIB_MAJOR=18
+ [ 18 -ge 13 ]
+ KEYSTONEUSEMEMCACHE=1
+ [ 18 -eq 10 ]
+ REGION=RegionOne
+ [ 18 -ge 17 ]
+ KADMINPORT=5000
+ [ x = x3 ]
+ [  != 2 -a 18 -ge 12 ]
+ KAPISTR=v3
+ KEYSTONEAPIVERSION=3
+ NAPISTR=v2
+ [ 18 -ge 13 ]
+ NAPISTR=v2.1
+ [ x = x -a 18 -ge 11 ]
+ KEYSTONEUSEWSGI=1
+ [ 18 -ge 13 ]
+ PROJECT_DOMAIN_PARAM=project_domain_name
+ USER_DOMAIN_PARAM=user_domain_name
+ AUTH_TYPE_PARAM=auth_type
+ [ 18 -ge 14 ]
+ DBDPACKAGE=python-pymysql
+ DBDSTRING=mysql+pymysql
+ [ 1 -eq 1 ]
+ geni-get slice_email
+ SWAPPER_EMAIL=tboudwin@wcupa.edu
+ [ 1 -eq 1 ]
+ + perl -e $found = 0; while (<STDIN>) { if ($_ =~ /\<[\d\w:]*routable_pool [^\>\<]*\/>/) { print STDERR "DEBUG: found empty pool: $_\n"; next; } if ($_ =~ /\<[\d\w:]*routable_pool [^\>]*client_id=['"]controller['"]/) { $found = 1; print STDERR "DEBUG: found: $_\n" } if ($found) { while ($_ =~ m/\<emulab:ipv4 address="([\d.]+)\" netmask=\"([\d\.]+)\"/g) { print "$1\n"; } } if ($found && $_ =~ /routable_pool\>/) { print STDERR "DEBUG: end found: $_\n"; $found = 0; } }cat
 /root/setup/manifests.0.xml
+ xargs
DEBUG: found:   <emulab:routable_pool client_id="controller" count="4" type="any" component_manager_id="urn:publicid:IDN+clemson.cloudlab.us+authority+cm">

DEBUG: end found:   <emulab:ipv4 address="130.127.132.210" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.226" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.238" netmask="255.255.252.0"/><emulab:ipv4 address="130.127.132.239" netmask="255.255.252.0"/></emulab:routable_pool>

+ PUBLICADDRS=130.127.132.210 130.127.132.226 130.127.132.238 130.127.132.239
+ PUBLICCOUNT=0
+ expr 0 + 1
+ PUBLICCOUNT=1
+ expr 1 + 1
+ PUBLICCOUNT=2
+ expr 2 + 1
+ PUBLICCOUNT=3
+ expr 3 + 1
+ PUBLICCOUNT=4
+ [ ! -f /root/setup/topomap -o 0 -ne 0 ]
+ [ ! -z  ]
+ [ ( -s /root/setup/manifests.xml ) -a ( ! ( -s /root/setup/fqdn.map ) ) ]
+ [ ! -s /root/setup/fqdn.map ]
+ + cut -f1
cat /root/setup/fqdn.map
+ xargs
+ NODES=controller compute-1
+ cat /root/setup/fqdn.map
+ cut+  -f2
xargs
+ FQDNS=controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us compute-1.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us
+ [ -z compute-1  ]
+ OTHERNODES=
+ [ controller = controller ]
+ continue
+ [ compute-1 = controller ]
+ OTHERNODES= compute-1
+ grep CONTROLLER /root/setup/settings
CONTROLLER="controller"
+ [ ! 0 = 0 ]
+ [ 0 -ne 0 ]
+ grep MIRRORSETUP /root/setup/settings
MIRRORSETUP=1
+ [ ! 0 -eq 0 ]
+ [ ! -f /root/setup/apt-updated -a 1 = 1 ]
+ [ ! -f /root/setup/cloudarchive-added -a 1 = 1 ]
+ [ ! -f /root/setup/apt-dist-upgraded -a 1 = 1 ]
+ maybe_install_packages crudini
+ [ ! 0 -eq 0 ]
+ are_packages_installed crudini
+ retval=1
+ [ ! -z crudini ]
+ dpkg -s crudini
+ [ ! 0 -eq 0 ]
+ shift
+ [ ! -z  ]
+ return 1
+ [ 1 -eq 1 ]
+ return 0
+ [ ! -f /root/setup/nextsparesubnet ]
+ cat /root/setup/nextsparesubnet
+ NEXTSPARESUBNET=253
+ [ ! -f /root/setup/mgmt-hosts -o 0 -ne 0 ]
+ [ 1 -gt 0 ]
+ i=0
+ [ 0 -lt 1 ]
+ [ -f /root/setup/ipinfo.tun0 ]
+ expr 0 + 1
+ i=1
+ continue
+ [ 1 -lt 1 ]
+ echo 253
+ echo 253
+ [ 0 -gt 0 ]
+ [ ! -e /root/setup/info.mgmt ]
+ . /root/setup/info.mgmt
+ MGMTIP=192.168.0.1
+ MGMTNETMASK=255.255.0.0
+ MGMTPREFIX=16
+ MGMTVLAN=0
+ MGMTMAC=
+ MGMT_NETWORK_INTERFACE=tun0
+ MGMTVLANDEV=
+ MGMTVLANTAG=
+ [ -e /root/setup/info.flat-lan-1 ]
+ continue
+ [ ! -f /root/setup/neutron.vars ]
+ [ ! -f /etc/emulab/bossnode -a 18 -ge 14 -a 1 = 1 ]
+ [ 0 -ne 0 ]
+ which wget
+ GETTER=/usr/bin/wget
+ [ -n /usr/bin/wget ]
+ GETTEROUT=/usr/bin/wget --remote-encoding=unix -c -O
+ GETTER=/usr/bin/wget --remote-encoding=unix -c -N
+ GETTERLOGARG=-o
+ [ 0 -ne 0 ]
+ IMAGEDIR=/root/setup/images
+ [ ! -d /root/setup/images ]
+ IMAGESETUPLOCKFILE=/root/setup/images/image-setup-lockfile
+ IMAGEUPLOADCMDFILE=/root/setup/images/image-upload-commands.sh
+ uname -m
+ ARCH=x86_64
+ [ x86_64 = aarch64 ]
+ [ -f /local/repository/setup-images-lib-x86_64.sh ]
+ lockfile-create --retry 65535 /root/setup/images/image-setup-lockfile
+ [ -f /root/setup/images/image-upload-commands.sh ]
+ echo *** Adding Images ...
*** Adding Images ...
+ . /root/setup/admin-openrc.sh
+ export OS_PROJECT_DOMAIN_NAME=default
+ export OS_USER_DOMAIN_NAME=default
+ export OS_PROJECT_NAME=admin
+ export OS_TENANT_NAME=admin
+ export OS_USERNAME=adminapi
+ export OS_PASSWORD=92748256c1e798f84f04
+ export OS_AUTH_URL=http://controller:5000/v3
+ export OS_IDENTITY_API_VERSION=3
+ export OS_IMAGE_API_VERSION=2
+ export OS_AUTH_TYPE=password
+ . /root/setup/images/image-upload-commands.sh
+ glance image-create --name xenial-server --disk-format qcow2 --container-format bare --progress --file /root/setup/images/xenial-server-cloudimg-amd64-disk1.img
+------------------+----------------------------------------------------------------------------------+
| Property         | Value                                                                            |
+------------------+----------------------------------------------------------------------------------+
| checksum         | f34de62778d91565c1e98dacf9e0a72c                                                 |
| container_format | bare                                                                             |
| created_at       | 2019-05-10T20:25:33Z                                                             |
| disk_format      | qcow2                                                                            |
| id               | eb612e6e-360e-48f5-8790-5dbbbd4fb3ed                                             |
| min_disk         | 0                                                                                |
| min_ram          | 0                                                                                |
| name             | xenial-server                                                                    |
| os_hash_algo     | sha512                                                                           |
| os_hash_value    | 959d5098c507299dc5024654cc525b97561920a8e947cd13e6df2a69781f1469a953bb4bea72d012 |
|                  | 8870e4592d25e6eca3cfe574b2252d72945f7471fdcdc51d                                 |
| os_hidden        | False                                                                            |
| owner            | c71f3ce86c4e437abf2407f488c55054                                                 |
| protected        | False                                                                            |
| size             | 299565056                                                                        |
| status           | active                                                                           |
| tags             | []                                                                               |
| updated_at       | 2019-05-10T20:25:35Z                                                             |
| virtual_size     | None                                                                             |
| visibility       | shared                                                                           |
+------------------+----------------------------------------------------------------------------------+
+ glance image-create --name manila-service-image --disk-format qcow2 --container-format bare --progress --file /root/setup/images/manila-service-image-master.qcow2
+------------------+----------------------------------------------------------------------------------+
| Property         | Value                                                                            |
+------------------+----------------------------------------------------------------------------------+
| checksum         | ed3afa5f195cb301a33692733ca1784e                                                 |
| container_format | bare                                                                             |
| created_at       | 2019-05-10T20:25:36Z                                                             |
| disk_format      | qcow2                                                                            |
| id               | 61ee22ad-d68e-4ab7-a1f7-37a129658aa2                                             |
| min_disk         | 0                                                                                |
| min_ram          | 0                                                                                |
| name             | manila-service-image                                                             |
| os_hash_algo     | sha512                                                                           |
| os_hash_value    | f0d92b498394eb15629de56c12b47138a8901b167650e48c93b25692cb29f802a15b8a6616020357 |
|                  | 46eab1ef2e43a56e0cc83f5c52b5ae628a2c7a78b0c4a7e2                                 |
| os_hidden        | False                                                                            |
| owner            | c71f3ce86c4e437abf2407f488c55054                                                 |
| protected        | False                                                                            |
| size             | 390791168                                                                        |
| status           | active                                                                           |
| tags             | []                                                                               |
| updated_at       | 2019-05-10T20:25:38Z                                                             |
| virtual_size     | None                                                                             |
| visibility       | shared                                                                           |
+------------------+----------------------------------------------------------------------------------+
+ lockfile-remove /root/setup/images/image-setup-lockfile
+ uname -m
+ ARCH=x86_64
+ [ x86_64 = aarch64 ]
+ echo *** Doing x86_64-specific setup...
*** Doing x86_64-specific setup...
+ /local/repository/setup-basic-x86_64.sh
+ wait 10439 10440 10441
+ logtend basic
+ area=basic
+ echo basic
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=basic
+ date +%s
+ stamp=1557520003
+ date
+ date=Fri May 10 14:26:43 MDT 2019
+ eval tss=$LOGTIMESTART_basic
+ tss=1557519932
+ expr 1557520003 - 1557519932
+ tsres=71
+ perl -e print 71 / 60.0 . "\n"
+ resmin=1.18333333333333
+ echo END basic 1557520003 Fri May 10 14:26:43 MDT 2019
+ echo TOTAL basic 71 1.18333333333333
+ exit 0
+ echo SETUP_BASIC_DONE="1"
+ cp -p /local/repository/openstack-slothd.py /root/setup/
+ [ 18 -ge 11 ]
+ cat
+ [ 0 -eq 1 ]
+ RANDPASSSTRING=
+ [ -e /root/setup/random_admin_pass ]
+ logtstart ext
+ area=ext
+ echo ext
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ext
+ date +%s
+ stamp=1557520003
+ date
+ date=Fri May 10 14:26:43 MDT 2019
+ eval LOGTIMESTART_ext=1557520003
+ LOGTIMESTART_ext=1557520003
+ echo START ext 1557520003 Fri May 10 14:26:43 MDT 2019
+ find /local/repository/ext -maxdepth 1 -type d
+ grep -v ^.$
+ grep -v /local/repository/ext$
+ xargs
find: â€˜/local/repository/extâ€™: No such file or directory
+ EXTDIRS=
+ [ ! -z  ]
+ logtend ext
+ area=ext
+ echo ext
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=ext
+ date +%s
+ stamp=1557520003
+ date
+ date=Fri May 10 14:26:43 MDT 2019
+ eval tss=$LOGTIMESTART_ext
+ tss=1557520003
+ expr 1557520003 - 1557520003
+ tsres=0
+ perl -e print 0 / 60.0 . "\n"
+ resmin=0
+ echo END ext 1557520003 Fri May 10 14:26:43 MDT 2019
+ echo TOTAL ext 0 0
+ [ -n 2002dfe5f7494556215a -a 1 = 1 ]
+ + hostname
sed -n -e s/[^\.]*\.\(.*\)$/\1/p
+ mydomain=
+ + sed -n -ehead s/^nameserver \([0-9]*\.[0-9]*\.[0-9]*\.[0-9]*\).*$/\1/p -1

+ mynameserver=130.127.132.51
+ [ -z 130.127.132.51 ]
+ cp -p /etc/resolv.conf /etc/resolv.conf.orig
+ grep -q forwarders /etc/bind/named.conf.options
+ [ 0 -eq 0 -a -n 130.127.132.51 ]
+ cat /var/emulab/boot/mydomain
+ outerdomain=clemson.cloudlab.us
+ dig @127.0.0.1

; <<>> DiG 9.11.3-1ubuntu1.7-Ubuntu <<>> @127.0.0.1
; (1 server found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 24483
;; flags: qr rd ra ad; QUERY: 1, ANSWER: 13, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
; COOKIE: 7b9a758eea9e72e849820f4c5cd5de832f61bf3b28741219 (good)
;; QUESTION SECTION:
;.				IN	NS

;; ANSWER SECTION:
.			10322	IN	NS	m.root-servers.net.
.			10322	IN	NS	a.root-servers.net.
.			10322	IN	NS	g.root-servers.net.
.			10322	IN	NS	c.root-servers.net.
.			10322	IN	NS	k.root-servers.net.
.			10322	IN	NS	d.root-servers.net.
.			10322	IN	NS	l.root-servers.net.
.			10322	IN	NS	b.root-servers.net.
.			10322	IN	NS	e.root-servers.net.
.			10322	IN	NS	j.root-servers.net.
.			10322	IN	NS	f.root-servers.net.
.			10322	IN	NS	i.root-servers.net.
.			10322	IN	NS	h.root-servers.net.

;; Query time: 0 msec
;; SERVER: 127.0.0.1#53(127.0.0.1)
;; WHEN: Fri May 10 14:26:43 MDT 2019
;; MSG SIZE  rcvd: 267

+ [ 0 -eq 0 ]
+ echo nameserver 192.168.0.1
+ echo nameserver 130.127.132.51
+ echo search clemson.cloudlab.us
+ dig @192.168.0.1 boss.clemson.cloudlab.us

; <<>> DiG 9.11.3-1ubuntu1.7-Ubuntu <<>> @192.168.0.1 boss.clemson.cloudlab.us
; (1 server found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 41844
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 13, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
; COOKIE: 4ab602fe972db03e4eb217df5cd5de8300b4c2c8592a8f97 (good)
;; QUESTION SECTION:
;boss.clemson.cloudlab.us.	IN	A

;; ANSWER SECTION:
boss.clemson.cloudlab.us. 30	IN	A	130.127.132.51

;; AUTHORITY SECTION:
.			10322	IN	NS	h.root-servers.net.
.			10322	IN	NS	a.root-servers.net.
.			10322	IN	NS	c.root-servers.net.
.			10322	IN	NS	e.root-servers.net.
.			10322	IN	NS	j.root-servers.net.
.			10322	IN	NS	f.root-servers.net.
.			10322	IN	NS	k.root-servers.net.
.			10322	IN	NS	l.root-servers.net.
.			10322	IN	NS	b.root-servers.net.
.			10322	IN	NS	m.root-servers.net.
.			10322	IN	NS	i.root-servers.net.
.			10322	IN	NS	d.root-servers.net.
.			10322	IN	NS	g.root-servers.net.

;; Query time: 291 msec
;; SERVER: 192.168.0.1#53(192.168.0.1)
;; WHEN: Fri May 10 14:26:43 MDT 2019
;; MSG SIZE  rcvd: 308

+ [ ! 0 -eq 0 ]
+ mkdir -p /root/setup/pssh.setup-designate.stdout
+ mkdir -p /root/setup/pssh.setup-designate.stderr
+ cat /root/setup/fqdn.map
+ cut -f1+ 
grep -v ^controller$
+ echo *** Saving original /etc/resolv.conf on all hosts...
*** Saving original /etc/resolv.conf on all hosts...
+ /usr/bin/parallel-ssh -t 0 -O StrictHostKeyChecking=no -h /tmp/pssh.hosts -o /root/setup/pssh.setup-designate.stdout -e /root/setup/pssh.setup-designate.stderr /bin/cp -p /etc/resolv.conf /etc/resolv.conf.pre-designate
[1] 14:26:43 [SUCCESS] compute-1
+ echo *** Copying Designate /etc/resolv.conf on all hosts...
*** Copying Designate /etc/resolv.conf on all hosts...
+ /usr/bin/parallel-scp -t 0 -O StrictHostKeyChecking=no -h /tmp/pssh.hosts -o /root/setup/pssh.setup-designate.stdout -e /root/setup/pssh.setup-designate.stderr /etc/resolv.conf /etc/resolv.conf
[1] 14:26:44 [SUCCESS] compute-1
+ echo ***
***
+ echo *** Done with OpenStack Setup!
*** Done with OpenStack Setup!
+ echo ***
***
+ echo *** Login to your shiny new cloud at 
*** Login to your shiny new cloud at 
+ echo   http://controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us/horizon/auth/login/?next=/horizon/project/instances/ !  
  http://controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us/horizon/auth/login/?next=/horizon/project/instances/ !  
+ echo ***
***
+ echo Your OpenStack instance has completed setup!  Browse to http://controller.tboudwin-QV52139.pdc-edu-lab-PG0.clemson.cloudlab.us/horizon/auth/login/?next=/horizon/project/instances/ .  
+ mail -s OpenStack Instance Finished Setting Up tboudwin@wcupa.edu
+ touch /root/setup/controller-done
+ logtend controller
+ area=controller
+ echo controller
+ sed -e s/[^a-zA-Z_0-9]/_/g
+ varea=controller
+ date +%s
+ stamp=1557520004
+ date
+ date=Fri May 10 14:26:44 MDT 2019
+ eval tss=$LOGTIMESTART_controller
+ tss=1557518730
+ expr 1557520004 - 1557518730
+ tsres=1274
+ perl -e print 1274 / 60.0 . "\n"
+ resmin=21.2333333333333
+ echo END controller 1557520004 Fri May 10 14:26:44 MDT 2019
+ echo TOTAL controller 1274 21.2333333333333
+ exit 0
